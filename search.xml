<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[[计算机系统结构]指令系统]]></title>
      <url>%2F2017%2F03%2F26%2F%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84-%E5%B1%82%E6%AC%A1%E5%AD%98%E5%82%A8%2F</url>
      <content type="text"><![CDATA[程序访问的局部性原理：时间局部性，空间局部性 存储系统的多级层次结构 CPU-&gt;M1-&gt;M2–。。。。。。.&gt;Mn 在存储层次中，各存储器中一般满足包含关系,即任何一层存储器中的内容都是其下一层存储（离CPU更远一级）中内容的子集 CPU与M1一般以字为单位传递，M1以外一般以块/页为单位传递数据 存储系统性能参数 存储容量S 一般来说，整个存储系统的存储容量即为最后一级存储器的容量，eg:cache + 主存的存储系统容量为主存容量 存储系统的平均每位价格C 命中率H CPU 访问该存储系统时，在M1中找到所需信息的概率 平均访存时间\(T_A\) 命中时间 不命中开销：访一级时间 + 数据传送时间 三级存储系统：Cache + 主存 + 磁盘 cache-主存层次：为了弥补主存速度的不足，一般是硬件完成的，对应用程序员和系统程序员是透明的 主存-辅存层次：为了弥补主存容量的不足，常被用于实现虚拟存储器，向编程人员提供用不完的程序空间，主要由软件完成 存储层次的四个问题 映像规则 查找算法 替换算法 写策略 Cache cache 基本结构及原理 cache是按块管理的，cache和主存均被分成大小相同的块，信息以块为单位调入cache中 主存地址： 块地址（块号） | 块内偏移 主存地址寄存器–》主存-Cache地址转换部件 –》 命中，Cache块地址，根据偏移在Cache存储体中查到对应的数据指令送给CPU -》 未命中，访主存储器，调入Cache（是否需要替换），送给CPU，或者直接送给CPU提高效率 Cache 映像规则 全相联映射 主存中的人意块可以放到Cache中的任意一个位置 ### 直接映射 主存中每一块只能放到Cache中的唯一一个位置，对应关系依次循环分配 主存的第i块（块地址为i）映射到Cache的第j块 \[j = i mod M\] M为Cache的快数， 若\(M = 2^m\)，则j实际上是i的低m位（注意是块地址的低m位），可用这m位去进行选择（索引） 组相连映像 Cache被分为若干组，每个组由若干块组成，主存中每一个块可以放到Cache中唯一一个组的任意一个位置。组的选择通常采用位选择方法 对于主存中的第i个块，若它映射到Cache中的组号为j，则 \[j = i mdo G\] G为Cache的组数，当\(G=2^g\)时，k为块号i的低g位，这里的低g位称为索引 如果每组有n 个块，则称该映像规则为n路组相联 n值越大，Cache的空间利用率就越高，块冲突的概率就越低 查找方法 Cache中设置有一个目录表，每一个Cache块在该表中均有唯一的一项，用于指出当前该块存放的信息是哪个主存块的（一般有多个主存块映射到该Cache块，它实际上记录了该主存块的块地址的高位部分，称为标识），每个主存块能唯一地由其标识来确定 12主存地址： 标识 | 索引 | 块内偏移 ____块地址__ 经典的CPU性能公式 现在我们可以用指令数、CPI和时钟周期时间来写出基本的性能公式： CPU时间=指令数×CPI×时钟周期时间 CPI（clock cycles per instruction）：每条指令的时钟周期数，表示执行某个程序或者程序片段时每条指令所需的时钟周期平均数。 指令数（instruction count）：执行某程序所需的总指令数量。 或 CPU时间=指令数×CPI/时钟频率 永远记住，唯一能够被完全可靠测量的计算机性能指标是时间。例如，对指令集减少指令数目的改进可能降低时钟周期时间或提高CPI，从而抵消了改进的效果。类似地，CPI与执行的指令类型相关，执行指令数最少的代码其执行速度未必是最快的。 写分配法 张晨曦 按写分配法：写失效时，先把所写单元所在的块调入 Cache，然后再进行写入。这与读失效类似。这种方法也称为写时取方法。 (2) 不按写分配法：写失效时，直接写入下一级存储器而不将相应的块调入 Cache。这种方法也称为绕写法。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[操作系统-页面置换算法]]></title>
      <url>%2F2017%2F03%2F25%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[置换算法的功能和目标 功能 当出现缺页异常，需调入新页面而内存已满时，置换算法选择被置换的物理页面 设计目标 尽可能减少页面的调入调出次数 把未来不再访问或短期内不访问的页面调出 页面锁定(frame locking) 描述必须常驻内存的逻辑页面 操作系统的关键部分 要求响应速度的代码和数据 页表中的锁定标志位(lock bit) 置换算法的评价方法 记录进程访问内存的页面轨迹 评价：模拟页面置换算法，记录缺页的次数，更少的缺页意味着更好的性能 页面置换算法分类 局部页面置换算法：着眼于当前进程 最优算法，先进先出算法，最近最久未使用算法，时钟算法，最不常用算法 全局页面置换算法：着眼于所有可换出的物理页面 工作集算法，缺页率算法 局部页面置换算法 最优页面置换算法 OPT 置换未来最长时间不访问的页面 实际系统中无法实现 FIFO算法 思路： 选择在内存中滞留时间最长的页面进行置换 实现： 维护一个记录所有位于内存中的逻辑页面链表 链表元素按驻留内存时间排序，链首最长，链尾最短 出现缺页时，选择链首进行置换 特征： 实现简单 性能较差 Belady现象 时钟置换算法 思路：对页面的访问情况进行大致统计 实现： 在页表项增加访问位， 各页面组织成环形链表 指针指向最先调入的页面 算法： 访问页面时，在页表项记录页面访问情况 缺页时，从指针处开始顺序查找未被访问的页面进行置换 特征：是LRU和FIFO的折中 【Note】:访问位的标记是硬件自动完成的 具体流程 页面装入内存时，访问位初始化为0 访问页面（读/写)时，访问位置1 缺页时，从指针当前位置顺序检查环形链表 访问位为0，则置换该页 访问位为1，则访问位置0，并指针移动到下一个页面， 直到找到可置换的页面 全局页面置换算法 工作集页置换算法 工作集 \(W(t, \Delta)\) t是当前的执行时刻 \(\Delta\) 是工作集窗口，即一个定长的页面访问时间窗口 \(W(t,\Delta)\)表示在当前时刻t前的\(\Delta\)时间窗口中的所有访问页面所组成的集合 \(|W(t,\Delta)|\)指工作集的大小，即页面数目 工作集页置换算法思路：换出不在工作集中的页面 窗口大小\(\tau\):当前时刻前\(\tau\)个内存访问的页引用是工作集，\(\tau\)被称为窗口大小 实现方法： 访存链表：维护窗口内的访存页面链表 访存时，换出不在工作集的页面，更新访存链表 缺页时，换出页面，更新访存链表]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ucore_lab]]></title>
      <url>%2F2017%2F03%2F23%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2Fucore-lab%2F</url>
      <content type="text"><![CDATA[ucore_lab 实验中一些重要结构体参数的含义 Page结构体 每个Page描述了一个物理页 12345678910111213141516/* * * struct Page - Page descriptor structures. Each Page describes one * physical page. In kern/mm/pmm.h, you can find lots of useful functions * that convert Page to other data types, such as phyical address. * */struct Page &#123; int ref; // page frame&apos;s reference counter // 页帧的reference uint32_t flags; // array of flags that describe the status of the page frame // 描述页帧的标记位， unsigned int unsigned int property; // the num of free block, used in first fit pm manager // 空闲块的数量， 用于first fit算法 list_entry_t page_link; // free list link // page_link&#125;; set_bit, clear_bit宏 123456set_bit(int nr,void *addr)；// 将addr中第nr位的值置为1 返回addr原第nr为的值，即0或者1clear_bit(int nr,void *addr)；// 将addr中第nr位的值置为0 返回addr原第nr为的值的反码test_bit(int nr, volatile void *addr) // 改为是否为1， 是1返回1，是0返回0 123456#define SetPageReserved(page) set_bit(PG_reserved, &amp;((page)-&gt;flags))#define ClearPageReserved(page) clear_bit(PG_reserved, &amp;((page)-&gt;flags))#define PageReserved(page) test_bit(PG_reserved, &amp;((page)-&gt;flags))#define SetPageProperty(page) set_bit(PG_property, &amp;((page)-&gt;flags))#define ClearPageProperty(page) clear_bit(PG_property, &amp;((page)-&gt;flags))#define PageProperty(page) test_bit(PG_property, &amp;((page)-&gt;flags)) 12#define PG_reserved 0 // if this bit=1: the Page is reserved for kernel, cannot be used in alloc/free_pages; otherwise, this bit=0 #define PG_property 1 // if this bit=1: the Page is the head page of a free memory block(contains some continuous_addrress pages), and can be used in alloc_pages; if this bit=0: if the Page is the the head page of a free memory block, then this Page and the mem. Or this Page isn't the head page. 12// convert list entry to page#define le2page(le, member) to_struct((le), struct Page, member)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数值分析]]></title>
      <url>%2F2017%2F03%2F21%2F%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[设𝑨,𝑩,𝑪均为𝑛×𝑛矩阵，且𝑩、𝑪非奇异，𝒃是𝑛维向量，要计算\(𝒙 = B^{-1} (2A+I)(C^{-1}+A)b\), 请给出一个合理、高效率的算法流程. \[y1 = C^{-1}b\] \[y2 = y1 + Ab\] \[y_3 = 2(Ay_2) + y_2\] \[ x = B^{-1}y_3\] 如果A的每个对角元的绝对值都比所在行的非对角元的绝对值的和要大,即 \[|a_{ii}|&gt;sum{j!=i}|a_{ij}|\] 对所有的i成立,那么称A是（行）严格对角占优阵. 如果A’是行严格对角占优阵,那么称A是列严格对角占优阵. 习惯上如果不指明哪种类型的话就认为是行对角占优.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[机器学习-朴素贝叶斯]]></title>
      <url>%2F2017%2F03%2F19%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%2F</url>
      <content type="text"><![CDATA[朴素贝叶斯原理 youryion数据挖掘指导 朴素贝叶斯法属于一种分类方法，基于特征条件独立假设学习输入输出的联合概率分布，以此为模型，对于给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。 简单有效，是一种常用的机器学习方法. 设输入空间 \(X \subseteq R^n\)为n维向量的集合 输出空间为类标记集合 \(Y=c_1, c_2,\cdots,c_k\) X是定义在输入空间上的随机变量 Y是定义在输出空间上的随机变量 P(X,Y)是X和Y的联合概率分布 \(T = (x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\)是由P(X,Y)独立同分布产生的训练集 贝叶斯法则 条件概率 条件概率表示为P（A|B），读作“在B条件下A的概率”。 若只有两个事件A，B，那么 \[P(A|B) = \frac{P(AB)}{P(B)}\] 贝叶斯法则 引入独立性假设 得到朴素贝叶斯分类器 拉普拉斯平滑]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[机器学习实验-朴素贝叶斯分类器]]></title>
      <url>%2F2017%2F03%2F18%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E9%AA%8C-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%2F</url>
      <content type="text"><![CDATA[提示：个人联系方式及代码简要说明、运行方式在README.md文件中 实验目的 在真实数据集上实现朴素贝叶斯分类器，并验证其分类效果 了解如何在测试数据集上实现一个机器学习算法 了解如何评价分类效果 了解如果分析实验结果 算法实现原理 假设各条件相互间独立，即\[P(y|x_1,\cdots,x_n)P(y) \propto \prod_{i=1}^{n}P(x_i|y)\] 在训练时训练 \(P(y)\) 以及\(P(x_i|y)\) 测试时输出 \[\hat y = argmax_yP(y)\prod_{i=1}^{n}P(x_i|y)\] 数据集处理 数据集描述 实验给定了Adult数据集，其中adult.train为训练集（32561条数据），adult.test为测试集(16281条数据)，每行数据代表一个人，共有15个维度的特征，最后一个特征为该人的收入是否超过了50K。 数据集中部分特征是连续数据，部分数据可能未知(用?表示) 分类器的性能评价指标： 本次实验中，我采用了准确率作为朴素贝叶斯分类器性能的评价指标，计算方法为： \[Accuracy = \frac{number\ of\ correctly\ classified\ records}{number\ test\ records}\] 数据集的变量及其含义 变量名 意义 数据特征 处理方式 age 年龄 连续数据 分段离散 work_class 职业类型 离散数据 fnlwgt 最终重量(?) 连续数据 无意义、忽略 education 学历等级 离散数据 education_num 学历的数字等级 连续数据 重复、忽略 marital-status 婚姻状况 离散数据 occupation 职业 离散数据 relationship 家庭关系 离散数据 race 人种 离散数据 sex 性别 离散数据 capital_gain 资本利得 连续数据 离散化 capital_loss 资本损失 连续数据 离散化 hours_per_week 每周工作时长 连续数据 离散化 native-country 出生国 离散 income 收入 离散 特殊数据的处理方式 未知数据？的处理 数据集中有未知的数据(?), 我的处理方式是将这类数据直接忽略掉 数据合并 使用R语言对数据进行统计，发现，Never-worked和Without-pay可以合并为Without-pay字段。 数据的离散化 数据规律探索 考虑到R语言对数据处理的优越性，因此采用R语言对数据规律进行探索，利用R语言读入测试集和训练集 123456# 读取测试集，已清除？test = read.csv("after.test", sep=",", header=F, col.names=c("age", "work_class", "fnlwgt", "education", "education_num", "marital-status", "occupation", "relationship", "race", "sex", "capital_gain", "capital_loss", "hourr_per_week","native-country", "income"), fill = FALSE, strip.white = T) 然后对连续数据做统计之后得到如下结果 Age的规律 12345678&gt; table(train$age) 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 328 447 594 629 621 674 824 752 799 745 789 808 774 813 851 789 837 836 828 852 828 791 786 765 769 741 743 704 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 706 711 683 523 555 575 571 455 448 394 386 343 337 344 332 276 259 213 186 173 136 110 111 90 80 64 54 40 73 74 75 76 77 78 79 80 81 82 83 84 85 86 88 90 49 38 34 29 20 14 15 16 13 7 5 8 3 1 3 35 可知年龄范围为17~90，我们设置其分割粒度为5 资本收益 资本收益 可以从统计结果看出，投资收益相互间差别很大，直接以固定颗粒度分割并不适合，考虑到投资和收入之间存在一定的关系，而且可以很明显的看出收益为0的占了所有数据的大部分，我们将其分为三个类别，没有资本收益，资本收益较少，资本收益较大，。 除去数据中为0的值之后，求得其平均值，中位数，方差如下： 123456789&gt; # 资本收益平均值&gt; mean(train$capital_gain[train$capital_gain!=0])[1] 12977.6&gt; # 资本收益中位数&gt; median(train$capital_gain[train$capital_gain!=0])[1] 7298&gt; # 资本收益方差&gt; sd(train$capital_gain[train$capital_gain!=0])[1] 22311.91 可以看出其方差较大，以平均值作为界点不合适，我们取其中位数作为资本收益高低的界点(训练集与测试集这个数据差别不大) 同理，资本损失的数据也有这样的规律，我们也用这样的方法对其进行处理。 123456789&gt; # 资本损失平均值&gt; mean(train$capital_loss[train$capital_loss!=0])[1] 1867.898&gt; # 资本损失中位数&gt; median(train$capital_loss[train$capital_loss!=0])[1] 1887&gt; # 资本损失收益方差&gt; sd(train$capital_loss[train$capital_loss!=0])[1] 361.8574 资本损失的差异值不大，我们直接取中位数作为分界点 每周工作时间 每周工作时间 工作时间为1~99， 分割粒度设置为5 各连续变量的范围及对应的分割粒度如下： 变量名 范围 分割粒度 age 17~90 5 capital_gain 0 ~ 99999 0，0~7298，7298+ capital_loss 0 ~ 4356 0，0~1887， 1887+ hours_per_week 1~99 5 实验结果的分析 训练集规模的影响 问题：训练集的规模对分类效果有什么影响？ 选取5%， 50%， 100%的训练集数据训练分类模型 测试数据的选择，经过多方面的对比测试，发现选取的特征值为 1年龄 工作类别 学历等级 婚姻状况 职业 投资利得 投资损失 收入 时，训练的模型分类效果最好。以此为基础，分别选取 5%， 50%， 100%的训练集数据训练分类模型时的训练结果对比如下： 比例 训练集数目 准确率 5% 1494 83.71% 50% 15075 83.99% 100% 30162 84.12% 由这个表格可以看出，随着数据集的增加，分类器的分类效果越来越好。而实际上，即使只取了5%（1494条训练数据），训练出的分类器分类效果仍然挺好的，可以由此体会到贝叶斯分类的高效性和实用性。 重复随机抽取样本实验（5次），记录最小，最大，平均准确率 随机比例 训练集数目 准确率 70.13% 21131 83.99% 47.92% 14458 84.01% 94.40% 28472 84.04% 58.65% 17687 84.14% 11.83% 3566 83.95% 最小值 最大值 平均值 83.95% 84.14% 84.03% 综合两个测试结果可以得出如下结论：数据集的规模会对分类效果产生一定影响，但这种影响并不是绝对的，当抽取的训练集具有随机性时，小训练集也有可能会有特别好的分类效果，不过整体来看，训练集规模越大，分类效果越好。 0概率的处理 当测试集中某个数据的某条特征值取了某个值\(x_i\)，但训练集中该特征值并没有取过该值\(x_i\)，则在训练时\(P(x_i|y) = 0\)，由此在做测试时计算其概率\[\hat y = argmax_yP(y)\prod_{i=1}^{n}P(x_i|y)\]时会得到概率为0。 解决方法：通常我们会进行拉普拉斯平滑处理，即在计算条件概率时对每个\(x_i\) 做\(+\lambda\)处理, 对应的总数也需要做\(+M\lambda\)，经过测试可以发现，在未做拉普拉斯平滑时，训练集取50%时，分类准确率为83.95%， 加上拉普拉斯平滑处理之后，分类准确率为83.99%， 准确率有一定提升。 连续特征以及未知特征的处理 连续数据如何进行处理 说明：【数据的分析及离散化方案】见前面【3.4.3数据的离散化】小节。由于后期经过测试发现特征选取年龄 工作类别 学历等级 婚姻状况 职业 投资利得 投资损失 收入这8个特征时分类效果最好，故前面测试样例的特征选取均选择了这8个，为了测试连续数据分割方案对分类效果的影响，将每周工作时间这一连续特征加入分类的特征中。 测试时，训练集取100%， 拉普拉斯平滑处理的\(\lambda = 1\) 各连续特征值分割粒度与其分类效果对比 特征 分割粒度 准确率 age 不分割 83.816% age 3 83.831% age 5 83.751% age 10 83.784% 特征 分割粒度 准确率 hour 不分割 83.845% hour 3 83.845% hour 5 83.752% hour 10 83.804% 特征 分割粒度 准确率 投资收益与损失 不分割 【85.20%】 投资收益与损失 1000 83.62% 投资收益与损失 无，低，高 83.75% （注意：测试某一特征时，其余特征分割情况默认为： 年龄分割粒度 5， 每周工作时间分割粒度为5， 投资收益和损失分割为无， 收益/损失低, 收益/损失高） 结果分析：这里发现了一些很尴尬的结果，对这三个连续特征值进行不同粒度离散之后发现，【不进行离散】，直接以每一个数据单独作为一个类别进行分类时准确率反而比对其进行不同间距离散之后分类【准确率高】，特别是【投资收益与损失】的两个特征值，不进行离散时其准确率甚至高达 【85.2%】，而进行了等间距离散或者以无，低、高， 结合前面对各个特征的分布情况的统计可以进行如下猜测： 结合前面age, work hour, capital_gain, capital_loss几个特征值的取值特征统计结果， 可以发现，age和work hour在各个取值中虽然较为分散，但是也有小范围集中，简单的等间距离散，对其分类的优化效果不大，甚至于有可能因为粒度过大而使分类效果显著下降， 当分割粒度恰好使得集中数据分在了一个category时，其准确率会略高一点，而如果恰好使之分散开，可能会对分类准确率有反作用，如work hour特征分割粒度为5和10的对比。 对于投资收益和损失这两个特征值，分析其数据特征可以发现，有超过70%的数据是0，而其他数据就较为零散并且差异值极大，简单地等间距分割，或者以中位数，平均数作为临界点进行分割都是不太合理的，因此这种情况下不进行离散化分类效果反而会更好，（不知道高斯分布处理会不会优化其分类效果，由于能力和时间限制，没来得及进行测试） 未知数据如何处理 对于未知数据的处理，我做了两种情况的对比，一种是直接忽略掉这些数据，另一种是将‘？’也视为一种数据和特征 处理方案 准确率 忽略未知数据 84.12% 视为新类型 【84.45%】 可以看出，将未知数据视为一种特殊的新类型时其分类准确率有较大提高，可知这些数据某种程度上也能够反映出其收入的高低 选取的特征值对比 选取的特征值 准确率 年龄 工作类别 重量 学历等级 教育年限 婚姻状况 职业 家庭关系 人种 性别 投资利得 投资损失 每周工作时间 出生国 收入 79.77% 年龄 工作类别 学历等级 婚姻状况 职业 家庭关系 人种 性别 投资利得 投资损失 每周工作时间 出生国 收入 81.85% 年龄 工作类别 学历等级 婚姻状况 职业 家庭关系 性别 投资利得 投资损失 每周工作时间 出生国 收入 81.83% 年龄 工作类别 学历等级 婚姻状况 职业 人种 投资利得 投资损失 每周工作时间 收入 83.74% 年龄 工作类别 学历等级 婚姻状况 职业 投资利得 投资损失 每周工作时间 收入 83.75% 年龄 工作类别 学历等级 婚姻状况 职业 投资利得 投资损失 收入 84.12% 年龄 工作类别 教育年限 婚姻状况 职业 收入 81.79% 由这个表的对比分析可以明显地感受到特征值的选取对分类效果的影响,【年龄,工作类别,学历等级,婚姻状况,职业,投资利得,投资损失】这几个特征值能够很大程度上反应出其收入的高低，特别是投资收入和损失，这个特征与收入有较大的相关性，这也是为什么在【5.3.1 连续数据如何进行处理】一节中提到对这两个特征不进行分割时其分类效果甚至可以高达85.20%的一个原因。 这也提醒我们在选取训练数据时注意对特征值的选取，有代表性的特征对其分类准确率有促进作用，而一些无关的特征则会对分类效果有负作用。 交叉验证 选取不同比例的测试集数据用作训练，观察其对分类效果的影响 测试集比例 训练集+测试集 准确率 0% 15075 + 0 83.99% 5% 15075 + 751 84.02% 50% 15075 + 7525 84.23% 100% 15075 + 15060 84.26% [注] 训练集选取的是50%训练集数据 由这个数据对比可以看出，训练模型时加入部分测试集数据，对分类效果有提升作用。 实验总结及结论 本次实验实现了贝叶斯分类算法，并探讨了数据规模、特征值的选择对分类效果的影响，以及连续值，未知值的不同离散方案和处理方案对分类效果的影响，并探讨了拉普拉斯平滑对分类效果的影响。 通过多方面的对比，主要得出了以下一些结论: 特征值的选取对分类效果影响较大，可以根据特征值与类别的相关性大小判断其对分类是有帮助的还是有干扰的。 特征值个数也对分类效果有一定影响，选择合适的，足够的特征作为分类依据是较好的，特征值的选择和个数的选择可通过参数的调整进行尝试后得出最优方案 数据规模对分类效果有一定影响，但是只要特征值选取较好，训练数据较少情况下训练出的模型其分类效果也较好。 连续值的处理方式对分类效果影响较大，对于一些本身比较离散并且该特征值对类型影响较大情况下，分割粒度越小，分类效果会更好，尤其是本实验中投资收入和投资损失两个特征值，不进行分割时其准确率甚至高达85.2%，可明显体会到数据离散粒度对分类效果的影响。 未知数据的处理，未知数据视为一种特殊类型也是一种比较有效的处理方式，背后原因可能是这些没统计到数据的人群可能具有某方面的共性，其收入也会受到这方面的影响。 本次实验中自己收获很大，特别是学会了从不同的方面去评价一个算法的性能的方式的分析方法。此外，对编程也有一些新的启发，在编程时需要注意面向对象编程，考虑到各种可能的变化，本次实验中的贝叶斯分类器的实现方法我参考了【参考资料1 使用python编写朴素贝叶斯分类器】一文的实现方式，这种实现可以达到一种自适应的状态，不论特征值有多少个，是什么类型的数据，只要给出参数，均可对其进行训练和分类，这就方便了我们进行不同的特征值对分类效果的影响分析时的测试，只需要对测试文件和训练文件做对应修改即可。此外，在实现过程中设置了很多参数，可以方便进行训练数据比例，是否随机选取，特征值分割粒度，是否进行拉普拉斯平滑处理等进行设置，极大地方便了测试和分析。 参考资料 使用Python编写朴素贝叶斯分类器 https://dataminingguide.books.yourtion.com/chapter-6/chapter-6-6.html Dataset: Adult (R) http://scg.sdsu.edu/dataset-adult_r/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[搜索引擎性能评价实验]]></title>
      <url>%2F2017%2F03%2F18%2F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%2F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%80%A7%E8%83%BD%E8%AF%84%E4%BB%B7%E5%AE%9E%E9%AA%8C%2F</url>
      <content type="text"><![CDATA[实验步骤 自由分组， 至多2人一组 构建查询样例集合：利用网络资源(http://top.baidu.com/; http://top.sogou.com/等) 和个人使用经验构建查询样例集合，查询样例集合需覆盖不同查询热门程度（ 冷门/热门） 和各种类型的用户查询需求（ 导航类/信息类/事务类），样例集合的规模为10个查询，各类比例为2:5:3， 并根据个人经验，撰写每个查询样例的信息需求内容。 构建Pooling：学生根据其构建的查询样例集合，抓取常用的三个中文搜索引擎(百度、360好搜、 搜狗)对这部分查询词的查询结果，每个搜索引擎抓取查询结果的前十位结果，并利用这些结果 构建Pooling。 构建相关性标注集合：根据步骤2中撰写好的信息需求，对Pooling里的结果进行标注，标注为 “ 答案” 和“ 非答案” 两类即可。 根据标注结果，依据MAP，P@10，MRR等评价指标对各个搜索引擎的查询性能进行评价，并对 搜索引擎满足不同信息需求的情况加以比较，每人各自撰写实验报告。 查询样例集合创建 导航类 丝芙兰官网（热门） 河海大学主页（冷门） 信息类 萨德(热门), 美对朝忍耐到尽头(热门)，红薯 地瓜（冷门），青铜器制作流程（冷门）, 烟草学专业(冷门) 事务类 NBA直播(热门)， 金刚狼3下载（热门），张家界联想笔记本维修（冷门） 查询样例信息需求 丝芙兰官网（热门）：找到丝芙兰官网，查看产品信息，功效，购买方式等等 河海大学主页（冷门）：找到河海大学的校园主页 萨德：关于萨德的最新新闻，以及事件经历 美对朝忍耐到尽头：相关的新闻 红薯 地瓜：红薯与地瓜是否是同一种事物，各地有什么区别 青铜器制作流程：直接给出青铜器的制作方法 烟草学专业：查询专业简介，需要给出专业学习内容，就业方向，相关学校 NBA直播：最新NBA赛事直播，比分情况，赛况解说等 金刚狼3下载：给出电影的下载链接或者在线观看链接 张家界联想笔记本维修：给出维修点，联系方式等 构建pooling 针对三个搜索引擎分别抓取对应搜索数据，并进行标记，抓取结果及Pooling标记结果见【统计数据.xls】 性能指标计算 首先需要明确性能指标的计算方法 平均准确率（AP）： \[AP=\frac{1}{N}\sum_{i=1}^NPrecision(i)\] MAP MAP方法是Mean Average Precison，即平均准确率法的简称。其定义是求每个相关文档检索出后的准确率的平均值（即Average Precision）的算术平均值（Mean），即 \[MAP = mean(AP)\] RR 首位相关结果倒数RR,即出现第一个相关性标注的排序的倒数 \[RR = \frac{1}{Rank(1)}\] MRR MRR是平均排序倒数（Mean Reciprocal Rank）的简称，MRR方法主要用于寻址类检索（Navigational Search）或问答类检索（Question Answering）,MRR方法首先计算每一个查询的第一个相关文档位置的倒数，然后将所有倒数值求平均。 P@N P@N本身是Precision@N的简称，指的是对特定的查询，考虑位置因素，检测前N条结果的准确率 基于此，计算各词条的RR,P@10，AP，以及对搜索引擎的MRR,MAP，P@10结果如下： 分词条结果 进一步统计各个搜索引擎对不同类型的关键词的搜索结果性能： 各搜索引擎不同类别的统计结果 实验结论 按照统计结果做出各项指标的柱状图如下： MAP MP@10 MRR 总体的数据 由统计结果分析，从总体来看，在各项指标中，百度是三个搜索引擎中表现最好的,360的性能次之，而搜狗的结果则稍差一些。 导航类搜索词 对于导航类搜索关键词，RR一般用作评价导航类的查询需求，用于表示用户在知道目标前需要浏览的结果数目，可以看到，三大搜索引擎的导航类关键词的MRR指标均为1，可以发现，当用户想要搜索的信息为已知资源，主页，资源等信息时，搜索引擎可能会更倾向于返回给用户一些官方的主页信息，以使用户能够尽快找到目标，对于导航类信息的其他指标，相差也不大，但是P@10的指标值相差比较大，百度的P@10值是较好的，而360和搜狗的结果则稍差，查看原始搜索结果标记，三大搜索引擎都加入了对应的百科，问答平台，而搜狗和360的结果还夹杂了不少“同名的广告”，以“河海大学主页”词条为例，360和搜狗的结果中有不少标题虽是“河海大学招生网”等信息，但实际是一些培训机构的页面，两家的搜索引擎并没有做这方面的剔除，使得结果首页多了不少奇怪的“广告”，影响了搜索体验。另一个比较有趣的现象是，河海大学离退休工作处官网的名称是“河海大学主页”，这个页面在三大搜索引擎的结果中排第2、3位，可见搜索引擎背后会根据用户的点击数据调整结果的显示顺序。 信息类搜索词 信息类数据是用户搜索需求中占比最大的，用户的关注点在于结果的全面和权威性，对于这类搜索词，搜索引擎多数会给出其问答平台的结果，相关新闻结果，或者百科结果。对于信息类关键词，P@10是评价其搜索性能的较好指标，百度的数据在70%左右，而360和搜狗在60%左右，可见在中文搜索中，百度的确做得比较好，对于大多数信息类搜索词，百度的结果足够全面。对于新闻类的信息，三大搜索引擎结果差别并不是特别大，但是对于一些知识类信息，或者生活类信息的搜索，360和搜狗的表现则差强人意，以“红薯 地瓜”关键词为例，用户的搜索需求是查询红薯地瓜的区别，百度的结果大体上与之相符，而搜狗和360除了少数两三条结果与之相关，多数结果只与红薯有关，可以推测是由于搜索引擎的分词和联合搜索系统的处理方式的差异。 事务类搜索词 事物类搜索词中，百度的结果优势不是那么明显，甚至略差，360的结果则稍微更好一些， 这里差异较大的词条是金刚狼3下载这个搜索词条，其实这个词条是一个坑，一般来说这类资源可能在互联网上很少甚至不存在，因此很多数据可能其实是广告或者一些死链接，这时可能更需要搜索引擎去剔除一些不必要的结果以帮助用户完成其任务需求，360的结果大多数是迅雷的链接，而百度的结果则包含了各种不同的站点，这些站点大多数是广告等非用户目标站点，可能是出于广告费等方面的考虑吧，使得其结果表现并不好。 冷热门 对于热门数据，三大搜索引擎的表现都比较好，冷门数据百度表现依然较好，而360和搜狗的性能则有所下降，一方面可能是由于百度的市场占有率更大，用户更多，能够获取到的用户数据也更多更全面，即使是冷门搜索词由于有较大的用户基数也能得到较好地反馈结果，另一方面，百度的数据抓取可能更全面，对于不同类别的搜索词，百度的P@10指标均能达到近70%，可见其数据是比较齐全的，这也给其冷门搜索词的搜索提供的数据。 总结 从各方面的分析可以看出，百度的性能的确是最好的，分析推测其原因如下：百度的实力更强，硬件资源，软件资源均遥遥领先于其他两家搜索引擎，这就使得百度可以拿到更多的数据，拿到更全面的数据，这会对搜索引擎性能有较大的影响；此外，百度的用户群体更大，丰富的用户数据可以帮助百度动态优化其搜索结果的排序，进而提升用户体验；百度的分词和检索算法可能更优，正如前面提到的“地瓜 红薯”词条，百度的结果是两个词的联合结果，而360和搜狗的结果可能只与其中一个有关。对于搜狗来说，其搜索结果中有时总是会有微信或者知乎的结果，当用户的意图并不在此时，可能会极大地影响其体验。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CCF2016]]></title>
      <url>%2F2017%2F03%2F16%2F%E7%AE%97%E6%B3%95%2FCCF2016%2F</url>
      <content type="text"><![CDATA[2016年CCF真题练习 Mac 下C++的编译 gcc -o target source.cpp -lstdc++ 2016-12 第一题 中间数 试题名称： 中间数 时间限制： 1.0s 内存限制： 256.0MB 12345678910111213141516171819202122232425262728293031问题描述 在一个整数序列a1, a2, …, an中，如果存在某个数，大于它的整数数量等于小于它的整数数量，则称其为中间数。在一个序列中，可能存在多个下标不相同的中间数，这些中间数的值是相同的。 给定一个整数序列，请找出这个整数序列的中间数的值。输入格式 输入的第一行包含了一个整数n，表示整数序列中数的个数。 第二行包含n个正整数，依次表示a1, a2, …, an。输出格式 如果约定序列的中间数存在，则输出中间数的值，否则输出-1表示不存在中间数。样例输入62 6 5 6 3 5样例输出5样例说明 比5小的数有2个，比5大的数也有2个。样例输入43 4 6 7样例输出-1样例说明 在序列中的4个数都不满足中间数的定义。样例输入53 4 6 6 7样例输出-1样例说明 在序列中的5个数都不满足中间数的定义。评测用例规模与约定 对于所有评测用例，1 ≤ n ≤ 1000，1 ≤ ai ≤ 1000。 思路：调用库函数进行排序，然后从中间向两侧进行查找 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt; #include &lt;cstring&gt; #include &lt;algorithm&gt;using namespace std;int a[1002];int main(int argc, char const *argv[])&#123; /* code */ int n = 0; cin &gt;&gt; n; for(int i = 0; i &lt; n; ++i) &#123; cin&gt;&gt;a[i]; &#125; sort(a, a+ n); int min = n/2; int max = n/2; // 一开始这里的设置是错的 for(int i = n/2; i&lt; n; ++i) &#123; if(a[n/2] &lt; a[i]) &#123; max = i; break; &#125; &#125; for(int i = n/2; i&gt;=0; --i) &#123; if(a[n/2] &gt; a[i]) &#123; min = i; break; &#125; &#125; if(n-1-max+1 == min + 1 || (max ==n/2 &amp;&amp; min ==n/2) ) &#123; cout &lt;&lt; a[n/2]&lt;&lt;"\n"; &#125; else &#123; cout&lt;&lt; -1&lt;&lt;"\n"; &#125; return 0;&#125; 2016-12第二题 工资计算 试题编号： 201612-2 试题名称： 工资计算 时间限制： 1.0s 内存限制： 256.0MB 12345678910111213141516171819202122问题描述 小明的公司每个月给小明发工资，而小明拿到的工资为交完个人所得税之后的工资。假设他一个月的税前工资（扣除五险一金后、未扣税前的工资）为S元，则他应交的个人所得税按如下公式计算： 1） 个人所得税起征点为3500元，若S不超过3500，则不交税，3500元以上的部分才计算个人所得税，令A=S-3500元； 2） A中不超过1500元的部分，税率3%； 3） A中超过1500元未超过4500元的部分，税率10%； 4） A中超过4500元未超过9000元的部分，税率20%； 5） A中超过9000元未超过35000元的部分，税率25%； 6） A中超过35000元未超过55000元的部分，税率30%； 7） A中超过55000元未超过80000元的部分，税率35%； 8） A中超过80000元的部分，税率45%； 例如，如果小明的税前工资为10000元，则A=10000-3500=6500元，其中不超过1500元部分应缴税1500×3%=45元，超过1500元不超过4500元部分应缴税(4500-1500)×10%=300元，超过4500元部分应缴税(6500-4500)×20%=400元。总共缴税745元，税后所得为9255元。 已知小明这个月税后所得为T元，请问他的税前工资S是多少元。输入格式 输入的第一行包含一个整数T，表示小明的税后所得。所有评测数据保证小明的税前工资为一个整百的数。输出格式 输出一个整数S，表示小明的税前工资。样例输入9255样例输出10000评测用例规模与约定 对于所有评测用例，1 ≤ T ≤ 100000。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IPv6协议转发实验]]></title>
      <url>%2F2017%2F03%2F16%2F%E7%BD%91%E7%BB%9C%2FIPv6%E5%8D%8F%E8%AE%AE%E8%BD%AC%E5%8F%91%E5%AE%9E%E9%AA%8C%2F</url>
      <content type="text"><![CDATA[p{ text-indent: 2em; } 实验目的 通过前面的实验，我们已经深入了解了 IPv6 协议的分组接收和发送处理流程。本实验需要将实验模块的角色定位从通信两端的主机转移到作为中间节点的路由器上，在 IPv6 分组收发处理的基础上，实现分组的路由转发功能。 网络层协议最为关注的是如何将 IPv6 分组从源主机通过网络送达目的主机，这个任务就是由路由器中的 IPv6协议模块所承担。路由器根据自身所获得的路由信息，将收到的 IPv6分组转发给正确的下一跳路由器。如此逐跳地对分组进行转发，直至该分组抵达目的主机。 IPv6 分组转发是路由器最为重要的功能。 本实验设计实现路由器中的 IPv6 协议，可以在原有 IPv6 分组收发实验的基础上，增加 IPv6 分组的转发功能。对网络的观察视角由主机转移到路由器中，了解路由器是如何为分组选择路由，并逐跳地将分组发送到目的端的。 大家在本实验中也会初步接触路由表这一重要的数据结构，认识路由器是如何根据路由表对分组进行转发的。 实验具体任务 对于每一个到达本机的 IPv6 分组，根据其目的 IPv6 地址查找本机的路由表，对该分组进行如下的几类操作： 丢弃查不到路由的分组； 向上层协议上交目的地址为本机地址的分组； 根据路由查找结果，向相应接口转发其余的分组。 实验内容 实验内容主要包括： 设计路由表数据结构：设计路由表所采用的数据结构。要求能够根据 IPv6 地址来确定分组处理行为（丢弃、 上交或转发），转发情况下需获得下一跳的 IPv6 地址。路由表的数据结构和查找算法会极大的影响路由器的转发性能，有兴趣的同学可以深入思考和探索。 IPv6 分组的接收和发送：对前面实验中所完成的代码进行修改，在路由器协议栈的 IPv6 模块中能够正确完成分组的接收和发送处理。具体要求不做改变，参见IPv6 分组收发实验。 IPv6 分组的转发：对于需要转发的分组进行处理，获得下一跳的 IP 地址，然后调用发送接口函数进一步处理。 实验说明： 具体实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** THIS FILE IS FOR IPv6 FORWARD TEST*/// system support#include "sysinclude.h"extern void ipv6_fwd_DiscardPkt(char *pBuffer, int type);/*参数： pBuffer：指向被丢弃的报文 type：表示错误类型，包括 TTL 错误和找不到路由两种错误，定义如下： # define STUD_IPV6_FORWARD_TEST_HOPLIMIT_ERROR #define STUD_IPV6_FORWARD_TEST_NOROUTE说明： 本函数是丢弃分组的函数，在接收流程中检查到错误时调用此函数将分组丢弃*/extern void ipv6_fwd_SendtoLower(char *pBuffer, int length, ipv6_addr *nexthop);/*参数： pBuffer：指向所要发送的 IPv6 分组的起始地址，指向数据为网络字节序，是从ipv6头开始的 length：分组的整个长度（包括分组头部） nexthop：为转发处理时下一跳的地址。说明： 本函数是发送流程的下层接口函数，在 IPv6 协议模块完成发送封装工作后调用该接口函数进行后续发送处理。*/extern void getIpv6Address(ipv6_addr *pAddr);/*本函数用于获取本机的 IPv6地址，该函数即可返回本机的 IPv6地址pAddr：返回的 IPv6 地址结构的指针*/extern void ipv6_fwd_LocalRcv(char *pBuffer, int length);// 分组上交函数，在对 IPv6 的分组完成解析处理之后，如果分组的目的地址是本机的地址，则调用本函数将正确分组提交上层相应协议模块进一步处理。// 自定义路由表数据结构struct Router&#123; ipv6_addr dest; // 目的地址 UINT32 masklen; // 掩码长度 ipv6_addr nexthop;// 下一跳 struct Router *next;// 链表下一个节点 &#125;RouterTables;// 链表的head和创建的新节点的位置RouterTables *head = null;RouterTables *p = null;void stud_ipv6_Route_Init()&#123; /* 本函数用于对路由表进行初始化，在系统初始化的时候将调用该函数，对学生自己写的路由表数据结构进行初始化操作。 */ return;&#125;void stud_ipv6_route_add(stud_ipv6_route_msg *proute)&#123; /* 参数： proute：需要添加的路由，其数据结构 stud_ipv6_route_msg 的定义如下： typedef stud_route_msg &#123; ipv6_addr dest; // 地址段 UINT32 masklen; // ipv6_addr nexthop;//下一跳地址 &#125; stud_ipv6_route_msg; 说明： 本函数为路由表配置接口，系统在配置路由表时需要调用此接口。此函数功能为向路由表中增加一个新的表项，将参数所传递的路由信息添加到路由表中。 */ RouterTables * newRouter = new Router(); newRouter-&gt;dest return;&#125;int stud_ipv6_fwd_deal(char *pBuffer, int length)&#123; /* 接收函数，实现分组接收处理.根据分组中 参数： pBuffer ：指向所及受到的 IPv6 分组头部 length：为 IPv6 分组的长度 返回值： 处理该包的返回值， 0 为成功， 1 为失败； 说明： 本函数是 IPv6 协议接收流程的下层接口函数，实验系统从网络中接收 到分组后会调用本函数。调用该函数之前已完成 IPv6 报文的合法性检查 */ // a.判定是否为本机接收的分组，如果是则调用 ipv6_fwd_LocalRcv( )； // b. 按照最长匹配查找路由表获取下一跳，查找失败则调用ipv6_fwd_DiscardPkt( )； // c. 需要转发，hop limit - 1 ,调用 ipv6_fwd_SendtoLower( )完成报文发送； return 0;&#125; 本实验中需要注意的几个问题是： IPV6地址结构体的定义 IPv6转发实验没有给出ipv6_addr结构体的定义，而比较地址时需要 广播地址也需要上交分组 最后一跳时需要将分组直接转发给目的主机]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux/Mac 常用命令]]></title>
      <url>%2F2017%2F03%2F15%2Flinux-Mac-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[使用pandoc将markdown输出为pdf pandoc的安装与配置 123456789101112131415161718192021222324252627pandoc hello-world.md -o out.pdf --latex-engine=xelatex# 如果提示pandoc无法找到插件xelatex（支持输出中文），则下载Tex，BasicTexpandoc hello-world.md -o out.pdf --latex-engine=/Library/TeX/texbin/xelatex# tips：可以将该路径加入$PATH# 指定中英文字体pandoc -N -s --toc --smart --latex-engine=xelatex -V CJKmainfont='Kai' -V mainfont='Monaco' -V geometry:margin=1in hello-world.md -o output.pdfpandoc -N -s --toc --smart -V CJKmainfont='Songti SC' -V mainfont='Monaco' --variable sansfont="Monaco" --variable monofont="Monaco" --variable fontsize=26pt --latex-engine=xelatex -V geometry:margin=1in IPv6协议转发实验.md -o example14.pdfpandoc -N -s --toc --smart --template default.latex -V CJKmainfont='Songti SC' -V mainfont='Monaco' --variable sansfont="Monaco" --variable monofont="Monaco" --latex-engine=xelatex -V geometry:margin=1in 搜索引擎性能评价实验.md -o 搜索引擎性能评价实验.pdf# 有代码高亮pandoc -N -s --toc --smart --template default.latex -V CJKmainfont='Songti SC' -V mainfont='Monaco' --variable sansfont="Monaco" --variable monofont="Monaco" --latex-engine=xelatex -V geometry:margin=1in linux-Mac-常用命令.md -o 搜索引擎性能评价实验.pdf --listings -H code.latexpandoc -N -s --toc --smart --template default.latex -V CJKmainfont='Songti SC' -V mainfont='Monaco' --variable sansfont="Monaco" --variable monofont="Monaco" --latex-engine=xelatex -V geometry:margin=1in --listings -H code.latex linux-Mac-常用命令.md -o 搜索引擎性能评价实验.pdfpandoc -N -s --toc --smart --template default.latex -V CJKmainfont='Songti SC' -V mainfont='Monaco' --variable sansfont="Monaco" --variable monofont="Monaco" --latex-engine=xelatex -V geometry:margin=1in --listings -H code.latex 机器学习实验-朴素贝叶斯分类器.md -o 朴素贝叶斯.pdfpandoc -s --smart --template default.latex -V CJKmainfont='Songti SC' -V mainfont='Monaco' --variable sansfont="Monaco" --variable monofont="Monaco" --latex-engine=xelatex -V geometry:margin=1in --listings -H code.latex OS-lec9-exercise.md -o lec9.pdfpandoc -s --smart --template ../default.latex -V CJKmainfont='Songti SC' -V mainfont='Monaco' --variable sansfont="Monaco" --variable monofont="Monaco" --latex-engine=xelatex -V geometry:margin=1in --listings -H ../code.latex OS-lec9-exercise.md -o lec9.pdfpandoc -s -N --toc --smart --template ../default.latex -V CJKmainfont='Songti SC' -V mainfont='Monaco' --variable sansfont="Monaco" --variable monofont="Monaco" --latex-engine=xelatex -V geometry:margin=1in --listings -H ../code.latex 搜索引擎性能评价实验.md -o 实验报告.docx Mac 下的中文字体集 12345678910宋体仿宋 STFangsong宋体黑体 STHei宋体简体 Songti SC PingFang SC LingWai SC LiSong Pro LiHei Pro Libian SC Lantinghei TC Kaiti SC PDF with numbered sections and a custom LaTeX header 123pandoc -N --template=mytemplate.tex --variable mainfont="Palatino" --variable sansfont="Helvetica" --variable monofont="Menlo" --variable fontsize=12pt --variable version=1.17.2 MANUAL.txt --latex-engine=xelatex --toc -o example14.pdfpandoc -N -s --toc --smart -V CJKmainfont='Kai' -V mainfont='Monaco' --variable sansfont="Monaco" --variable monofont="Monaco" --variable fontsize=26pt --latex-engine=xelatex -V geometry:margin=1in hello-world.md -o example14.pdf Unix/Linux 系统下修改环境变量 123sudo vi .bash_profile# 添加需要增加的环境变量PATH=$PATH:/Library/TeX/texbin/ 然后重新启动terminal即可 sublime 快捷键插入自定义字符串 Preference-&gt; Key Bingding-&gt; 修改user settings 在其中加入自定义快捷键 123456&#123; "keys": ["alt+r"], "command": "insert_snippet", "args": &#123; "contents": "&lt;font color=red&gt;$&#123;1:&#125;$SELECTION&lt;/font&gt;$&#123;0&#125;" &#125; &#125;, 其中光标所在位置为${1:}$SELECTION所在地 树莓派开机自启动脚本 12345678910111213141516171819202122232425#!/bin/sh### BEGIN INIT INFO# Provides: auto_start# Required-Start: $remote_fs# Required-Stop: $remote_fs# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Start or stop the HTTP Proxy.### END INIT INFOcase $1 in start) # svnserve -d -r /home/pi/svn_repository python /home/pi/Documents/tips/auto_login.py python /home/pi/Documents/tips/start_note.py python /home/pi/Documents/tips/baidu_weather.py php5 /home/pi/Documents/tips/bind_dns/bind.php pi php5 /home/pi/Documents/tips/bind_dns/bind.php survey ;; stop) killall svnserve ;;*)echo "Usage: $0 (start|stop)";;esac 注：本意是想写一个可以开机自启动的脚本，脚本的目的是登录校园网，然后将本机的IP地址更新到自己的域名中，向linux机器添加开机自启动脚本的方法为： 123456789# 在/etc/init.d/文件夹下添加新的启动脚本，格式参考上面，注意需要加入BEGIN INIT INFO那一段注释，否则在加入启动项时会出现LSB不存在的errorsudo chmod +x 775 name# 给脚本足够运行权限sudo update-rc.d name defaults 95# 将自启动脚本name添加到自启动表项中，启动顺序为95，注意，需要使用网络的脚本顺序要大于90sudo update-rc.d -f name remove# 移除自启动项name 这样既可开机自启动该脚本了 但是在实际运行中发现并不能实现自动的登录以及域名解析的更新，分析了之后发现该脚本启动时间太早，机器还没有分到ip地址，无法完成网络请求，于是将该脚本加入到了/etc/rc.local自启动脚本中，linux系统的脚本启动顺序为： 123456/etc/init.d/ # init.d目录包含许多系统各种服务的启动和停止脚本。/etc/rc.local# 脚本是在系统初始化级别脚本运行之后再执行的，# 因此可以安全地在里面添加你想在系统启动之后执行的脚本。 在rc.local文件中，exit 0之前加入我们的启动脚本 为了保证可以联网，我们在脚本中设置了一个死循环，重复登录直到登录成功 12345678910111213141516while True: try: f = urllib2.urlopen(url, post_data) # `这里完成了向登录页面发送登录POST请求的操作，只有这一步成功完成之后才能进行下一步的绑定域名脚本的执行，如果尚未分配到ip则会进入异常处理等待5秒继续尝试登录` content = f.read() # print content result=urllib.urlopen('http://baidu.com').read() print result print os.popen('sh /home/pi/Documents/bind.sh').read() # 在python中执行shell脚本的方法，这个函数可以输出脚本的输出信息 print "Network is Ready!" break except Exception , e: print e print "Network is not ready,Sleep 5s..." time.sleep(5) python 调用命令行 os.popen这种调用方法可以输出脚本的输出信息,推荐使用 12import osos.popen('sh /home/pi/Documents/bind.sh').read() os.system 会输出一些奇怪的东西 12import osos.system("echo \"Hello World\"") 查看应用安装位置 12345# 查看运行文件所在处which hexo# 查看应用安装位置whereis hexo git 相关 git status 中文乱码问题: git config --global core.quotepath false git gitignore 不起作用: 123git rm -r --cached .git add .git commit -m 'update .gitignore' Mac 下鼠标设置 defaults read -g com.apple.mouse.scaling defaults write -g com.apple.mouse.scaling 7]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[计算机系统结构]指令系统]]></title>
      <url>%2F2017%2F03%2F15%2F%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84-%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F%2F</url>
      <content type="text"><![CDATA[指令系统，寻址方式，内存映射，大端小端，哈夫曼编码，单地址指令，两地址指令 \[\sum_{i=1}^n a_i=0\] 计算机系统的性能评价 时钟频率 指令执行速度 一种经典的表示运算速度的方法 MIPS(Million Instructions Per Second), GIPS, TIPS \[MIPS = \frac{指令条数}{执行时间\times 10^6} = \frac{Fz}{CPI} = IPC \times Fz\] 其中: Fz为处理机的工作主频 CPI(Cycles Per Instruction)为每条指令所需的平均时钟周期数 IPC(Instruction Per Cycle)为每个时钟周期平均执行的指令条数 平均速度 核心程序法 峰值速度]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[密码学]古典密码]]></title>
      <url>%2F2017%2F03%2F14%2F%E5%AF%86%E7%A0%81%E5%AD%A6%2F%E5%AF%86%E7%A0%81%E5%AD%A6-%E5%8F%A4%E5%85%B8%E5%AF%86%E7%A0%81%2F</url>
      <content type="text"><![CDATA[Description：移位密码，凯撒密码，置换密码 移位密码： 加密:ci= (pi+K) mod 26 解密:pi= (ci-K) mod 26 123密钥：整数， 1≤K ≤25 (26个英文字母)加密：明文P中的每个字母被它之后的第K个字母替代解密：密文C中的每个字母被它之前的第K个字母替代 凯撒密码 1当 K=3时，该密码体制成为凯撒密码(Caesar Cipher) 在古罗马的战争(公元前54年)中使用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[密码学]-Exercise1]]></title>
      <url>%2F2017%2F03%2F14%2F%E5%AF%86%E7%A0%81%E5%AD%A6%2F%E5%AF%86%E7%A0%81%E5%AD%A6-Exercise1%2F</url>
      <content type="text"><![CDATA[密码学原理与实践（第二版） p32 1.5 1.16 1.21 1.26 1.29 1.30 1.5 使用穷尽密钥搜索方法破译如下利用移位密码加密的密文 BEEAK FYDJX UQYHY JIQRY HTYJI QFBQD UYJII KFUHC QD 解：移位密码的加解密方法为： 12加密：明文P中的每个字母被它之后的第K个字母替代解密：密文C中的每个字母被它之前的第K个字母替代 为了方便使用python编程完成遍历： 1234567import syspassword='BEEAK FYDJX UQYHY JIQRY HTYJI QFBQD UYJII KFUHC QD'password = password.replace(' ','')for i in range(0,26): for word in password: sys.stdout.write(chr(((ord(word) + i) - 65)%26 + 97)) sys.stdout.write('\n') 输出结果为： 12345678910111213141516171819202122232425260 beeakfydjxuqyhyjiqryhtyjiqfbqduyjiikfuhcqd1 addzjexciwtpxgxihpqxgsxihpeapctxihhjetgbpc2 zccyidwbhvsowfwhgopwfrwhgodzobswhggidsfaob3 ybbxhcvagurnvevgfnoveqvgfncynarvgffhcrezna4 xaawgbuzftqmudufemnudpufembxmzqufeegbqdymz5 wzzvfatyespltctedlmtcotedlawlypteddfapcxly6 vyyuezsxdroksbsdcklsbnsdckzvkxosdccezobwkx7 uxxtdyrwcqnjrarcbjkramrcbjyujwnrcbbdynavjw8 twwscxqvbpmiqzqbaijqzlqbaixtivmqbaacxmzuiv9 svvrbwpuaolhpypazhipykpazhwshulpazzbwlythu10 ruuqavotznkgoxozyghoxjozygvrgtkozyyavkxsgt11 qttpzunsymjfnwnyxfgnwinyxfuqfsjnyxxzujwrfs12 pssoytmrxliemvmxwefmvhmxwetperimxwwytivqer13 orrnxslqwkhdlulwvdeluglwvdsodqhlwvvxshupdq14 nqqmwrkpvjgcktkvucdktfkvucrncpgkvuuwrgtocp15 mpplvqjouifbjsjutbcjsejutbqmbofjuttvqfsnbo16 lookupintheairitsabirditsaplaneitssuperman17 knnjtohmsgdzhqhsrzahqchsrzokzmdhsrrtodqlzm18 jmmisnglrfcygpgrqyzgpbgrqynjylcgrqqsncpkyl19 illhrmfkqebxfofqpxyfoafqpxmixkbfqpprmbojxk20 hkkgqlejpdawenepowxenzepowlhwjaepooqlaniwj21 gjjfpkdioczvdmdonvwdmydonvkgvizdonnpkzmhvi22 fiieojchnbyuclcnmuvclxcnmujfuhycnmmojylguh23 ehhdnibgmaxtbkbmltubkwbmltietgxbmllnixkftg24 dggcmhaflzwsajalkstajvalkshdsfwalkkmhwjesf25 cffblgzekyvrzizkjrsziuzkjrgcrevzkjjlgvidre 查看输出的26条结果，发现lookup in the air its a bird its a plane its superman是其中有意义的语句，相应秘钥为K=16]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[搜索引擎]性能评价]]></title>
      <url>%2F2017%2F03%2F14%2F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%2F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-%E6%80%A7%E8%83%BD%E8%AF%84%E4%BB%B7%2F</url>
      <content type="text"><![CDATA[搜索引擎性能评价的目的 对用户而言： 信息获取渠道 对搜索引擎广告商而言 对搜索技术研究人员而言 对搜索引擎服务提供者 从较差查询样例中学习 链接锚本重定向问题 清华美院 团、派 搜索引擎性能评价流程 1.1 搜索引擎性能评价的对象 网络服务提供商的属性 市场占用率、 网络信息检索工具属性 网络数据环境、用户群体 搜索引擎运行效果 响应时间 耗费的硬件资源 是否满足用户的信息需求 用户获取信息耗费的时间成本？ 根据用户的需求调整响应时间和查询质量？ 1.2 搜索引擎性能评价的Cranfield体系 黑箱评价方式：给定标准输入情况下，看系统输出与标准输出的差异 输入:语料库，查询样例、相关性标注 优势：复用性（一次标注，多次使用） 语料库采集 信息检索系统：提供固定的语料库集合，集合规模适当，数据质量可靠 商业搜索引擎：不提供固定的语料库集合，评价数据抓取子系统性能 查询样例集合构建 用户查询规模庞大 核心问题：如何采样：真实性，精确性，全面性 查询采样的真实性：反映用户实际需求 来源：用户查询日志行为（日志隐私保护）、公开数据资源 查询采样的精确性：减少数据标注困难 查询采样的全面性：综合评价各方面性能 少量查询样例代表大多数需求 采样依据：内容类别、热门程度、需求类型 查询信息需求决定了用户使用搜索引擎的满意度，数据环境复杂用户意图难以琢磨 搜索引擎用户信息需求分布： 导航类：查询某个已知存在的资源，页面 主页，考试资源等等 信息类：查询与某个主题相关的关键信息资源 获取相关信息，没有确定查询目标， 香港股市，，， 事务类：查找与完成某个特定任务相关的资源 垂直搜索引擎服务对象 如：xxx下载， 保证采样全面性：查询热门程度（冷热保证） 查询信息需求（2：5：3） 结果相关性标注 内容相关≠关键资源 相关性结果的共性要求： 结果提供的学习时新、真实可靠 结果的标题和摘要应当方便阅读并有效引导用户阅读 以信息需求类别为指导 Pooling 方法 文本语料=》查询样例集 》 手工相关性标注 准确率/召回率 准确率：找到的是否准确 召回率：找到的是否全面 信息检索强调序列的关系 搜索引擎性能指标设计 AP：平均准确率 搜索引擎用户行为的特殊性 前10个结果（85%） 搜索引擎用户信息需求的差异性 • 导航类信息需求的用户仅关注特定检索目标 • 信息类信息需求的用户关注全面而权威的信息 • 事务类信息需求的用户关注自己的任务是否可以顺利完成。 指标 适用 描述 RR 导航类 用户在找到搜索目标前需要浏览多少结果 P@N 信息类 结果列表中多大比例信息能够满足用户需求？ MAP 反映系统在全部相关文档上性能的单值指标。系统检索出来的相关文档越靠前(rank 越高)，MAP就应该越高 前n位成功率 事务类 用户是否能够利用给出的结果完成自己所关注的事务 首位相关结果倒数(Reciprocal Rank) \[RR = \frac{1}{Rank(1)}\] 适用于导航类型的查询信息需求（ 用户在找到搜索目标前需要浏览多少结果？ ） 前N位准确率(Precision@N) 适用于信息类型的查询信息需求（ 结果列表中多大比例信息能够满足用户需求？ ） 前N位成功率(Success@N) 适用于事务类型的查询信息需求（ 用户是否能够利用给出的结果完成自己所关注的事务？ ） 其他 NDCG@N: • Normalized Discounted Cumulative Gain • 对结果进行多级相关性标注时适用 • ERR: Expected Reciprocal Rank • Supported by Yahoo! and Google • 可以获取用户行为数据时适用 • B-pref: Binary preference • 相关性标注不完整时适用 P@N的计算方法 P@N本身是Precision@N的简称，指的是对特定的查询，考虑位置因素，检测前N条结果的准确率。例如对单次搜索的结果中前5篇，如果有4篇为相关文档，则P@5 = 4/5 = 0.8 。 测试通常会使用一个查询集合（按照前文所述方法构造），包含若干条不同的查询词，在实际使用P@N进行评估时，通常使用所有查询的P@N数据，计算算术平均值，用来评判该系统的整体搜索结果质量。 N的选取 对用户来说，通常只关注搜索结果最前若干条结果，因此通常搜索引擎的效果评估只关注前5、或者前3结果，所以我们常用的N取值为P@3或P@5等。 对一些特定类型的查询应用，如寻址类的查询（Navigational Search），由于目标结果极为明确，因此在评估时，会选择N=1（即使用P@1）。举个例子来说，搜索“新浪网”、或“新浪首页”，如果首条结果不是 新浪网（url：www.sina.com.cn），则直接判该次查询精度不满足需求，即P@1=0 MRR 平均倒数排序 MRR是平均排序倒数（Mean Reciprocal Rank）的简称，MRR方法主要用于寻址类检索（Navigational Search）或问答类检索（Question Answering），这些检索方法只需要一个相关文档，对召回率不敏感，而是更关注搜索引擎检索到的相关文档是否排在结果列表的前面。 MRR方法首先计算每一个查询的第一个相关文档位置的倒数，然后将所有倒数值求平均。 MRR 上述的P@N方法，易于计算和理解。但细心的读者一定会发现问题，就是在前N结果中，排序第1位和第N位的结果，对准确率的影响是一样的。但实际情况是，搜索引擎的评价是和排序位置极为相关的。即排第一的结果错误，和第10位的结果错误，其严重程度有天壤之别。因此在评价系统中，需要引入位置这个因素。 MRR是平均排序倒数（Mean Reciprocal Rank）的简称，MRR方法主要用于寻址类检索（Navigational Search）或问答类检索（Question Answering），这些检索方法只需要一个相关文档，对召回率不敏感，而是更关注搜索引擎检索到的相关文档是否排在结果列表的前面。MRR方法首先计算每一个查询的第一个相关文档位置的倒数，然后将所有倒数值求平均。例如一个包含三个查询词的测试集，前5结果分别为： 查询一结果：1.AN 2.AR 3.AN 4.AN 5.AR 查询二结果：1.AN 2.AR 3.AR 4.AR 5.AN 查询三结果：1.AR 2.AN 3.AN 4.AN 5.AR 其中AN表示不相关结果，AR表示相关结果。那么第一个查询的排序倒数（Reciprocal Rank）RR1 = 1/2=0.5 ；第二个结果RR2 = 1/2 = 0.5 ； 注意倒数的值不变，即使查询二获得的相关结果更多。同理，RR3= 1/1 = 1。 对于这个测试集合，最终MRR=（RR1+RR2+RR3）/ 3 = 0.67 然而对大部分检索应用来说，只有一条结果无法满足需求，对这种情况，需要更合适的方法来计算效果，其中最常用的是下述MAP方法。 MAP MAP方法是Mean Average Precison，即平均准确率法的简称。其定义是求每个相关文档检索出后的准确率的平均值（即Average Precision）的算术平均值（Mean）。这里对准确率求了两次平均，因此称为Mean Average Precision。（注：没叫Average Average Precision一是因为难听，二是因为无法区分两次平均的意义） MAP 是反映系统在全部相关文档上性能的单值指标。系统检索出来的相关文档越靠前(rank 越高)，MAP就应该越高。如果系统没有返回相关文档，则准确率默认为0。 MAP:全称mean average precision(平均准确率)。mAP是为解决P，R，F-measure的单点值局限性的，同时考虑了检索效果的排名情况。 计算如下： 假设有两个主题，主题1有4个相关网页，主题2有5个相关网页。某系统对于主题1检索出4个相关网页，其rank分别为1, 2, 4, 7；对于主题2检索出3个相关网页，其rank分别为1,3,5。对于主题1，平均准确率为(1/1+2/2+3/4+4/7)/4=0.83。对于主题 2，平均准确率为(1/1+2/3+3/5+0+0)/5=0.45。则MAP=(0.83+0.45)/2=0.64。”]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello Hexo]]></title>
      <url>%2F2017%2F03%2F14%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new "My New Post" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy 草稿 草稿相当于很多博客都有的“私密文章”功能。 1$ hexo new draft "new draft" 会在source/_drafts目录下生成一个new-draft.md文件。但是这个文件不被显示在页面上，链接也访问不到。也就是说如果你想把某一篇文章移除显示，又不舍得删除，可以把它移动到_drafts目录之中。 如果你希望强行预览草稿，更改配置文件： 1render_drafts: true 或者，如下方式启动server： 1$ hexo server --drafts 下面这条命令可以把草稿变成文章，或者页面： 1$ hexo publish [layout] &lt;filename&gt; More info: Deployment MathJax MathJax 常用命令 mathjax 常用 推荐 手写识别 修复公式不正常 在blog文件夹中执行： 1$ hexo math install 在_config.yml文件中添加： 12plugins:- hexo-math 使用 1Simple inline $a = b + c$. 效果： Simple inline \(a = b + c\). MathJax Block: 1234$$\frac&#123;\partial u&#125;&#123;\partial t&#125;= h^2 \left( \frac&#123;\partial^2 u&#125;&#123;\partial x^2&#125; +\frac&#123;\partial^2 u&#125;&#123;\partial y^2&#125; +\frac&#123;\partial^2 u&#125;&#123;\partial z^2&#125;\right)$$ 效果： \[\frac{\partial u}{\partial t} = h^2 \left( \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} + \frac{\partial^2 u}{\partial z^2}\right)\] 为Hexo Next博客添加关键词功能 修改文件：themes_partials.swig 1234567&#123;% if page.keywords %&#125; &lt;meta name="keywords" content="&#123;&#123; page.keywords &#125;&#125;" /&gt;&#123;% elif page.tags and page.tags.length %&#125; &lt;meta name="keywords" content="&#123;% for tag in page.tags %&#125;&#123;&#123; tag.name &#125;&#125;,&#123;% endfor %&#125;" /&gt;&#123;% elif theme.keywords %&#125; &lt;meta name="keywords" content="&#123;&#123; theme.keywords &#125;&#125;" /&gt;&#123;% endif %&#125; 修改内容：35行左右，将原来的设置ketwords的代码覆盖即可 1234567&#123;% if page.keywords and page.keywords.length %&#125; &lt;meta name="keywords" content="&#123;% for key in page.keywords %&#125;&#123;&#123; key &#125;&#125;,&#123;% endfor %&#125;" /&gt;&#123;% elif page.tags and page.tags.length %&#125; &lt;meta name="keywords" content="&#123;% for tag in page.tags %&#125;&#123;&#123; tag.name &#125;&#125;,&#123;% endfor %&#125;" /&gt;&#123;% elif theme.keywords %&#125; &lt;meta name="keywords" content="&#123;&#123; theme.keywords &#125;&#125;" /&gt;&#123;% endif %&#125;]]></content>
    </entry>

    
  
  
</search>
