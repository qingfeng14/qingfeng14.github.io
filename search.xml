<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[系统结构第二次实验:设计实现 Tomasulo 调度算法]]></title>
      <url>%2F2017%2F06%2F07%2FTomasulo%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[实验原理 Tomasulo 算法以硬件方式实现了寄存器重命名，允许指令乱序执行，这是提高流水线的吞吐率和效率的一种有效方式。该算法首先出现在 IBM360/91 处理机的浮点处理部件中，后广泛应用于现代处理器设计中。 假设浮点处理部件结构如下图所示。浮点处理部件从取指单元接收指令，存入浮点操作队列。浮点操作队列每拍最多发射1条指令给浮点加法器或浮点乘除法器。 浮点处理部件包含一个浮点加法器和一个浮点乘除法器。浮点加法器为两段流水线，输入端有三个保留站A1、A2、A3，浮点乘除法器为六段流水线，输入端有两个保留站M1，M2。当任意一个保留站中的两个源操作数到齐后，如果对应的操作部件空闲，可以把两个操作数立即送到浮点操作部件中执行。Load Buffer和Store Buffer各缓存三条访存操作。 实现要求 设计实现 Tomasulo 算法模拟器，要求： Tomasulo 算法模拟器能够执行浮点加、减、乘、除运算及 LOAD 和 STORE 操作。为了保持一致性，我们小组采用了【教科书上的指令格式】 指令格式 指令说明 指令执行周期 保留站/缓冲队列项数 ADDD F1,F2,F3 F1,F2,F3为浮点寄存器，寄存器至少支持F0~F10 2个周期 3 SUBD F1,F2,F3 同上 2个周期 3 MULD F1,F2,F3 同上 10个周期 2 DIVD F1,F2,F3 同上 40个周期 2 LD F1, NUM, R1 F1为寄存器，NUM 为偏移量，R1为基地址 2个周期 3 ST F1, NUM, R1 同上 2个周期 3 支持单步执行及连续执行(n 条指令)，实时显示算法的运行状况，包括各条指令的运行状态、各寄存器以及内存的值、保留站(Reservation Stations)状态、Load Buffer 和 Store Buffer 缓存的值等; 程序执行完毕后，能够显示指令执行周期数等信息; 为了简化设计，建议模拟器 供编辑内存值功能，以便实现数据输入;浮点除法可不做除 0 判断; 能够以文本方式输入指令序列。 显示界面自由设计，下图仅供参考: 完成内容 能够以文件方式导入指令 能够以文本框编辑方式编辑指令 能够设置FU,RU寄存器的初始值 能够编辑内存值 能够设置实时显示内存内容的起始内存地址（5个） 支持单步和多步连续执行 程序执行完毕后，能够显示指令执行周期数等信息 实现设计思路 后台 算法框架和基本流程 模拟环境: 我们用一次循环来代表一次始终周期,每次循环始终加一. 对于每个时钟周期(一个节拍),一条指令最多只能被执行发射,执行,或者写入中的一种操作(若所需运算数据未就绪,所需运算器件未就绪均会阻塞).即对于一条需要2个周期来执行运算的加法指令,共需要至少1+2+1=4个周期,其运算结果才会被写入目的寄存器. 我们将Load/Store缓冲区和保留站统一处理,即缓冲区和保留站均有Qi,Qj,Vi,Vj,A等数据信息.对于Load保留站,其Qi始终为0,即Vi始终就绪,Vj为计算所得的地址;对于Store缓冲区,其Vi为所要存储的数据,Vj为通过整数寄存器计算所得的地址. 算法流程: 系统在完成初始化后，会将指令按给定的序列加入指令队列,即在UI界面点击开始后,程序会根据给定的指令序列自动初始化指定队列。接下来,对于每一个时钟周期会进行如下操作 (1)发射指令 对于位于指令队列队首的指令，我们先寻找其对应的空闲保留站，若存在，则发射该指令到对应的保留站，更新该保留站的数据信息(包括busy,Vi,Vj,Qi,Qj,A),并更新要写入寄存器的状态.若不存在空闲站,则队首指令将无法流出，该指令会停留在队首等待下个周期。当指令队列清空时,说明所有指令已经流出,不再发射指令. (2)执行流水线 我们共提供了三条流水线分别处理访存(根据课件认为是一个2段流水线,每段1周期)、加减法、乘除法指令，每条流水线有自己的流水段和相应的各段周期。每条位于保留站的指令必须在其所需数据均准备好才能进入对应的流水线进行执行.(对于Load指令来说,所需数据为整型寄存器所表示的基址,对于Store指令来说,所需数据出了基址还有要存储的数据) 指令进入流水线后,我们通过如下两个过程来模拟流水线运行流程: 新指令进入流水线 当保留站中缓存的指令要进入对应的流水线时必须满足两个条件：一,流水线当前进行的运算能够执行该指令（即乘法指令要进入乘除法器的流水线时，必须保证没有除法指令在执行，我们认为加减法和访存不需要改变运算器的功能逻辑,因此加法和减法进入加法器流水线以及访存指令进入访存流水线时没有该要求）;二,对应流水线首段空闲,即流水线首段没有指令在占用。 更新流水线上各个段的指令 对于每个段的指令，我们会递减其需要的执行周期。当剩余周期为0时，说明该段运算完成，需要进入下一流水段继续运算，此时若下一流水段空闲，则直接进入下一流水段,否则阻塞等待直到其空闲为止，在此期间会持续占用原有流水段。若当前完成段为流水线最后一段，则进行结果运算，并记录结果到对应的保留站，等待写入(对于Store指令我们在此时更新相应的内存)同时释放对流水段的占有。 (3)写入数据： 对于每条完成的指令(除了Store指令)，我们会将其结果写入对应的寄存器并更新相应的订阅的保留站的等待数据。我们假设总线在一个周期内可以完成多次数据传输，即对于同一个周期内要进行多条指令的写回时，我们按照顺序将其结果更新到对应的位置，Tomasulo算法保证了该过程不会触发数据相关的错误。 算法状态显示: 在指令的每个时期(发射,执行完毕,写回完毕)完成后，我们会记录对应指令的完成时间，并更新到前台。 在完成每个周期的操作后,我们将保留站和寄存器以及指令的执行信息更新到前台，以供观察。 主要数据结构: 我们通过4个主要的数据结构来执行该算法. 寄存器class Register:维护了寄存器的数据和状态信息Qi 指令class Inst: 维护了指令的操作码,操作数,目的地址,指令的运行状态,指令发射,运算完毕,写回的时间 保留站class ReservationStation: 保留站是关键的数据结构,它维护了保留站的基本数据信息(op,busy,vj,vk,qj,qk,A,result).此外还维护了便于观察保留站状态的各种数据: execover//保留站所缓存的指令是否已经运算完成 status//保留栈所缓存指令的状态,包括(发射,等待数据,等待运算器相应的流水段空闲,正在运算,运算完毕,保留站空闲) times: 所缓存的指令还需要在运算器运算的总周期数(不包括等待流水段的时间) 流水线模拟器class Pipeline: 流水线模拟器维护了各个流水段需要的运行周期,各个流水段正在运行的指令和其所需的剩余的运算时间.我们设计实现的流水线有以下性质: 对于n段流水线,最多同时支持n条指令在其中运行 当第i条指令完成第k段流水段运算后,若第i-1条指令还占据第k+1段流水段,则第i条指令会阻塞并持续占用第k段流水段. 当第i条指令未完成第k段流水段运算时,其不会受其他段指令的影响,即第i+1条指令或者i-1条指令阻塞时,第i条指令能继续进行第k段的运算. 流水线支持功能切换,即可以切换流水段数量和每段的周期数,以此支持乘除法周期数不一致的要求.但功能切换必须在流水线中所有指令全部流出时才能进行.即若一条除法指令想进入流水线,必须在流水线处理完所有的乘法运算后切换成除法模式后才能进入. 对于系统默认的参数,我们将访存处理和加法减法处理设计为了2段流水线,每段1周期. 对于乘法为6段流水线.分别为1,1,2,4,1,1周期. 对于除法为6,6,6,6,6,10周期(参数可以在代码中重新自由设置,如设置为Firgure.A31所示的流水线) 前端 程序运行时主窗口如下图所示 程序主界面 如【图 程序主界面】所示，前端的实现中界面采用GridBagLayout()布局模式，顶部是10个操作按钮，点击即可完成对应的设置和执行功能。 其下方依次是指令队列状态展示区，当前周期展示区，内存展示区，保留站状态信息，浮点寄存器状态信息，整型寄存器展示区。 下面一次展示其各个部分的运行方式 从文件导入指令 点击【导入指令文件】按钮，即可进入指令文件选择界面，点击open按钮，默认打开当前工作目录，选择示例代码文件example.txt,点击导入即可导入指令，指令队列展示区会做出对应的更新。 从文件导入指令 文本框方式编辑指令 点击【编辑指令】按钮，即可进入指令编辑界面。指令编辑完成后点击确认即可导入编辑的指令，指令队列展示区会做出对应的更新。 文本框方式编辑指令 设置内存 点击【内存赋值】按钮，即可进入内存编辑界面，在第一个框中输入内存地址(0~4096), 第二个输入框中输入内存值，点击赋值按钮，若输入合法则会更新对应地址处内存。点击关闭按钮退出内存编辑界面。 设置内存 设置内存显示 点击【内存显示】按钮，即可设置内存展示的起始地址(0~4091),输入合法时点击确认即可更新内存展示区。 内存显示设置 多步执行设置 点击【步数设置】按钮，即可进行多步运行步数设置。 步长设置 寄存器设置 点击【设置寄存器】按钮，即可进入寄存器设置界面，页面中可进行FU0~FU10, RU0~RU10，共22个寄存器的初始值的设置，设置完成后点击保存若输入合法即可完成更改，输入不合法时保持当前值。 寄存器设置 程序运行 初始或点击【重置】按钮时是初始状态，此时可进行指令的导入，编辑，内存赋值，寄存器赋值，步长设置，内存显示设置等功能，点击执行后，即进入执行状态，此时部分设置按钮不可点击，即不可再进行更改指令，设置内存，设置寄存器等操作。此时若点击【步进】按钮，程序则会运行一步，点击执行n步（n可点击【步数设置】按钮进行设置）即可执行多步（n步）, 每一次步进都会更新对应部件状态展示区，程序运行结束后则不可继续点击【步进】，【执行n步】按钮。 运行效果图 程序运行说明： 在项目根目录下运行sh run.sh即可，或者在在命令行中输入如下编译运行指令 123mkdir binjavac -d bin/ src/com/company/UI.java src/com/company/Main.javajava -cp bin/ com.company.UI 项目文件说明 12345678910111213.├── README.md 运行说明├── Report.md 实验报告(MD版)├── Tomasulo调度算法实验报告.pdf 实验报告PDF版├── example_book.txt 教科书中的示例├── example_阻塞等待指令序列.txt 会在流水线各个段发生阻塞等待指令序列 ├── example_RAW相关的ST指令序列.txt 有 RAW 相关的 ST 指令序列├── run.sh 项目编译运行脚本└── src └── com └── company ├── Main.java 后台代码 └── UI.java 前端代码 运行实例 对于课件中所给的样例指令序列: 123456LD F6, 34, R2LD F2, 45, R3MULD F0, F2, F4SUBD F8, F6, F2DIVD F10, F0, F6ADDD F6, F8, F2 我们得到的指令队列状态与课件中相同: 指令 发射指令时间 执行完成时间 写入结果时间 LD F6,34,R2 1 3 4 LD F2,45,R3 2 4 5 MULD F0,F2,F4 3 15 16 SUBD F8,F6,F2 4 7 8 DIVD F10,F0,F6 5 56 57 ADDD F6,F8,F2 6 10 11 运行结束需要57个周期与课件一致 对于有RAW相关的ST指令序列: 123ST F1,0,R2MULD F0, F2, F4ST F0,4,R0 也能得到正确结果: 指令 发射指令时间 执行完成时间 写入结果时间 ST F1,0,R2 1 3 4 MULD F0,F2,F4 2 12 13 ST F0,4,R0 3 15 16 对于会在流水线各个段发生阻塞等待指令序列: 123456DIVD F6, F0, F4MULD F2, F1, F5MULD F0, F6, F4SUBD F8, F6, F2DIVD F10, F0, F6ADDD F6, F8, F2 我们也能得到正确的结果: 指令 发射指令时间 执行完成时间 写入结果时间 DIVD F6,F0,F4 1 41 42 MULD F2,F1,F5 2 51 52 MULD F0,F6,F4 43 55 56 SUBD F8,F6,F2 44 54 55 DIVD F10,F0,F6 53 96 97 ADDD F6,F8,F2 54 57 58 在该例子中前三条指令间存在结构冲突,由于除法在流水线中执行时,新来的乘法指令必须等待除法指令完成才能进入流水线,因此乘法指令完成时的时钟周期为51(42进入首段,51完成最后一段). 另外由于保留站占满,第三条乘法指令等到43周期才被发射. 对于第三条乘法指令,由于乘法流水线各个段的运行周期为(1,1,2,4,1,1),第三条指令会在第三段完成后阻塞等待2个时钟周期,以等待第二条乘法指令完成第4段,因此第三条乘法指令的执行完成时间为55(44进入,55完成,共用12个周期,比第二条慢了2(慢2周期进入)+2(期间等待2周期)=4个周期而不是2个周期,在第48,49会看到对应的保留站状态为WAIT_ALU意为等待处理器)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[校园搜索引擎]]></title>
      <url>%2F2017%2F06%2F03%2F%E6%A0%A1%E5%9B%AD%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%2F</url>
      <content type="text"><![CDATA[内容 综合运用搜索引擎体系结构和核心算法方面的知识，基于开源资源搭建搜索引擎 开源搜索引擎工具资源： Heritrix 1.14.4 Lucene 4.0 分词工具： IK Analyzer 2012 Html解析：Jsoup 1.7.2 PDF 解析：pdfbox 1.8.1 Doc 解析：poi 3.16 前端服务：apache+tomcat (http://tomcat.apache.org/) 实验要求 抓取清华校内绝大部分网页资源以及大部分在线万维网文本资源（含M.S.office文档、pdf文档等，约20-30万个文件） 实现基于概率模型的内容排序算法； 实现基于HTML结构的分域权重计算，并应用到搜索结果排序中； 实现基于PageRank的链接结构分析功能，并应用到搜索结果排序中； 采用便于用户信息交互的Web界面。 实现流程 爬虫爬取清华校内网页数据 Heritrix抓取对象 Heritrix环境搭建教程 清华新闻网网页（不包括图书馆）资源 种子http://news.tsinghua.edu.cn/ 使用正则表达式对URL进行过滤 过滤无关页面，过滤无关格式文件，，保留html页面和pdf,word文档，去除奇怪链接： 1.*(?i)\.(mso|tar|txt|asx|asf|bz2|mpe?g|MPE?G| tiff?|gif|GIF|png|PNG|ico|ICO|css|sit|eps|wmf|zip|pptx?|xlsx?|gz|rpm|tgz|mov|MOV|exe|jpe?g|JPE?G|bmp|BMP|rar|RAR|jar|JAR|ZIP|zip|gz|GZ|wma|WMA|rm|RM|rmvb|RMVB|avi|AVI|swf|SWF|mp3|MP3|wmv|WMV|ps|PS|d|dd|yyyy|nivo-nextNav|xiao_ming)$ 禁止抓取图书馆资源： [\S]*lib.tsinghua.edu.cn[\S]*；[\S]*166.111.120.[\S]* 只抓取清华新闻网的数据 [\S]*news.tsinghua.edu.cn[\S]*； Module设置，参考PPT中的设置进行 Heritrix 抓取过程中遇到的问题 页面剔除问题 在一开始的抓取过程中发现了部分奇怪的页面，如图[Heritrix 异常页面]所示，发现了很多以yyyy.MM.dd、yyyy.M.d、MM.dd.yyyy、a.nivo-nextNav 为结尾的奇怪链接，后来经过分析清华新闻网的源码，发现这些链接都是js代码里的内容，虽然已经在配置中设定为不从css,js等域中获取超链接，但是仍然会得到这样的url, 因此后来在正则表达式中加上了d|dd|yyyy|nivo-nextNav|xiao_ming字段进行过滤，最终得到的页面有52769个，共2.3G Heritrix 异常页面 Heritrix 加速问题 在抓取页面过程中，第一次尝试时发现抓取速度特别慢，爬取整整一个晚上只能获取300MB的数据，通过查询相关资料尝试了很多加速方法，最终在博客Heritrix提高抓取效率的若干尝试 {http://blog.csdn.net/yangding_/article/details/41122977} 找到Heritrix抓取速度特别慢的原因：heritrix在抓取时一般只运行了一个线程。这是因为在默认的情况下，Heritrix使用HostnameQueueAssignmentPolicy来产生key值，而这个策略是用hostname作为key值的，因此一个域名下的所有链接都会被放到同一个线程中去。如果对Heritrix分配URI时的策略进行改进，利用ELFhash算法把url尽量平均分部到各个队列中去，就能够用较多的线程同时抓取一个域名下的网页，速度将得到大大的提高。 12345678910111213141516171819202122@Override//重写 getClassKey()方法public String getClassKey(CrawlController controller, CandidateURI cauri) &#123; String uri = cauri.getURI().toString(); long hash = ELFHash(uri);//利用 ELFHash 算法为 uri 分配 Key 值 String a = Long.toString(hash % 50);//取模 50，对应 50 个线程 return a;&#125;public long ELFHash(String str)&#123; long hash = 0; long x = 0; for(int i = 0; i &lt; str.length(); i++) &#123; hash = (hash &lt;&lt; 4) + str.charAt(i);//将字符中的每个元素依次按前四位与上 if((x = hash &amp; 0xF0000000L) != 0)//个元素的低四位想与 &#123; hash ^= (x &gt;&gt; 24);//长整的高四位大于零，折回再与长整后四位异或 hash &amp;= ~x; &#125; &#125; return (hash &amp; 0x7FFFFFFF); &#125; 按照该教程完成代码的修改之后，重新运行，抓取速度得到了大幅提升，4个半小时的时间完成了清华新闻网的页面抓取工作。 未修改hash函数时爬取速度 修改代码后的爬取速度明显加快 数据清洗及PageRank计算 在实验过程中我们需要使用页面的PageRank值来对网页进行打分，因此需要对抓取的数据计算其PageRank值，由于Heritrix在抓取时就已经有了crawl.log文件用于记录抓取到的网页链接及访问信息，因此在计算PageRank时直接使用了该文件的记录信息。 预处理及PageRank计算 12345├── clean_page.py : 页面清洗，├── parse_graph_title_anchor.py ： ├── share.py : 一些共有的文件名记录，html页面处理函数└── tsinghua_rank.py ： 计算PageRank值，结果保存到pagerank.txt中└── crawl.log : Heritrix 抓取的结果记录 需要注意的是，由于 Heritrix 在抓取带 GET 请求的网页时，存储文件的文件名和网址URL并不能一一对应(其去掉了问号，挪动了文件类型的位置)，且单从文件名并不能找到对应的 URL，所以第一步分析Heritrix爬取日志是必要且是必须的。通过分析日志，得到了URL到文件名的双向映射，同时删除了 404网页，将网页个数减少到 52205个页面。 在提取链接、标题、anchor时一开始使用的是BeautifulSoup进行提取，后来发现这种方式太慢，于是手动使用正则表达式进行提取。 123href_pattern = re.compile(r'&lt;a href=[\"\']([^\"\']*?\.(html|pdf|doc|docx))[\"\'].+?&gt;(.+?)&lt;/a&gt;', re.S)html_pattern = re.compile(r'&lt;a href=[\"\']([^\"\']*?\.html)[\"\']', re.S)title_pattern = re.compile(r'&lt;title&gt;(.+?)&lt;/title&gt;', re.I | re.M | re.S) 计算完成之后的PageRank值如下所示： 排名前10的页面 12345678910 /publish/thunews/index.html 0.0563122679453 首页 清华大学新闻网/publish/thunews/9652/index.html 0.0448806058384 更多 &amp;#8250; 清华大学新闻网 - 图说清华/publish/thunewsen/index.html 0.0384040176156 ENGLISH Tsinghua University News/publish/thunews/9650/index.html 0.0257207878312 媒体清华 清华大学新闻网 - 媒体清华/publish/thunews/10303/index.html 0.0257202750476 综合新闻 清华大学新闻网 - 综合新闻/publish/thunews/9656/index.html 0.0250196913473 清华人物 清华大学新闻网 - 清华人物/publish/thunews/9649/index.html 0.02500709101 要闻聚焦 清华大学新闻网 - 要闻聚焦/publish/thunews/9657/index.html 0.0249803912605 新闻合集 清华大学新闻网 - 新闻合集/publish/thunews/10304/index.html 0.0249798815124 新闻排行 清华大学新闻网 - 新闻排行/publish/thunews/9655/index.html 0.0243158953181 专题新闻 清华大学新闻网 - 专题新闻 新闻页前10 123456789101112 /publish/thunews/9648/2017/20170520203232435687344/20170520203232435687344_.html 0.00197507591613 邱勇出席第二届中以创新论坛：畅谈国际创新创业教育合作 邱勇出席第二届中以创新论坛：畅谈国际创新创业教育合作/publish/thunews/9648/2017/20170518115011788320647/20170518115011788320647_.html 0.00197507591613 清华医学院程功研究组揭示寨卡病毒感染暴发机制 清华医学院程功研究组揭示寨卡病毒感染暴发机制/publish/thunews/9648/2017/20170519190126950804131/20170519190126950804131_.html 0.00197507591613 邱勇会见以色列总统鲁文·里夫林·接受以色列特拉维夫大学荣誉博士学位 邱勇会见以色列总统鲁文·里夫林·接受以色列特拉维夫大学荣誉博士学位/publish/thunews/9648/2017/20170522184445768862282/20170522184445768862282_.html 0.00197507591613 清华大学新闻与传播学院举办纪念成立15周年系列活动 清华大学新闻与传播学院举办纪念成立15周年系列活动/publish/thunews/9648/2017/20170515184412579525281/20170515184412579525281_.html 0.00197507591613 清华大学全球可持续发展研究院正式揭牌成立 清华大学全球可持续发展研究院正式揭牌成立/publish/thunews/9648/2017/20170516121327519550489/20170516121327519550489_.html 0.00197507591613 清华微电子所钱鹤、吴华强课题组在基于新型忆阻器阵列的类脑计算取得重大突破 清华微电子所钱鹤、吴华强课题组在基于新型忆阻器阵列的类脑计算取得重大突破/publish/thunews/9652/2017/20170307133841881904789/20170307133841881904789_.html 0.00193350555685 【组图】最美三月女生节 浪漫创意盈满“幅” 【组图】最美三月女生节 浪漫创意盈满“幅”/publish/thunews/9652/2017/20170314142112142471080/20170314142112142471080_.html 0.00193350555685 【组图】春到绿茵场 马杯足球赛正酣 【组图】春到绿茵场 马杯足球赛正酣/publish/thunews/9945/2017/20170524164751321376872/20170524164751321376872_.html 0.00143223231223 5月18日，以“一带一路低碳前行”为主题的第十二届世界低碳城市联盟大会暨低碳城市发展论坛在三亚召开。 ... 2017-05-24 清华共同主办第十二届世界低碳城市联盟大会/publish/thunews/9945/2017/20170524113049223303463/20170524113049223303463_.html 0.00143197048315 2017年“共和国的脊梁——科学大师名校宣传工程”汇演在重庆大学启动。清华大学原创话剧《马兰花开》被 ... 2017-05-24 清华原创话剧《马兰花开》在科学大师名校宣传工程汇演上首演/publish/thunews/9945/2017/20170522171134178522272/20170522171134178522272_.html 0.00143197048315 5月19日晚，清华大学巅峰对话第二十期物理分论坛在清华大学举行。本次活动邀请了2015年诺贝尔物理学 ... 2017-05-23 诺贝尔物理学奖得主梶田隆章做客“巅峰对话”/publish/thunews/9945/2017/20170524093408535456498/20170524093408535456498_.html 0.00143197048315 5月18日—21日，清华大学第一附属医院党委书记类延旭和副院长朱栓立带领一附院医疗分队走进昆明市东川 ... 2017-05-24 清华大学第一附属医院走进昆明健康义诊 由PageRank计算结果可以发现，正常的新闻页面的PageRank值大多在\(10^{-6} ~10^{-4}\)之间，如果直接将该PageRank值与BM25算法的得分相乘会导致PageRank值高的页面，即使关键词出现次数少，也会在最终排名中特别靠前，为了减少其影响，在将PageRank值应用到Score计算时对PageRank值进行压缩\[newPageRank = 16 + ln(PageRank)\] 构建索引及倒排索引 文档解析 Html解析 网页文件元素十分丰富。实验中使用Jsoup工具包解析网页，抽取title标签的文本内容作为文档的的标题域；抽取p、span、td、div、li、a标签的文本内容作为文档的内容域；a标签的内容表示页面链出的内容，也作为一个域单独索引；h1-h6标签的文本内容表示页面内的小标题，拿出来作为一个域；此外，进入页面的链接有着和页面标题相似的作用，单独成为一个域。 PDF解析 PDF的元素不易区分，实验中使用pdfbox解析文件获得内容域，直接以文件名作为标题域。 Doc解析 Doc文件与PDF文件类似，实验中使用POI包解析文件获得内容域，直接以文件名作为标题域。需要注意的是，POI工具解析.doc文件.docx文件的方法并不一样，在实验中，我们为此耽误了不少时间。 检索 修改图片搜索框架 在实验开始，我们修改了图片搜索的框架，进行如下操作。 对查询进行分词后获得token列表。 对每一个token的倒排索引，只需满足一个域的文档即认为是属于该token的文档 满足所有token的文档才能作为整个查询的文档进行评分 对每个token的每个域计算BM25并求和，最后加上页面的PageRank值。加上PageRank值而非相乘，可以避免索引页面总排在最前面而在评分相差不大时获得优势 使用MultiFieldQueryParser 通过修改框架的方式获得了很大的自由空间，但实现上效率很低，搜索结果用时很长。由此，我们使用MultiFieldQueryParser替代自己实现的SimpleQuery、SimpleSimilarity、SimpleScorer等类。为了使用BM25评分，Lucene也改为4.0版本，相应地，IK Analyzer也修改了版本。至此，我们使用Lucene提供的BM25Simlarity计算BM25评分。 分域权重 我们抽取1000个文档进行测试，给各个域赋予不同的权重，作为boosts参数传给MultiFieldQueryParser。在使用整体数据进行测试的过程中，我们也进行了相应调整，最后确定了100、25、35、1、0.001的一组权重。 文档摘要 呈现文档时，我们对文档内容抽取摘要进行展示。建立所有token在文档内容中的位置构成的集合，从前开始，并呈现token前后的30个字符；若两个token临近则连续输出。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public static String genAbstract(List&lt;String&gt; tokens, String content) &#123; int maxLength = 300; int range = 30; String result = ""; content = content.trim(); List&lt;Integer&gt; startPositions = new ArrayList&lt;Integer&gt;(); List&lt;Integer&gt; endPositions = new ArrayList&lt;Integer&gt;(); for (String t : tokens) &#123; String token = new String(t); int colonIndex = token.indexOf(':'); if (colonIndex &gt;= 0) &#123; token = token.split(":")[1]; &#125; int pos = 0; Pattern pattern = Pattern.compile(token, Pattern.CASE_INSENSITIVE); Matcher matcher = pattern.matcher(content); int num = 0; while (matcher.find(pos) &amp;&amp; ++num &lt; maxLength / range) &#123; pos = matcher.start(); startPositions.add(pos); endPositions.add(pos + token.length()); ++pos; &#125; &#125; Collections.sort(startPositions); Collections.sort(endPositions); int i = 0; int size = startPositions.size(); while (i &lt; size) &#123; int pos = startPositions.get(i); int end = endPositions.get(i); int ptr; for (ptr = pos; ptr &gt;= pos - range; --ptr) &#123; if (ptr &lt; 0 || stopChar.contains(content.charAt(ptr))) &#123; ++ptr; break; &#125; &#125; result += content.subSequence(ptr, pos); result += "&lt;em&gt;"; result += content.subSequence(pos, end); result += "&lt;/em&gt;"; ++i; while (i &lt; size) &#123; pos = startPositions.get(i); if (end &gt; pos) &#123; result += "&lt;em&gt;"; result += content.subSequence(end, endPositions.get(i)); result += "&lt;/em&gt;"; pos = end; end = endPositions.get(i); ++i; &#125; else &#123; if (pos == end) &#123; result += content.subSequence(end, pos); end = endPositions.get(i); result += "&lt;em&gt;"; result += content.subSequence(pos, end); result += "&lt;/em&gt;"; ++i; &#125; else if (pos - end &lt; range) &#123; result += content.subSequence(end, pos); end = endPositions.get(i); result += "&lt;em&gt;"; result += content.subSequence(pos, end); result += "&lt;/em&gt;"; ++i; if (result.length() &gt; maxLength - range) &#123; break; &#125; &#125; else &#123; break; &#125; &#125; &#125; for (ptr = end; ptr &lt; end + range; ++ptr) &#123; if (ptr &gt;= content.length() || stopChar.contains(content.charAt(ptr))) &#123; break; &#125; &#125; result += content.subSequence(end, ptr) + "... "; if (result.length() &gt; maxLength) &#123; break; &#125; &#125; return result;&#125; 但这种方法并不总能正确呈现查询词的位置。之后，我们使用Lucene自带的highlight进行处理，一些原来认为毫无关系的文档也能看到相关性。 实验结果 刘奕群 陈旭 超算 长文本搜索 心得体会 实验开始，我们完成了对图像搜索框架的修改，并实现了摘要提取，费尽周章进行调试，但是效果始终不理想。一个是响应速度慢，需要十几秒，一个是显示的摘要大多时候表现不出和查询的相关性。 这个时候，我们采用了Lucene自带的MultiFieldQueryParser进行查询，显著缩短了查询时间，增强了查询体验；同时，Lucene框架内的highlights提供了更加友好的摘要，使得一些标题好像根本不相关的页面也表现出了相关性。与此同时，原有的代码被删减近半。 痛惜之余，我们也感受到了开源社区的优越性，反复造轮子的过程是对时间的浪费，多使用已有的工具包可以获得更好的效果。回过头来看，似乎所有的工作在最后一天下午又重新做起了。 在重新构建框架的过程中也进一步发现了很多有用的开源工具，也发现了很多可进一步扩展的功能，不过由于前期反复造轮子耗时过多导致最后时间不够没能进一步实现。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ipv4 over Ipv6隧道协议实验客户端报告]]></title>
      <url>%2F2017%2F05%2F23%2F4over6%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%2F</url>
      <content type="text"><![CDATA[实验目的 IPV4 over IPV6，简称“4over6”是IPV4向IPV6发展进程中，向纯IPV6主干网过渡提出的一种新技术，可以最大程度地继承基于IPV4网络和应用，实现IPV4向IPV6平滑的过渡。 该实验通过实现IPV4 over IPV6隧道最小原型验证系统，让同学们对4over6隧道的实现原理有更加深刻的认识。 实验要求 在安卓设备上实现一个4over6隧道系统的客户端程序 实现安卓界面程序，显示隧道报文收发状态(java语言)； 启用安卓VPN服务(java语言)； 实现底层通信程序，对4over6隧道系统控制消息和数据消息的处理(C语言)。 实验内容 前台是java语言的显示界面 进行网络检测并获取上联物理接口IPV6地址； 启动后台线程； 开启定时器刷新界面； 界面显示网络状态； 开启安卓VPN服务。 后台是C语言客户端与4over6隧道服务器之间的数据交互 连接服务器； 获取下联虚接口IPV4地址并通过管道传到前台； 获取前台传送到后台的虚接口描述符； 读写虚接口； 对数据进行解封装； 通过IPV6套接字与4over6隧道服务器进行数据交互； 实现保活机制，定时给服务器发送keeplive消息。 前端具体实现 后台具体实现 遇到的问题 连接VPN之后无法与服务器之间进行通信 C后台请求到IPV4地址信息之后，前端建立好VPN服务之后读取虚接口向服务器发送数据流量信息时服务器收不到相应的数据包，经过检查发现在 VPNService重入问题 在测试阶段 数据包读取不完整 异常退出问题 断开连接重连问题]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[密码学第三次大作业]]></title>
      <url>%2F2017%2F05%2F23%2F%E5%AF%86%E7%A0%81%E5%AD%A6%E7%AC%AC%E4%B8%89%E6%AC%A1%E5%A4%A7%E4%BD%9C%E4%B8%9A%2F</url>
      <content type="text"><![CDATA[查阅文献，搞清楚滑动窗口方法+Montgomery模乘运算原理 算法原理 实现两个512比特大整数的模乘运算 设计一个安全的（没有中间人攻击）的Diffie-Hellman密钥交换协议 DH算法描述 DH密钥交换算法是为了使两个用户能够安全地交换密钥的密钥交换协议。 假定Alice和Bob期望在一个不安全的网络中协商一个共同的密钥，那么进行如下步骤： 双方约定大素数\(q\)和它的一个本原根\(g\), 其中\(g&lt;q\)。 Alice随机产生一个数(私钥) \(a\),\(a &lt; q\),并计算公钥\(Y_A = g^a \mod q\), 发送给Bob。 Bob随机产生一个数(私钥) \(b\),\(b&lt;q\), 并计算公钥\(Y_B= g^b \mod q\)，发送给Alice。 此时， Alice手握Bob发过来的公钥\(Y_B\)，结合自己产生私钥a计算会话密钥：\[K = Y_B^a \mod q = (g^b \mod q)^a \mod q = g^{ab} \mod q\] Bob也拿到了Alice发来的公钥\(Y_A\)，同时结合自己的私钥b，计算会话密钥：\[K = Y_A^b \mod q = (g^a \mod q)^b \mod q = g^{ab} \mod q\] 这样Alice和Bob都得到了相同的会话密钥K，即通过DH算法完成了密钥交换。 DH协议的安全性依赖于离散对数的安全性，其假定它假定当q足够大时，通过公共值\(g^a \mod q\)和\(g^b \mod q\)无法计算出共享的secret key，即\(K = g^{ab} \mod q\)。 DH算法的中间人攻击漏洞描述 D-H的密钥交换容易被中间人攻击。其攻击思路如下: Alice 发送公钥\(Y_A\)给Bob, 中间人EVE截取该值，并选择了一个自己的私钥\(c\)，计算出自己的公钥\(Y_C = g ^ c \mod q\)然后发送自己的公钥给Bob Bob向Alice传递自己的公钥\(Y_B\)时，也被中间人EVE截获该值,EVE代替Bob发送它自己的公共值\(Y_C\)给Alice 此时，Alice收到中间人EVE的公钥，Alice和EVE计算出会话密钥\(K_1 = g^{ac} \mod q\), Bob也收到中间人发送的公钥，Bob和EVE计算出会话密钥\(K_2 = g^{bc} \mod q\) Alice和Bob都以为是和对方协商好了会话密钥，于是双方互相发送数据，Alice用\(K_1\)加密数据之后发送给Bob，EVE截获该数据，用\(K_1\)解密，即可查看Alice发送给Bob的数据，Eve还可对其进行修改，然后用\(K_2\)加密发送给Bob，这是Bob收到的消息已经被中间人Eve窥探甚至篡改，但Bob对此毫不知情。 这就是中间人攻击的原理。 DH算法的防止中间人攻击的方法—–签名认证 D-H之所以容易被中间人攻击，是因为key在交换时并不对其参与者进行认证。可能的解决办法是使用数字签名，以及使用其它的协议变种。 A与B都提供自己的公钥/密钥对和公钥的证书，A根据一些消息来计算一个签名，其中包括公共值g^a mod p，B也做类似的运算。即使C仍然能够截取A与B之间的信息，但他并不能在没有A和B的密钥的情况下伪造签名，因此，这个增强的协议抵挡了中间人攻击。 具体实现为， 全局公开大素数q及其本原根\(\alpha\) Alice随机产生一个数x，并计算其公钥\(\alpha ^ x \mod q\),发送给Bob 签名认证的DH算法 参考文献 李必涛,徐赐文,王晓菲,贾杰,郭远,郑辉. 一种能够抵抗主动攻击的改进Diffie-Hellman密钥协商方案[J]. 中央民族大学学报(自然科学版),2008,(04):54-57. 徐恒,陈恭亮,杨福祥. 密钥交换中中间人攻击的防范[J]. 信息安全与通信保密,2009,(02):90-92. Diffie–Hellman key exchange. (2017, March 22). In Wikipedia, The Free Encyclopedia. Retrieved June 2, 2017, from https://en.wikipedia.org/wiki/Diffie–Hellman_key_exchange Blakewilson, S., &amp; Menezes, A. (1999). Unknown Key-Share Attacks on the Station-to-Station (STS) Protocol. International Workshop on Practice and Theory in Public Key Cryptography (Vol.1560, pp.154-170). Springer-Verlag. Diffie, W., Oorschot, P. C. V., &amp; Wiener, M. J. (1992). Authentication and authenticated key exchanges. Designs, Codes and Cryptography, 2(2), 107-125.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[密码学实验2]]></title>
      <url>%2F2017%2F05%2F09%2F%E5%AF%86%E7%A0%81%E5%AD%A6%E5%AE%9E%E9%AA%8C2%2F</url>
      <content type="text"><![CDATA[接口函数 AES: 12void Crypt_Enc_Block(unsigned char *input,int in_len,unsigned char*output,int *out_len, unsigned char *key,int keylen); AES加密过程涉及4种操作： 字节替代（SubBytes） 行移位（ShiftRows） 列混淆（MixColumns） 轮密钥加（AddRoundKey） 通用的序列密码RC4 12void RC4(unsigned char *input,int in_len,unsigned char *output,int*out_len,unsigned char *key,int keylen); RonRivest设计。密钥长度可变 状态:256个bytes – State[256]=[0,1,2,…,255] 密钥:40至2048比特可变 初始化算法和伪随机子密钥生成算法 RC4于1987年提出，和DES算法一样，是一种对称加密算法，也就是说使用的密钥为单钥（或称为私钥）。但不同于DES的是，RC4不是对明文进行分组处理，而是字节流的方式依次加密明文中的每一个字节，解密的时候也是依次对密文中的每一个字节进行解密。 RC4算法的特点是算法简单，运行速度快，而且密钥长度是可变的，可变范围为1-256字节(8-2048比特)，在如今技术支持的前提下，当密钥长度为128比特时，用暴力法搜索密钥已经不太可行，所以可以预见RC4的密钥范围任然可以在今后相当长的时间里抵御暴力搜索密钥的攻击。实际上，如今也没有找到对于128bit密钥长度的RC4加密算法的有效攻击方法。 在介绍RC4算法原理之前，先看看算法中的几个关键变量： 密钥流：RC4算法的关键是根据明文和密钥生成相应的密钥流，密钥流的长度和明文的长度是对应的，也就是说明文的长度是500字节，那么密钥流也是500字节。当然，加密生成的密文也是500字节，因为密文第i字节=明文第i字节^密钥流第i字节； 状态向量S：长度为256，S[0],S[1]…..S[255]。每个单元都是一个字节，算法运行的任何时候，S都包括0-255的8比特数的排列组合，只不过值的位置发生了变换； 临时向量T：长度也为256，每个单元也是一个字节。如果密钥的长度是256字节，就直接把密钥的值赋给T，否则，轮转地将密钥的每个字节赋给T； 密钥K：长度为1-256字节，注意密钥的长度keylen与明文长度、密钥流的长度没有必然关系，通常密钥的长度取为16字节（128比特）。 RC4的原理分为三步： 12345678910111213141516171、初始化S和Tfor i=0 to 255 do S[i]=i; T[i]=K[ i mod keylen ];2、初始排列Sj=0;for i=0 to 255 do j= ( j+S[i]+T[i])mod256; swap(S[i],S[j]);3、产生密钥流i,j=0;for r=0 to len do //r为明文长度，r字节 i=(i+1) mod 256; j=(j+S[i])mod 256; swap(S[i],S[j]); t=(S[i]+S[j])mod 256; k[r]=S[t]; SM3: 12void SM3(unsigned char *InMessage,int MessageLen,unsigned char *OutDigest,int *DigestLen); 寻找SM3的高56比特的碰撞.（提交源程序和碰撞消息对）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数值分析实验]]></title>
      <url>%2F2017%2F05%2F09%2F%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E5%AE%9E%E9%AA%8C%2F</url>
      <content type="text"><![CDATA[实验一 1.3 实验内容 编程观察无穷级数\[\sum_{n=1}^\infty\frac{1}{n}\]的求和运算. 采用IEEE单精度浮点数,观察当n为何值时求和结果不再变化,将它与理论分析的结论进行比较（注：在MATLAB中可用single命令将变量转成单精度浮点数）。 用IEEE双精度浮点数计算（1）中前n项的和，评估IEEE单精度浮点数计算结果的误差。 如果采用IEEE双精度浮点数，估计当n为何值时求和结果不再变化，这在当前做实验的计算机上大概需要多长的计算时间？ 实现思路： 第一问：采用IEEE单精度浮点数, 使用MATLAB的single命令即为IEEE单精度数值，使用single_sum和last_sum记录求和结果，当两个值相等时跳出while循环，保留n值，输出求和结果 不使用single即为Double型数据，对其循环1中的n次，记录求和结果 利用matlab的tic,toc组合命令记录双精度计算n次运行时间，进而推测求值不再变化时的运行时间 结果及分析 程序运行结果如下 1234双精度运算结果: 15.403683 n = 2097152时间已过 0.011240 秒。双精度运算结果: 15.133307单精度运算误差: -0.270376 数据类型 位数 符号位 指数位 尾数 有效位(10进制) float 32 1 8 23 7 double 64 1 11 52 16 1、 根据定理 1.6(即“大数吃小数”定理):\[|\frac{x_2}{x_1}|\le0.5\epsilon, x_1+x_2==x_1\]其中\(\epsilon\)为机器精度。则当前的 1/n 与当前求和值之比小于等于 \(0.5*\epsilon\)时退出循环。单精度浮点计数时的机器精度为\[2^{-24} \approx 5.960*10^{-8}，n -&gt; \infty\]时有\[\sum_{n=1}^\infty\frac{1}{n} = ln(n)\]从而当\[\frac{1}{nln(n)} \le 0.5 *5.960*10^{-8}\]时计算结果不再变化，估算该n值为2000000,这与程序所得结果2097152基本符合. 2、单精度计算前2097152项和结果与双精度计算结果绝对误差为0.270376。 3、单精度浮点计数时的机器精度为\[2^{-53} \approx 1.110*10^{-16}\]，有 \[\sum_{n=1}^\infty\frac{1}{n} = ln(n)\]从而当\[\frac{1}{nln(n)} \le 0.5 *1.110*10^{-16} = 5.55 * 10^{-17}\]时计算结果不再变化，估算该n值为\(n = 500000000000000 = 5.0*10^{14}\)， 计算2097152次双精度加法时耗时0.011240秒，则计算n次耗时\[0.011240 * \frac{n}{2097152} \approx 2679824.8291015625 s\] 估算结果 实验心得 初步接触了MATLAB的部分编程方法，对机器精度的理解更加深入了，对单精度和双精度的计算准确度也有了一个直观的了解。 实验二 2.2 实验内容 编程实现阻尼牛顿法。要求: 设定阻尼因子的初始值\(\lambda_0\)及解的误差阈值\(\epsilon\)； 阻尼因子\(\lambda\)用逐次折半法更新； 打印每个迭代步的最终值及近似解。 用所编程序求解： \(x^3 - x - 1 = 0\)，取\(x_0 = 0.6\) \(-x^3 + 5x = 0\), 取\(x_0 = 1.2\) 实现思路 阻尼牛顿法中迭代新解为 \[x_{k+1} = x_k - \lambda_i \frac{f(x_k)}{f^\prime(x_k)}\] 单调性要求为\[|f(x_{k+1})|&lt;|f(x_k)|, k = 0,1,2,\cdots\] 算法按照课本中算法2.5的伪代码实现 结果及分析 1234567891011121314151617181920212223242526272829303132333435363738394041========阻尼牛顿法========初始值x_0:0.6000000000 lambda:1.000000x_1: 1.1406250000 lambda:0.015625x_2: 1.3668136616 lambda:1.000000x_3: 1.3262798040 lambda:1.000000x_4: 1.3247202256 lambda:1.000000x_5: 1.3247179572 lambda:1.000000迭代解为: 1.32471795725 2.04494199352e-11初始值x_0:1.2000000000 lambda:1.000000x_1: -1.9411764706 lambda:0.250000x_2: -2.3204623232 lambda:1.000000x_3: -2.2404594360 lambda:1.000000x_4: -2.2360808552 lambda:1.000000x_5: -2.2360679776 lambda:1.000000迭代解为: -2.23606797761 1.1124381416e-09========牛顿法========初始值x_0:0.6000000000x_1: 17.9000000000x_2: 11.9468023286x_3: 7.9855203519x_4: 5.3569093148x_5: 3.6249960329x_6: 2.5055891901x_7: 1.8201294223x_8: 1.4610441099x_9: 1.3393232243x_10: 1.3249128677x_11: 1.3247179926迭代解为: 1.32471799264 1.50938453736e-07初始值x_0:1.2000000000x_1: -5.0823529412x_2: -3.6219359167x_3: -2.7660437838x_4: -2.3576006646x_5: -2.2448622370x_6: -2.2361193864x_7: -2.2360679793迭代解为: -2.23606797927 1.77279613212e-08 本实验中，\(\lambda\)均只在第一步迭代中有折半运算，其后都未进入折半循环，减少了总体计算次数，这是一个好结果。 实验三 3.6 实验内容 编程序生成Hilbert矩阵\(\mathbf H_n\)，以及n维向量\(b = \mathbf H_nx\)，其中x为所有分量都是1的向量。用Cholesky分解算法求解方程\(\mathbf H_nx = b\)，得到近似解\(\hat x\)，计算残差\(r = b - H_n\hat x\) 和误差 \(\Delta x = \hat x - x\) 的\(\infty-\)范数。 设n=10，计算\(\| r \|_\infty、 \| \Delta x \|_\infty\)。 在右端项上施加\(10^{-7}\)的扰动然后解方程组，观察残差和误差的变化情况。 改变n的值为8和12，求解相应方程，观察\(\| r \|_\infty、 \| \Delta x \|_\infty\)的变化情况。通过这个实验说明了什么问题？ 实现思路 根据Hilbert矩阵的结构，生成n阶矩阵\(\mathbf H\)，继而得到向量\(b = \mathbf H_nx\)； 用Cholesky分解算法求解方程\(\mathbf H_nx = b\)，得到近似解\(\hat x\)，具体过程为： 首先对\(\mathbf H_n\)进行Choklesky分解得到下三角矩阵\(L_n\) \(\mathbf H_nx = b, H_n = LL^T\), 则先计算\(LY = b\)得到Y, 然后计算\(L^Tx = Y\),得到\(x\) 计算残差和误差的\(\infty-\)范数。 结果及分析 123456789101112131415161718n = 8 扰动 = 0.0误差x无穷范数: 6.27198750047e-07残差r无穷范数: 2.22044604925e-16n = 8 扰动 = 1e-07误差x无穷范数: 0.0216211911554残差r无穷范数: 4.4408920985e-16n = 10 扰动 = 0.0误差x无穷范数: 0.000643781555903残差r无穷范数: 8.881784197e-16n = 10 扰动 = 1e-07误差x无穷范数: 0.699727076702残差r无穷范数: 4.4408920985e-16n = 12 扰动 = 0.0误差x无穷范数: 0.355545598229残差r无穷范数: 4.4408920985e-16n = 12 扰动 = 1e-07误差x无穷范数: 23.9972906485残差r无穷范数: 1.11022302463e-15 n = 10, 无扰动时 \[\| r \|_\infty = 8.881784197e-16\] \[\| \Delta x \|_\infty = 0.000643781555903\] n = 10, 扰动\(10^{-7}\)时 \[\| r \|_\infty = 4.4408920985e-16\] \[\| \Delta x \|_\infty = 0.699727076702\] n = 8时 \[\| r \|_\infty = 2.22044604925e-16\] \[\| \Delta x \|_\infty = 6.27198750047e-07\] n = 12时 \[\| r \|_\infty = 4.4408920985e-16\] \[\| \Delta x \|_\infty = 0.355545598229\] 进一步实验，统计实验结果 N \(\| \Delta x \|_\infty\) 引入\(10^{-7}\)扰动后 \(\| r \|_\infty\) 引入\(10^{-7}\)扰动后 8 6.27198750047e-07 0.0216211911554 2.22044604925e-16 4.4408920985e-16 10 0.000643781555903 0.699727076702 8.881784197e-16 4.4408920985e-16 12 0.355545598229 23.9972906485 4.4408920985e-16 1.11022302463e-15 由上述结果分析可以得出如下结论： 无论是施加扰动还是改变矩阵的阶数n, 对残差的无穷范数\(\| r \|_\infty\)影响不大，但误差的无穷范数\(\| \Delta x \|_\infty\)变化明显 矩阵的阶数n增大，误差的无穷范数\(\| \Delta x \|_\infty\)增加明显，问题的条件数 \[\begin{align} cond &amp;= \frac{\|\Delta x\|/\|x\|}{\|\Delta b\|/\|b\|} \\ &amp;= \frac{\|\Delta x\|/\|x\|}{\frac{\|\Delta b\|}{\|H\|}/\|x\|} \\ &amp;= \frac{\|\Delta x\|}{\|\Delta b\|}\|H\| \\ &amp;= \frac{\|\Delta x\|}{\|r\|} \|H\| \end{align}\] 希尔伯特矩阵是一个典型的病态矩阵，其条件数\(cond(H_n)_\infty &gt; 1\) 且随着矩阵的阶数n越大，其病态性越严重，因此本题中线性方程组求解问题也是敏感的。 实验四 4.1 实验内容 考虑10阶\(Hilbert\)矩阵作为系数阵的方程组\[Ax = b\] 其中，A的元素\(a_{ij}=\frac{1}{i+j-1}\), \(b = \begin{bmatrix}1&amp;\frac{1}{2}&amp;\cdots&amp;\frac{1}{10}\end{bmatrix}^T\).取初始解\(x^{(0)} = 0\),编写程序用\(Jacobi\)与\(SOR\)迭代法求解该方程组，将\(\|x^{(k+1)} - x^{(k)}\|_\infty &lt; 10^{-4}\)作为终止迭代的判据。 分别用\(Jacobi\)与\(SOR(w = 1.25)\)迭代法求解，观察收敛情况； 改变\(w\)的值，试验\(SOR\)迭代法的效果，考察解的准确度。 实现思路 根据教程中的\(Jacobi\)迭代算法和\(SOR\)迭代算法的伪代码完成编码 因为A是\(Hilbert\)矩阵，是实对称矩阵，其谱半径\(\rho(A) = \|A\|_2 &gt; 1\)，其\(Jacobi\)迭代法不收敛。 对于\(SOR\)迭代法的准确度，我们使用误差\(\Delta x = \hat x - x\)的无穷范数进行量化，易知线性方程组的正确解\(x=\begin{bmatrix}1&amp;0&amp;\cdots&amp;0\end{bmatrix}^T\) 结果及分析 1234567891011121314151617181920212223242526272829雅克比迭代法jacobi迭代不收敛w = 1.25迭代次数: 187迭代结果: [1.002022594409028, -0.021609987149109246, 0.05149585866739306, -0.028416470227697905, -0.006259608843587831, -0.006192548765741887, -0.0005373689012403876, 0.0018347675968743396, 0.003636620501503592, 0.004567285710065993]w = 1.6迭代次数: 493迭代结果: [1.0021469657102071, -0.0283570320963052, 0.08880081215699734, -0.09535773222087951, 0.04336165034147876, -0.0355509984828663, 0.02513571167799267, -0.010543151501989416, 0.013356482959673942, -0.0023146920643427986]w = 1.4迭代次数: 270迭代结果: [1.0022700223737249, -0.027450984607899714, 0.07485459487277796, -0.05746975449051693, 0.005911675449980705, -0.012463346972930323, 0.0036081977048833262, 0.0015499835906313381, 0.00513317184635749, 0.004901511994768535]w = 1.2迭代次数: 164迭代结果: [1.0019214723944498, -0.019188626689019883, 0.04270174478597167, -0.02008673411613389, -0.007120242694937775, -0.005157615844817916, -0.0009805683321413268, 0.0013857829440947498, 0.0029820023152041636, 0.0039040390400999197]w = 1.0迭代次数: 2迭代结果: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]w = 0.8迭代次数: 178迭代结果: [0.9973420757985196, 0.022189810579507762, -0.03692216721730894, 0.0002172210934328124, 0.012508220958753955, 0.010340953138668948, 0.0047473091369648925, -0.00029255227286110113, -0.003947813463373296, -0.006348095947258598]w = 0.6迭代次数: 271迭代结果: [0.9955833379103364, 0.038088293718681644, -0.06191668688342534, -0.008191119893787442, 0.022657640869212896, 0.024947505162692972, 0.014412072529676016, 0.0013699258800427523, -0.009816061664535391, -0.018012206700100845]w = 0.4迭代次数: 397迭代结果: [0.9932920658677347, 0.05517010926044667, -0.08070115313478526, -0.023914639520845007, 0.024971861498459945, 0.03919911225602069, 0.029505998466182924, 0.008987379128371036, -0.013671954578940389, -0.03395765285066289]w = 0.2迭代次数: 657迭代结果: [0.9886002689546933, 0.081327354825667, -0.09358751789761771, -0.048223519275488166, 0.012311655912579827, 0.04317339038553021, 0.043997018466545454, 0.024122149074273676, -0.007160625602977868, -0.0428600869164585] w \(\| \Delta x \|_\infty\) 迭代次数 1.6 0.0953577322209 493 1.4 0.0748545948728 270 1.25 0.0514958586674 187 1.2 0.042701744786 164 1.0 0.0 2 0.8 0.0369221672173 178 0.6 0.0619166868834 271 0.4 0.0807011531348 397 0.2 0.0935875178976 657 \(Jacobi\)迭代法不收敛,\(SOR\)迭代法(\(w = 1.25\))迭代187次后收敛，得到近似解\(\hat x\) = [1.002022594409028, -0.021609987149109246, 0.05149585866739306, -0.028416470227697905, -0.006259608843587831, -0.006192548765741887, -0.0005373689012403876, 0.0018347675968743396, 0.003636620501503592, 0.004567285710065993], 误差的无穷范数为\(\| \Delta x \|_\infty = 0.0514958586674\) 选取不同的w值，得到的迭代次数和误差的无穷范数变化如上表所示，可以得到的结论是w值越接近1，其收敛速度越快，误差越小。 实验心得 对\(Jacobi\)迭代法和\(SOR\)迭代法的收敛条件有了更深入的认识，对\(SOR\)迭代法中松弛因子\(w\)的大小对迭代算法收敛速度及计算准确度的影响有了直观的感受，针对一类应用问题选择合适的松弛因子是一个重要问题。 实验五 5.1 实验内容 用幂法求下列矩阵按模最大特征值\(\lambda_1\)及其对应的特征向量\(x_1\)，使\(\|(\lambda_1)_{k+1} - (\lambda_1)_k\| &lt; 10^{-5}\)。 \(A = \begin{bmatrix}5&amp;-4&amp;1\\-4&amp;6&amp;-4\\1&amp;-4&amp;7\end{bmatrix}\) \(B = \begin{bmatrix}25&amp;-41&amp;10&amp;-6\\-41&amp;68&amp;-17&amp;10\\10&amp;-17&amp;5&amp;-3\\-6&amp;10&amp;-3&amp;2\end{bmatrix}\) 实现思路 按照课本中算法5.1实现算法 结果及分析 迭代次数 16 主特征向量: [ 0.67401996 -1. 0.8895594 ] 主特征值: 12.2543197032 迭代次数 6 主特征向量: [-0.60397234 1. -0.25113513 0.14895345] 主特征值: 98.5216977228 实验六 6.3 实验内容 对物理实验中所得的下列数据 \(t_i\) 1 1.5 2 2.5 3.0 3.5 4 4.5 \(y_i\) 33.40 79.50 122.65 159.05 189.15 214.15 238.65 252.2 \(t_i\) 5.0 5.5 6.0 6.5 7.0 7.5 8.0 \(y_i\) 267.55 280.50 296.65 301.65 310.40 318.15 325.15 用公式\(y = a + bt + ct^2\)做曲线拟合. 用指数函数\(y = ae^{bt}\)做曲线拟合. 比较上述两条拟合曲线，哪条更好？ 实现思路 参考课本算法6.2（用法方程方法求解曲线拟合的最小二乘问题）。 首先根据式（6.28）形成矩阵A，继而计算出\(G = A^TA\)和向量\(b = A^Tf\)，得到方程\(Gx = b\)。 解上述所得方程。可以采用\(Cholesky\)分解然后执行前代和回代过程,得到的向量即为多项式函数的各项系数（低次到高次）。 用指数函数拟合时，可以对函数式两边同时取对数，转化为一次多项式函数的曲线拟合问题。 结果及分析 拟合结果\(y=-45.29423077+94.19429218t-6.12682612t^2\)， 均方误差: 5.68393182348 拟合结果\(y=67.39379285e^{0.23898344t}\)， 均方误差: 63.1840873401 通过比较其均方误差可知：用2次多项式函数拟合曲线比指数函数拟合曲线好，其拟合图像如下所示 拟合图像]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[链接结构分析实验]]></title>
      <url>%2F2017%2F05%2F07%2F%E9%93%BE%E6%8E%A5%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90%E5%AE%9E%E9%AA%8C%2F</url>
      <content type="text"><![CDATA[实验内容 基于维基百科网站中各网页之间的链接关系图，计算该网站中各网页对应的PageRank值。 数据格式 12head:node1,node2,…,noden\n 源网页:目标网页1,目标网页2,…,目标网页n\n 实现 按照课件中的PageRank算法完成实现即可, 其中跳出参数aplha = 0.15, 迭代次数TN = 30 链接结构文件在results.txt文件中 运行结果 PageRank算法结果分布情况，PageRank得分与相应条目语义内容的分析 PageRank值前10的页面为 网页名 ID PageRank OutDegree InDegree 箭头 25883781 0.0222736998255 5 45 &lt;- 27117327 0.0172915137241 2 228676 维基数据 26530938 0.00480022230925 14 196429 Unicode 27003594 0.00390634021739 170 945 符号 27013210 0.00383295720591 78 283 中国 27116231 0.00129406053337 2287 68798 美国 27116867 0.00115684939603 1741 70222 学名 27108158 0.00108490964783 20 68384 法国 27114727 0.000980044130108 629 54791 市镇 27079331 0.00097233210881 10 64201 由结果可以发现箭头和&lt;-是两个页面结果奇地高，分析这两个页面可以发现，“箭头”和“&lt;-”两个页面的出度都比较小，而‘&lt;-’入度特别高，这在一定程度上使得其PageRank值偏高，而’箭头’页面的入度实际上并不高，但其PageRank值却是最高的，查询对应网页内容，发现’&lt;-’页面其实是维基百科的重定向页面，有大量页面指向该页面，因此其PageRank值会偏高 &lt;-出度 箭头出度1 箭头出度2 ‘&lt;-’页面由于有很多页面指向，因此其PageRank值偏高是比较合理的，而“箭头”页面的入度实际上并不高，但是其PageRank值却是最高的，进一步分析“箭头页面”，查看“箭头”页面的出度，发现其5个出页面中有两个指向了自己，进一步查看‘&lt;-’页面的出度，发现其两个出度都是’25883781’,即“箭头页面”，由PageRank迭代过程中PageRank值更新过程（PageRank算法图所示），‘&lt;-’页面由于入度大故PageRank值较高，而该页面又全部指向了‘箭头’页面，由算法图中标记位置可知，“箭头”页面的PageRank值的确会特别高 由此可以得出结论，计算PageRank时一定要注意数据的清洗，清除一些不必要的页面，PageRank值排名第2和3的页面实际的重要程度并不高，但是由于其是分类或者重定向页面而显得比较高，这实际上影响了其页面重要性的真实度。 PageRank算法图 算法结果分布情况 维基百科语料库中入连接数/出连接数分布情况 维基百科语料库中入连接数/出连接数分布情况 PageRank与入链接数的关联分析 通过计算PageRank值和入连接数的相关系数，可知其相关性不大]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lec19]]></title>
      <url>%2F2017%2F05%2F07%2FLec19%2F</url>
      <content type="text"><![CDATA[保管员问题 有一材料保管员，他保管纸和笔若干。有A 、B 两组学生，A 组学生每人都备有纸，B 组学生每人都备有笔．任一学生只要能得到其他一种材料就可以写信。有一个可 以放一张纸或一支笔的小盒，当小盒中无物品时，保管员就可任意放一张纸或一支笔 供学生取用，每次允许一个学生从中取出自己所需的材料，当学生从盒中取走材料后 允许保管员再存放一件材料，请用信号量与P 、v 操作 12345678910111213141516171819202122232425262728293031323334353637383940vars, Sa.Sb, mutexa, mutexb: semaphore;s: = mutexa ：=mutexb: = 1;sa: = sb: = 0;box: (PaPer, Pen);cobegin process 保管员 begin repeat P(S); take a material intobox ; if (box)=Paper then V(Sa); else V(Sb); untile false ; endProcess A组学生 begin repeat P(Sa); P(mutexa); take the pen from box ; V(mutexa); V(S); write a letter; untile false ; endProcess B组学生 begin repeat P(Sb); P(mutexb); take the paper from box ; V(mutexb); V(S); wnte a letter ; untile false ; endCoend. 要求用C语言，基于semaphore和monitor两种方式实现同步互斥问题，并有测试用例和README，说明你实现的设计和结果分析 一个可以参考的实现例子请看 https://github.com/chyyuu/os_tutorial_lab/tree/master/knowledge_points/semaphore-vs-monitor 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;#include &lt;time.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;semaphore.h&gt;#include &lt;jmorecfg.h&gt;// 每组学生有5名#define STUDENTS_NUM 5#define random(x) (rand()%x)#define TEST_TIMES 10// 互斥信号，初值为1sem_t lock;// AB两组学生的自己的互斥信号量，初值为1，即每次只能一个A,或者一个B访问BOXsem_t mutex_A, mutex_B;// A,B两组学生之间的同步访问量，保管员放入物资时，对应学生需要取走物资，初值为0sem_t pen, paper;int count = 0;void * keepers (void *ptr) &#123; // printf(&quot;I&apos;m keepers\n&quot;); while(count &lt; TEST_TIMES) &#123; // 只试验TS+EST_TIMES次 // P操作，每次只能放一次，直到学生取走物资 sem_wait(&amp;lock); count += 1; // 放入材料 if(rand() % 2 == 0) &#123; // 放入了笔,A组学生可以取材料 printf(&quot;保管员放入笔\n&quot;); sem_post(&amp;pen); &#125; else &#123; // 放入了纸，B组同学可以取材料 printf(&quot;管理员放入纸\n&quot;); sem_post(&amp;paper); &#125; &#125; return NULL;&#125;void * student_A(void *ptr) &#123; // A组学生，每人备有纸，等待pen资源 int index = *(int*)ptr; boolean not_get = TRUE; while (not_get) &#123; // 无其他A组同学申请取资源 sem_wait(&amp;pen); // 无其他A组同学申请取资源 sem_wait(&amp;mutex_A); printf(&quot;A 组同学 %d 获得笔\n&quot;, index); sem_post(&amp;mutex_A); // V操作，保管员可再次放入材料 printf(&quot;A 组同学 %d 写信\n&quot;, index); not_get = FALSE; sem_post(&amp;lock); &#125; return NULL;&#125;void * student_B(void *ptr) &#123; // B组学生，每人备有笔，等待paper资源 int index = *(int*)ptr; boolean not_get = TRUE; while (not_get) &#123; sem_wait(&amp;paper); // 无其他B组同学申请取资源 sem_wait(&amp;mutex_B); printf(&quot;B 组同学 %d 获得纸\n&quot;, index); sem_post(&amp;mutex_B); // V操作，保管员可再次放入材料 printf(&quot;B 组同学 %d 写信\n&quot;, index); not_get = FALSE; sem_post(&amp;lock); &#125; return NULL;&#125;int main(int argc, char const *argv[])&#123; /* code */ // int sem_init(sem_t *sem,int pshared,unsigned int value); // 第二个参数指允许被几个进程共享 // 同步访问 sem_init(&amp;pen, 0, 0); sem_init(&amp;paper, 0, 0); // 互斥访问 sem_init(&amp;lock, 0, 1); sem_init(&amp;mutex_A, 0, 1); sem_init(&amp;mutex_B, 0, 1); // 保管员，学生A,B pthread_t keep; pthread_t stu_A[STUDENTS_NUM]; pthread_t stu_B[STUDENTS_NUM]; // 保管员线程 pthread_create(&amp;keep, NULL, keepers, NULL); int thread_args[STUDENTS_NUM]; for (int i = 0; i &lt; STUDENTS_NUM; ++i) &#123; thread_args[i] = i+1; pthread_create(&amp;stu_A[i], NULL, student_A, (thread_args + i)); pthread_create(&amp;stu_B[i], NULL, student_B, (thread_args + i)); &#125; pthread_join(keep, 0); for (int i = 0; i &lt; STUDENTS_NUM; ++i) &#123; pthread_join(stu_A[i], 0); pthread_join(stu_B[i], 0); &#125; sem_destroy(&amp;lock); sem_destroy(&amp;mutex_A); sem_destroy(&amp;mutex_B); sem_destroy(&amp;paper); sem_destroy(&amp;pen); return 0;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[集成学习知识点]]></title>
      <url>%2F2017%2F05%2F06%2F%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
      <content type="text"><![CDATA[两个概念 强学习器：高准确率 弱学习器：低准确率（比随机猜测略好） 基本思想 把几个弱分类器加权融合提升效果 每个算法池中的算法有自己的权值 当用于预测一个新的测例时，每个分类器给出自己的预测，总算法使用各自的权值加权得出结果 加权多数算法 加权多数算法 权值为0或1 二值输出，权重为0/1 算法流程，权值变化 每次失败除2， 避免特别小（直接置为0） Bagging算法 Bagging = Bootstrap aggregating 如果只有一个弱分类器，如何进行集成学习 自举法采样 给定一个包含m个训练集的数据集D 有放回采样取m个数据组成训练集\(D_i\) \(D_i\)可能存在重复，存在漏选 12345For t = 1, 2, …, T Docreate boostrap sample Dt from S train a classifier Ht on DtClassify new instance x∈X by majority vote of H t(equal weights) 可以预测连续输出 Bagging算法对结果提示是不稳定的 预测方法的稳定性问题 不稳定的算法：训练集的小变化会造成假设的大变化 如果扰动训练集可以造成预测器的显著变化那么Bagging算法可以提高其精度 特殊点 每个基础分类器在小数据集进行训练（只有63.2%的数据在所有的分数据集中） 但是最终的模型中几乎包含了所有的训练集（平均每个会被&gt;50%的bootstrap包含） 小结 加权多数算法： 同样的数据集，不同的学习算法，生成多个模型，加权预测 Bagging： 一个数据集，一个弱分类器， 生成多个训练集来训练多个模型，然后集成 Boosting算法 基本思想 从错误中学习 给每个example一个权值， AdaBoost get每一个样本一个等值权重\(\frac{1}{N}\) 对1~T,训练生成Ct,计算器错误率 实现参考 adaboosting AdaBoost.M1]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[机器学习实验二-集成学习]]></title>
      <url>%2F2017%2F05%2F06%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E5%AE%9E%E9%AA%8C%2F</url>
      <content type="text"><![CDATA[数据集 本实验采用的数据集是 WEBSPAM-UK2006 数据集, 数据集中包含1803个垃圾网站，4411个正常网站，每个网站有96个内容特征，有138个超链接标签。这138个超链接标签可以被分为五类：Degree-related features, PageRank-related features, TrustRank-related features, Truncated PageRank-related features, Supporter-related features 在本实验中，需要将数据集划分为4：1的训练集和测试集 实验任务 比较由不同的基本分类器组成的不同的集成学习算法的性能 至少需要包含Bagging 算法和 AdaBoost.M1算法 至少需要使用SVM和Decision Tree两种基本分类器算法 至少需要完成的算法组合为：Bagging + DTree, Bagging + SVM, AdaBoost.M1 + DTree, AdaBoost.M1 + SVM. 扩展任务 尝试其他的基本分类器（K-NN, Naive Bayes…） 分析不同的特征的影响（比如可以只使用内容特征，或者只使用链接特征，或者进行特征组合） 考虑特征缩放（归一化）来提高性能 数据集是不平衡的，如何克服 实验设计 基础分类器选取了SVM，Dtree, 和KNN 基础分类器采用了sklearn的包，由于KNN算法无法设置训练样本的权中，因此进行了如下组合： Bagging + DTree Bagging + SVM Bagging + KNN AdaBoost.M1 + DTree AdaBoost.M1 + SVM. 实验结果 针对Bagging和AdaBoost.M1集成学习算法 分别使用SVM,Dtree,KNN等基本分类器进行组合后，并且设置了不同的训练集大小，迭代次数（分类器个数），测试后的总体结果如下： 集成算法 基础算法 迭代次数 训练集大小 准确率 Bagging SVM 1 994 0.886565 Bagging Decision Tree 1 994 0.824618 Bagging KNN 1 994 0.849558 AdaBoost.M1 SVM 1 994 0.884956 AdaBoost.M1 Decision Tree 1 994 0.847949 Bagging SVM 21 994 0.881738 Bagging Decision Tree 21 994 0.913113 Bagging KNN 21 994 0.881738 AdaBoost.M1 SVM 21 994 0.862430 AdaBoost.M1 Decision Tree 21 994 0.881738 Bagging SVM 41 994 0.913113 Bagging Decision Tree 41 994 0.900241 Bagging KNN 41 994 0.884151 AdaBoost.M1 SVM 41 994 0.896219 AdaBoost.M1 Decision Tree 41 994 0.901046 Bagging SVM 21 1988 0.895414 Bagging Decision Tree 21 1988 0.902655 Bagging KNN 21 1988 0.885760 AdaBoost.M1 SVM 21 1988 0.873693 AdaBoost.M1 Decision Tree 21 1988 0.881738 Bagging SVM 21 3976 0.895414 Bagging Decision Tree 21 3976 0.901046 Bagging KNN 21 3976 0.897828 AdaBoost.M1 SVM 21 3976 0.901850 AdaBoost.M1 Decision Tree 21 3976 0.901046 由上表可以得出结论：对于本数据集，Bagging算法和AdaBoost算法的算法性能大致相同，组合基础算法时，KNN+性能最差，Dtree+性能最好，不过在迭代次数较少时SVM的性能较好，迭代次数增加、训练集增加时Dtree+的准确率上升较快 分析和讨论 数据预处理问题 在不对数据进行归一化处理的时候，SVM的Bagging算法表现极差，只能达到 对于SVM,Dtree, KNN三个基础分类器，进行特征归一化与否的分类效果如下所示： 是否归一化 分类器 准确率 否 SVM 0.735318 否 DTree 0.875302 否 KNN 0.781979 是 SVM 0.914722 是 DTree 0.876106 是 KNN 0.899437 可以得出结论:归一化操作对SVM,KNN等算法而言及其重要，这是因为这类分类器是利用两点间的距离计算两点间的差异，当各个特征的维度差异较大时对其分类效果影响较大，因此需要进行归一化，而这些也直接影响了集成学习算法的准确率，如下表所示 不进行归一化处理 集成算法 基础算法 迭代次数 训练集大小 准确率 Bagging SVM 21 994 0.714401 Bagging Decision Tree 21 994 0.896219 Bagging KNN 21 994 0.764280 AdaBoost.M1 Decision Tree 21 994 0.894610 （不归一化处理时，SVM在训练集上做测试时几乎会是完全正确，即出现了过拟合，这时AdaBoost算法无法进行下去，故无数据） 进行归一化处理 集成算法 基础算法 迭代次数 训练集大小 准确率 Bagging SVM 21 994 0.905873 Bagging Decision Tree 21 994 0.907482 Bagging KNN 21 994 0.893001 AdaBoost.M1 SVM 21 994 0.872888 AdaBoost.M1 Decision Tree 21 994 0.901046 可以发现，在不进行归一化处理时，对于基于SVM和KNN两种基本算法的Bagging和AdaBoost集成学习算法表现均较差，而进行了归一化处理之后，其算法准确率则大幅提高（注意，单个算法的准确率较高是因为训练时采用了全训练集，而集成学习的训练集只采用了20%的训练集，因此可能稍有偏差）而DTree的结果并无比较大的差异 由这个对比可以感受到特征归一化对部分分类器的重要性 SVM的参数设置 在实验过程中发现使用SVM算法 + AdaBoost.M1算法时会出现每轮迭代时会出现分类效果越来越差的情况，通过打印预测结果发现，其对训练集的预测会循环出现全0和全1，即这一轮迭代会将每一个测试数据分类为sapm,下一轮迭代时会将每一个测试数据分类为normal, 这样会导致最终的训练结果准确率为69%，反复调试发现是sklearn.svm.SVC参数设置问题 123456sklearn.svm.SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&apos;ovr&apos;, degree=3, gamma=&apos;auto&apos;, kernel=&apos;rbf&apos;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) SVC的参数C代表了其惩罚参数，相当于惩罚松弛变量，松弛变量接近0时，即对误分类的惩罚增大，趋向于对训练集全分对的情况，这样对训练集测试时准确率很高，但泛化能力弱。默认为1时，训练时加上了各样本参数时则会对其训练效果产生极大影响，最终导致分类错误率增加，将其设置为300之后则效果变好。 算法表现差异分析 将上述测试结果按照准确率进行排序结果如下： 集成算法 基础算法 迭代次数 训练集大小 准确率 Bagging Decision Tree 1 994 0.824618 AdaBoost.M1 Decision Tree 1 994 0.847949 Bagging KNN 1 994 0.849558 AdaBoost.M1 SVM 21 994 0.86243 AdaBoost.M1 SVM 21 1988 0.873693 Bagging SVM 21 994 0.881738 Bagging KNN 21 994 0.881738 AdaBoost.M1 Decision Tree 21 994 0.881738 AdaBoost.M1 Decision Tree 21 1988 0.881738 Bagging KNN 41 994 0.884151 AdaBoost.M1 SVM 1 994 0.884956 Bagging KNN 21 1988 0.88576 Bagging SVM 1 994 0.886565 Bagging SVM 21 1988 0.895414 Bagging SVM 21 3976 0.895414 AdaBoost.M1 SVM 41 994 0.896219 Bagging KNN 21 3976 0.897828 Bagging Decision Tree 41 994 0.900241 AdaBoost.M1 Decision Tree 41 994 0.901046 Bagging Decision Tree 21 3976 0.901046 AdaBoost.M1 Decision Tree 21 3976 0.901046 AdaBoost.M1 SVM 21 3976 0.90185 Bagging Decision Tree 21 1988 0.902655 Bagging Decision Tree 21 994 0.913113 Bagging SVM 41 994 0.913113 可以发现，综合表现最好的是Bagging + Dtree算法，平均来看，Bagging集成方法优于AdaBoost算法，这与经验相悖，分析可能的原因是：实验时未考虑各特征的权重问题，每个特征的计算方法不同，归一化时并没有考虑这一点，这些可能使得当AdaBoost算法专注于那些分错的样本时其实违背了数据的特征规律。 Bagging算法和AdaBoost算法有什么区别 Bagging 算法流程： 给定一个大小为n的训练集D，Bagging算法从中均匀、有放回地选出T个大小为n1的子集Di，作为新的训练集。在这m个训练集上使用分类、回归等算法，则可得到m个模型，再通过取平均值、取多数票等方法，即可得到Bagging的结果 算法特点： Bagging要求基分类器的学习算法不稳定，也就是当数据发生小变化时，训练的分类器会产生很大不同，依次来增加基分类器的多样性，使得分类系统更加稳定，泛化能力更强。 AdaBoost 算法流程 AdaBoost方法是一种迭代算法，在每一轮中加入一个新的弱分类器，直到达到某个预定的足够小的错误率。 每一个训练样本都被赋予一个权重，表明它被某个分类器选入训练集的概率。 如果某个样本点已经被准确地分类，那么在构造下一个训练集中，它被选中的概率就被降低； 相反，如果某个样本点没有被准确地分类，那么它的权重就得到提高。 通过这样的方式，AdaBoost方法能“聚焦于”那些较难分（更富信息）的样本上。 在具体实现上，最初令每个样本的权重都相等， 对于第k次迭代操作，我们就根据这些权重来选取样本点，进而训练分类器Ck。 然后就根据这个分类器，来提高被它分错的的样本的权重，并降低被正确分类的样本权重。 然后，权重更新过的样本集被用于训练下一个分类器Ck[2]。整个训练过程如此迭代地进行下去。 算法特点 具有较低的泛化误差（low generalization） 不容易出现overfiting(过拟合)现象 算法差异 Bagging算法的训练集是从原数据集中有放回的抽样得到的（原数据集的一部分），每个基分类器是相互独立的，并列的。因为每个基分类器训练方法独立且相同，所以最后分类器等权重投票。 而在Boosting算法中，基分类器是依次训练的，因为分错的点在接下来的训练时会更加的被侧重，也就是说，每个基分类器的训练都是建立在之前基分类器的表现基础之上的。最后分类器加权投票。 通常来说，基分类器不稳定时，Bagging算法的表现会比较好，大多数情况下AdaBoost算法表现较好，但是也容易出现过拟合的情况，比如说本次实验中（【SVM的参数设置】一节所述），当基分类器为SVM时，若C参数设置为1时，则会出现最终分类准确率仅为69%的情况 什么样的组合最好，为什么 进行相应的参数调整之后，各个算法组合之间的差异并不是特别大，不过Bagging + Dtree的稳定性应该是最高的，其效果也最好，实际上Bagging + SVM的效果也比较好，此次测试SVM效果劣于Dtree可能是SVC的参数设置不够好 代码说明： ContentNewLinkAllSample.csv : 原始数据 README.md : 说明文档 base_cls.py : 基础分类器的分类效果测试, python base_cls.py即可运行 ensemble.py : 集成学习算法 main.py : 测试程序 share.py : 一些配置函数 参考资料 曾刚,李宏.一个基于现实世界的大型Web参照数据集——UK2006 Datasets的初步研究[J].企业技术开发（学术版）,2009,28(5):16-17,31. SVM: Weighted samples http://scikit-learn.org/stable/auto_examples/svm/plot_weighted_samples.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lec17]]></title>
      <url>%2F2017%2F04%2F26%2FLec17%2F</url>
      <content type="text"><![CDATA[1 在报告中通过枚举和分类方法或反证法说明Peterson算法的正确性。 参考： https://en.wikipedia.org/wiki/Peterson%27s_algorithm https://en.wikipedia.org/wiki/Dekker%27s_algorithm 解：Peterson 算法是满足两个线程之间互斥的算法，针对P0和P1两个线程，其执行的代码分别为 12345678910111213141516171819202122P0: flag[0] = true;P0_gate: turn = 1; while (flag[1]== true &amp;&amp; turn == 1) &#123; // busy wait &#125; // critical section ... // end of critical section flag[0] = false;P1: flag[1] = true;P1_gate: turn = 0; while (flag[0]==true &amp;&amp; turn == 0) &#123; // busy wait &#125; // critical section ... // end of critical section flag[1] = false; 首先，需要明确，如果\(P_0\) 和\(P_1\)两个线程同时试图进入临界区，即两个线程都试图设置turn为对方，即发生了同时写操作，这时总线仲裁会确定一个写操作的先后顺序，那么被总线仲裁先写的则会被覆盖，也就是先写的会先被允许进入临界区。 下面证明Peterson算法的正确性，即满足 空闲则入，忙则等待，有限等待的访问规则 互斥：只有当 flag[j] == FALSE 或 turn == i 时 Pi 才进入临界区。假设 Pi 和 Pj 同时进入临界区，则 flag[0] == flag[1] == TRUE， 而turn 只能为 0 或 1，所以只有一个进程（假设 turn == i）Pi 能够跳出 While 语句进入临界区。此外，只要 Pi 在临界区内，flag[i] == TRUE &amp;&amp; turn == i 就始终成立，所以 Pi 在临界区执行期间，Pj 将始终等待或执行剩余区内容。这就意味着其满足忙则等待规则 空闲则入，有限等待：进程 Pi 仅在 flag[j] == True 且 turn == j 的情况下才会被阻塞，若 Pj 不准备进入临界区，则 flag[j] == False，此时 Pi 可以进入；若 Pj 当前也在请求进入临界区，则 flag[j] == True，此时由 turn 决定哪个进程进入临界区。假设此时 Pj 进入临界区，当 Pj 退出临界区时会设置 flag[j] 为 False 使 Pi 进入临界区；如果 Pj 剩余区执行速度非常快，又重新申请进入临界区，此时 Pj 设置 flag[j] 为 TRUE，同时 turn 被设置为 i。因此 Pi 一定会进入临界区（发展），并且最多需要等待一次。即满足空闲则如，以及有限等待规则 2 在报告中准确描述Eisenberg同步算法，并通过枚举和分类方法或反证法说明说明Eisenberg同步算法的正确性。用C或PYTHON实现Eisenberg同步算法和测试用例。在报告中给出测试结果简单描述。 参考： https://en.wikipedia.org/wiki/Eisenberg_%26_McGuire_algorithm https://en.wikipedia.org/wiki/Lamport%27s_bakery_algorithm http://blog.csdn.net/asce1885/article/details/5735565 piazza.com的本课程网页中，搜索“Eisenberg”，可看到3个相关帖子集合 算法描述 Eisenberg同步算法给每个对某个共享资源有需求的n个进程中的每一个有一个唯一的序号，形成一个圈，根据这个圈分发资源。当进程i对共享资源有需求时，先声明对其需求，即flag[i] = WAITING，表示进程i想进入临界区，此时检查进程i前面是否有其他进程已占用该资源，若有，则等待其执行完毕，如果没有，则尝试占有资源（flag[i]=ACTIVE），如果此时其他进程也处于ACTIVE状态，则进程i占有失败，重复上述操作并回到WAITING态，直到占有成功]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[实验 1 Cache 替换策略设计与分析]]></title>
      <url>%2F2017%2F04%2F23%2FCRC_report%2F</url>
      <content type="text"><![CDATA[实验目的 深入理解各种不同的 Cache 替换策略 理解学习不同替换策略对程序运行性能的影响 动手实现自己的 Cache 替换策略 实验要求 理解学习 LRU 及其它已经提出的 Cache 替换策略 在提供的模拟器上实现自己设计的 Cache 替换策略 通过 benchmark 测试比较不同的 Cache 替换策略 在实验报告中简要说明不同 Cache 替换策略的核心思想和算法 在实验报告中说明自己是怎样对不同的 Cache 替换策略进行测试的 在实验报告中分析不同替换策略下，程序的运行时间、Cache 命中率受到的影响 已有替换策略分析 常见的Cache替换策略有LRU，FIFO, LFU等，本次实验基于MK Qureshi于2007年的Adaptive insertion policies for high performance caching一文提出的LRU Insertion Policy算法进行的实现。 在该文中，作者指出，当程序重用工作集大于可用Cache时或者其存储访问具有低局部相关性时，Cache替换策略中最常用的LRU策略表现出十分低下的命中率。大量新替换入Cache的行对命中率的贡献为零，而原本可能命中的行则由于长期不被访问而替换出Cache。针对这种情况，该文提出了以下一些改进策略： LRU Insertion Policy (LIP) 。该策略将所有替换入Cache的行置于LRU端。相对于传统策略将所有替换入的行置于MRU端，LIP使一部分行得以驻留于Cache中，其驻留时间能比Cache本身容量更长。LIP策略能够很好地应对Thrashing，尤其对于循环访问内存的程序其性能近似于OPT策略。 Bimodal Insertion Policy (BIP)。BIP策略是对LIP的加强和改进，新换入的行会小概率地被置于MRU端。BIP可以很好地响应Working Set的切换，并保持一定的命中率。 Dynamic Insertion Policy (DIP) 能动态地在LRU和BIP间切换，选择其中命中率较高的策略执行后续指令。DIP对于LRU-friendly的程序块使用LRU策略，对于LRU-averse的程序块使用DIP策略，以求通用效率。对于1MB16路L2 Cache，DIP策略较LRU降低21%的失配率。 LIP和BIP两种策略对于LRU-friendly（高局部性）的程序，性能均不佳。 我实现的替换策略 考虑到实现难度，本次实验我实现了MK Qureshi提出的三个算法中的第一个LIP算法，具体的实现为： 当访存命中时，将命中的Cache块放到对应栈的LRU端，其他块依次移位 当Cache缺失时，替换策略与LRU一致，这时需要将新换入的Cache块放到对应栈的MRU端 在实际的实验过程中发现，LIP算法并没有很明显的改进LRU算法，约有\(\frac{1}{3}\)的测试样例中LIP算法表现更好，\(1/2\)的测试样例中LRU算法表现更好，由此，我采用了一个稍大概率值使得其一部分情况下采用LRU算法，一部分情况下采用LIP算法，考虑到LRU算法在大多数情况下表现较好，这里的概率值设置得稍大一些，置为了30%,即对于新换入的Cache块，有30%的概率会被放置在LRU端，有70%的概率会被置于MRU端 具体实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// 这个函数是根据实现的Cache替换策略函数 INT32 CACHE_REPLACEMENT_STATE::Get_LIP_Victim( UINT32 setIndex )&#123; // Get pointer to replacement state of current set LINE_REPLACEMENT_STATE *replSet = repl[ setIndex ]; INT32 lipWay = 0; // Search for victim whose stack position is assoc-1 // 被替换的块策略与LRU一致，选择栈底被替换出去 for(UINT32 way=0; way&lt;assoc; way++) &#123; if( replSet[way].LRUstackposition == (assoc-1) ) &#123; lipWay = way; break; &#125; &#125; // return lru way return lipWay;&#125;// This function implements the LIP update routine for the traditional //// LIP replacement policy. The arguments to the function are the physical //// way and set index. void CACHE_REPLACEMENT_STATE::UpdateLIP( UINT32 setIndex, INT32 updateWayID, bool cacheHit )&#123; // Determine current LRU stack position UINT32 currLRUstackposition = repl[ setIndex ][ updateWayID ].LRUstackposition; // 如果hit // Update the stack position of all lines before the current line // Update implies incremeting their stack positions by one if (cacheHit) &#123; for(UINT32 way=0; way&lt;assoc; way++) &#123; if( repl[setIndex][way].LRUstackposition &lt; currLRUstackposition ) &#123; repl[setIndex][way].LRUstackposition++; &#125; &#125; // Set the LRU stack position of new line to be zero repl[ setIndex ][ updateWayID ].LRUstackposition = 0; &#125; else &#123; // Cache缺失时, 把新换入的Cache的行置于LRU端 repl[ setIndex ][ updateWayID ].LRUstackposition = assoc - 1; &#125; &#125;void CACHE_REPLACEMENT_STATE::UpdateBIP( UINT32 setIndex, INT32 updateWayID, bool cacheHit )&#123; // Determine current LRU stack position UINT32 currLRUstackposition = repl[ setIndex ][ updateWayID ].LRUstackposition; // 如果hit // Update the stack position of all lines before the current line // Update implies incremeting their stack positions by one if (cacheHit || (rand()%100 &lt; probability)) &#123; for(UINT32 way=0; way&lt;assoc; way++) &#123; if( repl[setIndex][way].LRUstackposition &lt; currLRUstackposition ) &#123; repl[setIndex][way].LRUstackposition++; &#125; &#125; // Set the LRU stack position of new line to be zero repl[ setIndex ][ updateWayID ].LRUstackposition = 0; &#125; else &#123; // Cache缺失时, 把新换入的Cache的行置于LRU端 repl[ setIndex ][ updateWayID ].LRUstackposition = assoc - 1; &#125; &#125; 替换策略测试 测试方法 本次实验中将29个测试程序分别采用LRU,LIP算法进行了测试，测试时的Cache设置为 UL3:1024:64:16 即 实验在第3级Cache上进行，统一存储指令和数据， Cache 大小为 1024KB Cache 行大小为 64B 16路组相连 在测试时我利用shell脚本自带的time命令输出其运行时间(取real time结果)以此代表程序运行时间，此外，我还采用了CPI,缺失率作为其评价指标 分析不同替换策略下，程序的运行时间、Cache 命中率受到的影响 LRU和LIP算法比较 程序 LRU_time LIP_time less_time LRU_CPI LIP_CPI Less_cpi LRU_miss LIP_miss less miss perlbench 17.070 16.420 LIP 0.642823 0.669326 LRU 40.7952 44.9668 LRU bzip2 123.840 120.870 LIP 0.554642 0.571873 LRU 61.7369 55.3261 LIP gcc 134.380 130.780 LIP 0.614864 0.575939 LIP 42.7521 38.5965 LIP bwaves 118.230 117.520 LIP 0.253088 0.253088 = 99.6634 99.6634 = gamess 133.080 135.110 LRU 0.30022 0.312251 LRU 26.3204 92.0923 LRU mcf 163.610 153.580 LIP 2.55358 2.04087 LIP 75.676 59.7033 LIP milc 148.670 144.780 LIP 1.14939 1.1807 LRU 77.0164 79.3471 LRU zeusmp 148.800 133.400 LIP 0.451633 0.452046 LRU 80.81 82.492 LRU gromacs 143.230 153.090 LRU 0.607769 0.664129 LRU 71.1979 89.1534 LRU cactusADM 133.370 130.880 LIP 0.44249 0.378492 LIP 76.1164 63.7024 LIP leslie3d 133.210 133.850 LRU 1.50626 1.4344 LIP 84.0284 79.7774 LIP namd 112.000 111.370 LIP 0.273795 0.273797 LRU 66.2603 66.2661 LRU gobmk 127.020 127.540 LRU 0.383876 0.388093 LRU 14.919 15.5215 LRU dealII 130.630 131.960 LRU 0.463916 0.446134 LIP 45.0892 47.2678 LRU soplex 72.310 75.080 LRU 0.356909 0.431378 LRU 15.2011 35.9993 LRU povray 134.860 134.040 LIP 0.360431 0.360387 LIP 39.9258 39.7901 LIP calculix 130.460 127.370 LIP 0.321346 0.359601 LRU 34.05 53.1214 LRU hmmer 133.820 135.260 LRU 0.258513 0.258513 = 71.4736 71.4868 LRU sjeng 129.020 134.210 LRU 0.323006 0.322841 LIP 93.5415 93.3249 LIP GemsFDTD 153.820 171.260 LRU 0.368143 0.368143 = 84.1525 84.1525 = libquantum 147.090 132.630 LIP 0.272749 0.272749 = 100.0 100.0 = h264ref 137.550 129.450 LIP 0.28787 0.292871 LRU 70.0086 72.4714 LRU tonto 122.590 122.090 LIP 0.347856 0.34803 LRU 78.8694 79.2837 LRU lbm 175.980 175.560 LIP 1.15379 1.15439 LRU 99.9725 99.7331 LIP omnetpp 156.400 150.580 LIP 0.41278 0.412729 LIP 59.4443 59.2859 LIP astar 161.890 152.050 LIP 0.267647 0.267647 = 5.84718 5.84718 = sphinx3 148.620 145.960 LIP 0.445644 0.445645 LRU 97.156 97.1648 LRU xalancbmk 163.490 155.190 LIP 0.414993 0.411322 LIP 66.2759 63.1589 LIP specrand 90.180 89.100 LIP 0.336211 0.336348 LRU 95.9373 97.6647 LRU LRU和BIP算法比较 程序 LRU_time BIP_time less_time LRU_CPI BIP_CPI Less_cpi LRU_miss BIP_miss less miss perlbench 17.070 17.490 LRU 0.642823 0.653642 LRU 40.7952 42.4235 LRU bzip2 123.840 144.210 LRU 0.554642 0.570891 LRU 61.7369 59.0281 BIP gcc 134.380 167.270 LRU 0.614864 0.575685 BIP 42.7521 37.0908 BIP bwaves 118.230 152.430 LRU 0.253088 0.253088 = 99.6634 99.6634 = gamess 133.080 159.270 LRU 0.30022 0.304011 LRU 26.3204 30.4442 LRU mcf 163.610 182.510 LRU 2.55358 2.27179 BIP 75.676 67.9679 BIP milc 148.670 137.590 BIP 1.14939 1.14853 BIP 77.0164 76.2688 BIP zeusmp 148.800 127.220 BIP 0.451633 0.451496 BIP 80.81 81.883 LRU gromacs 143.230 148.100 LRU 0.607769 0.625808 LRU 71.1979 74.1585 LRU cactusADM 133.370 141.210 LRU 0.44249 0.368551 BIP 76.1164 62.9769 BIP leslie3d 133.210 147.700 LRU 1.50626 1.44446 BIP 84.0284 73.9532 BIP namd 112.000 122.800 LRU 0.273795 0.273801 LRU 66.2603 66.2719 LRU gobmk 127.020 144.260 LRU 0.383876 0.384353 LRU 14.919 14.2733 BIP dealII 130.630 143.810 LRU 0.463916 0.42624 BIP 45.0892 35.1431 BIP soplex 72.310 79.220 LRU 0.356909 0.366633 LRU 15.2011 17.9177 LRU povray 134.860 165.980 LRU 0.360431 0.360417 BIP 39.9258 39.858 BIP calculix 130.460 145.710 LRU 0.321346 0.332007 LRU 34.05 39.1968 LRU hmmer 133.820 157.060 LRU 0.258513 0.258513 = 71.4736 71.4868 LRU sjeng 129.020 166.850 LRU 0.323006 0.322882 BIP 93.5415 93.359 BIP GemsFDTD 153.820 169.420 LRU 0.368143 0.368143 = 84.1525 84.1525 = libquantum 147.090 138.730 BIP 0.272749 0.272749 = 100.0 100.0 = h264ref 137.550 138.360 LRU 0.28787 0.289044 LRU 70.0086 70.8777 LRU tonto 122.590 143.870 LRU 0.347856 0.347883 LRU 78.8694 78.898 LRU lbm 175.980 149.190 BIP 1.15379 1.15361 BIP 99.9725 99.9688 BIP omnetpp 156.400 161.910 LRU 0.41278 0.412755 BIP 59.4443 59.3624 BIP astar 161.890 156.370 BIP 0.267647 0.267647 = 5.84718 5.84718 = sphinx3 148.620 136.150 BIP 0.445644 0.44566 LRU 97.156 97.2443 LRU xalancbmk 163.490 142.850 BIP 0.414993 0.421033 LRU 66.2759 67.5348 LRU specrand 90.180 85.870 BIP 0.336211 0.336235 LRU 95.9373 96.1932 LRU 算法表现统计 LRU与LIP算法 CPI值: LRU算法15次更小, LIP算法9次更小 运行时间:LRU算法9次更小, LIP算法20次更小 缺失率: LRU算法15次更小, LIP算法10次更小 LRU与BIP算法 CPI值: LRU算法13次更小, BIP算法11次更小 运行时间:LRU算法21次更小, BIP算法8次更小 缺失率: LRU算法13次更小, BIP算法12次更小 结果分析 由统计结果分析，大概一半的测试程序中，LRU的算法的缺失率和CPI指标比LIP算法更优，但是仍然有不少测试样例显示LIP算法表现更好，而这些程序即是前文所说的局部相关性不是特别高的情况，而LIP算法的运行时间明显更优。 新加入的第三种策略（类似于BIP算法）在缺失率上的表现较LIP稍好一些（运行时间偏慢应该是因为在其中做了取随机数和取模的运算操作），其表现与LRU表现不分上下，可以看做是LRU算法和LIP算法的一个综合，可以看出不同的算法对程序局部性的适应度是有区别的，而测试程序的局部性好坏也极大地影响着其缺失率，在实际的操作中综合LIP和LRU算法应该是比较好的。根据测试结果推测，当概率值设置为50%时BIP算法表现可能会优于LRU算法 由此可以分析，通常来说，程序的局部性更强时LRU算法表现会比较好，当程序的局部性表现有较大波动时，LIP一类改进算法会表现更好（即缺失率会降低），实际上，DIP算法的动态调节表现应该是最好的，不过出于实现难度本次实验没有进行实现。 附件： 123456789101112131415161718192021## 算法文件replacement_state.cppreplacement_state.h## 实验数据results/├── get_time.py // 通过运行数据提取运行结果表格记录├── time_bip.txt // 算法3的运行时间结果├── log_all.txt // 分别使用LRU算法和LIP算法运行29个测试程序的输出结果├── bip_log.txt // 算法3的运行记录├── name.txt├── run.sh // 运行脚本，在CRC/项目根目录下运行即可├── runs // 解压后的测试结果│ ├── LIP_GemsFDTD.stats│ ├── LIP_astar.stats│ ├── LIP_bwaves.stats│ ├── LIP_bzip2.stats| ......|└── time_log.txt // 每个程序的运行时间记录---- 参考文献 [1] Moinuddin K. Qureshi , Aamer Jaleel , Yale N. Patt , Simon C. Steely , Joel Emer, Adaptive insertion policies for high performance caching, Proceedings of the 34th annual international symposium on Computer architecture(ISCA), June 09-13, 2007, San Diego, California, USA]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[lec16_exe]]></title>
      <url>%2F2017%2F04%2F22%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2Flec16-exe%2F</url>
      <content type="text"><![CDATA[请描述stride调度算法的目标，思路和算法设计（要求写出伪代码），并分析stride调度算法只采用整数运算是如何避免stride计算溢出问题的。 目标 在round-robin调度算法的基础上，希望调度器能更智能地为每个进程分配合理的CPU资源，假设我们为不同的进程分配不同的优先级，则我们有可能希望每个进程得到的时间资源与他们的优先级成正比关系 思路 1、为每个runnable的进程设置一个当前状态stride，表示该进程当前的调度权。另外定义其对应的pass值，表示对应进程在调度后，stride 需要进行的累加值，该pass值只与进程的优先级有关 2、每次需要调度时，从当前 runnable 态的进程中选择 stride最小的进程调度。对于获得调度的进程P，将对应的stride加上其对应的步长pass 3、在一段固定的时间之后，回到 2.步骤，重新调度当前stride最小的进程。 算法设计 123456789101112131415161718192021222324252627init() // 初始化队列，proc['stride']=0, proc['pass'] = BIG_STRIDE/proc['priority']def schedule(): while True: if runnable_list is null: continue # 就绪队列为空， 等待就绪队列 cur_run = get_proc_min_stride(runnable_list) # 选取stride值最小的进程 cur_run['stride'] += cur_run['pass'] #被选中队列的stride值+步长pass cur_run['time_slice'] = time_slice # 分配时间片 break;def proc_tick(): # 时钟 if cur_run['run_time'] &gt;= cur_run['running_time']: # 进程运行完毕 do_exit(cur_run) schedule() if cur_run['time_slice'] == 0: # 时间片用完，准备调度 cur_run['need_sche'] = 1 schedule() else: cur_run['time_slice'] -= 1while True: proc_tick() sleep(1) 分析stride调度算法只采用整数运算是如何避免stride计算溢出问题的。 stride 算法是通过无符号数的有符号比较来解决溢出问题的，其最终的比较是通过将两个待比较的stride相减，结果以带符号整数形式进行比较。 在stride算法中，步长值设置为 P-&gt;pass = BIG_STRIDE / P-&gt;priority, 这样可以使进程的步长只与优先级相关，同时，这个设定使得每次进程的stride值得增量都不会超过BIG_STRIDE, 其中，BIG_STRIDE值是一个预先设定的大常数，这个大常数的设置是保证stride算法即使在溢出时仍然能够得到正确运行结果的关键。 设进程A、B的stride值分别为a、b， 假设一开始a=b,设进程B先被调度执行，此时b增加B_pass： 如果此时B的stride值未溢出，那么自然有signed(a-(b+B_pass))&lt;0,下一次轮到A被调度执行，a增加 如果此时B的stride值溢出，以32位整数为例，则有\(b+B\_pass\ge2^{32}\),溢出后的实际值会是\(b&#39; = b+B\_pass - 2^{32}\), 此时为保证仍能正确运行，需要保证\(signed(a-b) \le 0\),则需要\(A\ge b + B\_pass -2^{32} + 2^{31} = b+BIG\_STRIDE-2^{31}\), 从而需要保证BIG_STRIDE ＜ 2^31,亦即BIG_STRIDE需要设置为最大的有符号整数值。 基于这种特殊的考虑，才能使得即使stride有可能溢出，仍能得到理论上的当前最小stride。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lec15练习]]></title>
      <url>%2F2017%2F04%2F19%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2FLec15%E7%BB%83%E4%B9%A0%2F</url>
      <content type="text"><![CDATA[请证明短进程优先算法具有最小平均周转时间。 证明： 设一组就绪进程 \(\{p_1, p_2,...p_n\}\), 其运行时间依次对应为 \(\{r_1, r_2,...,r_n\}\), 且\(\forall i \le j, r_i \le r_j\) 则按照短进程优先原则，其平均周转时间为： \[avg_r = \frac{r_1 + (r_1 + r_2) + ... + (r_1 +...+r_n)}{n} = \frac{\sum _{i=1}^{n}{(n-i+1)r_i}}{n}\] 即需要证明上述排列方式计算的\(avg_r\)最小，采用反证法，假设存在一个进程运行顺序使得其平均周转时间更小，为简单起见，不妨设，任意交换原序列中两个进程m,n，即序列变为\(\{p_1, p_2,...,p_n,...,p_m,...,p_n\}\)则其平均周转时间为： \[\begin{align} avg_r &amp;= \frac{r_1 +(r_1 + r_2) +...(r_1 +...+r_{m-1}+r_n)+(r_1 +...+r_{m-1}+r_n + r_{m+1}) +... }{n} \\ &amp; = \frac{\sum _{i=1}^{n}{(n-i+1) \cdot r_i} + (m-n)\cdot(r_m - r_n)}{n} \\ &amp; \ge \frac{\sum _{i=1}^{n}{(n-i+1)r_i}}{n} \end{align}\] 得证。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[图片搜索实验]]></title>
      <url>%2F2017%2F04%2F19%2F%E5%9B%BE%E7%89%87%E6%90%9C%E7%B4%A2%E5%AE%9E%E9%AA%8C%2F</url>
      <content type="text"><![CDATA[基本任务 查找资料，跑通流程 【部署方法】 使用MyEclipse导入该工程，运行ImageIndexer建立索引生成forIndex文件夹 将forIndex文件夹拷贝到Tomcat的安装目录下（取决于具体运行环境，有的可能需要拷贝到Tomcat_ROOT/bin/目录下） 此外，由于我在ImageIndexer.java中修改了图片存放位置，因此一定要重新运行ImageIndexer.java生成forIndex文件并拷贝过去才行（也可直接拷贝提交的forIndex文件） 将图片解压至/Tomcat_ROOT/webapps/ROOT/pictures/下， 访问 http://localhost:8080/ImageSearch/imagesearch.jsp 即可进行搜索显示 根据ImageIndexer中对Sogou图片分类目录的索引，对Sogou图片搜索热门查询对应图片建立索引 首先运行 Encode_gbk_to_utf8.java将gbk编码的threeMonth.xml转换为utf-8编码格式， 1&lt;pic id=&quot;278535&quot; query=&quot;西藏&quot; total_click=&quot;6977&quot; click=&quot;14&quot; pic_url=&quot;http://travel.bjhotel.cn/tour/Article/UploadFiles/200803/2008030608595904.jpg&quot; page_url=&quot;http://travel.bjhotel.cn/tour/Article/fsyj/xz&quot; locate=&quot;pictures/threeMonth/西藏/274863.jpg&quot; /&gt; 索引结果 threeMonth.xml中对每个搜索词的描述有query，click，total_click，page_url等， 本次索引的field采取query(点击频度暂未找到合适的方法考虑到评分系统内，因此并未考虑该参数) 由于threeMonth图片集太大，而索引文件中本身有pic_url，因此,我直接采用的是将pic_url作为其picPath,同时将imageshow.jsp中的图片路径改为相对路径，确保图片正确显示（sougou图片集的ImageIndexer.java中需要在路径前加’/’） 1234567891011NamedNodeMap map=node.getAttributes();Node locate=map.getNamedItem(&quot;locate&quot;);Node url = map.getNamedItem(&quot;pic_url&quot;);// Node bigClass=map.getNamedItem(&quot;bigClass&quot;);// Node smallClass=map.getNamedItem(&quot;smallClass&quot;);Node query=map.getNamedItem(&quot;query&quot;);String absString=query.getNodeValue();Document document = new Document();// 采用网页链接作为图片地址Field PicPathField = new Field( &quot;picPath&quot; ,url.getNodeValue(),Field.Store.YES, Field.Index.NO);Field abstractField = new Field( &quot;abstract&quot; ,absString,Field.Store.YES, Field.Index.ANALYZED); 运行结果 12345678910111213141516171819202122232425262728293031323334353637process 0process 10000process 20000process 30000process 40000process 50000process 60000process 70000process 80000process 90000process 100000process 110000process 120000process 130000process 140000process 150000process 160000process 170000process 180000process 190000process 200000process 210000process 220000process 230000process 240000process 250000process 260000process 270000process 280000process 290000process 300000process 310000process 320000process 330000process 340000average length = 4.73518total 340518 documents 根据Simple实现的Lucene评分核心类，了解Lucene评分架构，在SimpleScorer.java中实现BM25模型算法（实现很简单） 给定一个查询 Q,包含了关键词 \(q_1, ..., q_n\), 利用BM25算法计算出的文档D的得分为: \[{\text{score}}(D,Q)=\sum _{i=1}^{n}{\text{IDF}}(q_{i})\cdot {\frac {f(q_{i},D)\cdot (k_{1}+1)}{f(q_{i},D)+k_{1}\cdot \left(1-b+b\cdot {\frac {|D|}{\text{avgdl}}}\right)}}\] 其中： \(f(q_i, D)\) 表示关键词\(q_i\)在文档D中的频率 |D| 是文档D的长度 avgdl 是平均文档长度 \(k_1\) 和 b 是调节因子, 通常\(k_1 \in [1.2,2.0]\) , b = 0.75 （本实验中\(k_i = 2.0\)） \(IDF(q_i)\) 是查询词\(q_i\)的IDF (inverse document frequency) 权重，是根据每个关键词在所有文档中出现的次数多少对该关键词的一个调整,其计算方式为：\[\text{IDF}(q_i) = \log \frac{N - n(q_i) + 0.5}{n(q_i) + 0.5}\] 其中N代表文档总数，\(n(q_i)\)是包含该关键词的文档个数 查阅Lucene可知，norm的计算为lengthNorm = 1.0 / Math.sqrt(numTerms) 具体实现为： 123456789// 文档termDocs中关键词qi的频率float f_qi_D = this.termDocs.freq();// doc对应的文档长度计算， norms[i] = 1/sqrt(length[i])float norm = Similarity.decodeNorm(this.norms[doc]);// 文档termDocs的长度float length = 1 / (norm * norm);// BM25算法return idf * f_qi_D * (this.K1 + 1)/ (f_qi_D + this.K1 *(1 - this.b + this.b * length/this.avgLength)); 利用Lucene提供的评分核心类实现VSM模型，并与BM25进行对比 原始评分算法即为VSM。 BM25和VSM算法的搜索结果没有明显差异，score值是明显不同的（这里的score值是开启了多关键词查询之后的结果） BM25算法 1234567891011=========下面是普通merge的结果==========doc=15007 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/0.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15008 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/10.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15009 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/11.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15010 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/12.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15011 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/13.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15012 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/14.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15013 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/15.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15014 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/16.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15015 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/17.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15016 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/18.jpg tag= 精美壁纸 人物壁纸 港台美女 VSM算法 1234567891011=========下面是普通merge的结果==========doc=15007 score=5.85986 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/0.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15008 score=5.85986 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/10.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15009 score=5.85986 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/11.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15010 score=5.85986 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/12.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15011 score=5.85986 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/13.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15012 score=5.85986 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/14.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15013 score=5.85986 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/15.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15014 score=5.85986 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/16.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15015 score=5.85986 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/17.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15016 score=5.85986 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/18.jpg tag= 精美壁纸 人物壁纸 港台美女 扩展任务 基于语料库所提供的图片所在网页内容，对图片描述文本进行扩充，实现基于图片描述文本的图像检索 基于BM25模型实现对于查询词的分词检索（参考Lucene的MultiTermQuery对应的核心评分类实现，也可参考网上的开源代码，最终大作业时需要） 分词工具采用IKAnalyzer, 具体实现参考了IKAnalyzer中文分词器[http://blog.sina.com.cn/s/blog_7663527601012vdg.html]一文。 一开始的实现是直接将查询词使用IKAnalyzer进行分词，然后将每个关键词分别作为搜索词去查询，然后将查询结果merge起来，按照得分高低排序。如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344//基于Lucene实现Analyzer analyzer = new IKAnalyzer(true);//true智能切分StringReader reader = new StringReader(queryString);TokenStream ts = analyzer.tokenStream("", reader);CharTermAttribute term = ts.getAttribute(CharTermAttribute.class);List&lt;String&gt; key_word = new ArrayList&lt;String&gt;(); while(ts.incrementToken())&#123; // System.out.print(term.toString()+"|"); key_word.add(term.toString());&#125;System.out.println(key_word);TopDocs[] resultsArray = new TopDocs[key_word.size()];for(int j = 0; j &lt; key_word.size(); ++j) &#123; // 针对每个搜索词去查询 resultsArray[j] = search.searchQuery(key_word.get(j), "abstract", 100);&#125;// TopDocs results=search.searchQuery(queryString, "abstract", 100);TopDocs results = TopDocs.merge(null, 100, resultsArray);System.out.println("=========下面是普通merge的结果==========");if (results != null) &#123; ScoreDoc[] hits = showList(results.scoreDocs, page); if (hits != null) &#123; // tags = new String[hits.length]; // paths = new String[hits.length]; for (int i = 0; i &lt; hits.length &amp;&amp; i &lt; PAGE_RESULT; i++) &#123; Document doc = search.getDoc(hits[i].doc); System.out.println("doc=" + hits[i].doc + " score=" + hits[i].score + " picPath= " + doc.get("picPath")+ " tag= "+doc.get("abstract")); // tags[i] = doc.get("abstract"); // paths[i] = picDir + doc.get("picPath"); &#125; &#125; else &#123; System.out.println("page null"); &#125;&#125;else&#123; System.out.println("result null");&#125; 但是在实际操作中发现，这样的查询操作是由问题的，表现极差，无法达到搜索者预期的多次查询需求，于是通过进一步的搜索和查询相关资料，最后决定采用 MultiFieldQueryParser的方式进行多关键词查询。实现参考博客- 关键词高亮（lucene笔记) http://www.jianshu.com/p/055ddb99819d 该函数可以实现多个关键词在不同的field中进行查询的功能，同时可以设定多个关键词之间的关系：and, not, or, 这里我们采用或的逻辑关系，同时设置field为‘abstract’，具体实现如下： 12345678910111213141516171819202122232425262728293031323334353637//待查找字符串对应的字段String [] to_query = &#123;queryString&#125;;String [] fields = &#123;"abstract"&#125;;//Occur.MUST表示对应字段必须有查询值， Occur.MUST_NOT 表示对应字段必须没有查询值， Occur.SHOULD(结果“或”)Occur[] occ=&#123;Occur.SHOULD&#125;;Query query = null;try &#123; query = MultiFieldQueryParser.parse(Version.LUCENE_35, to_query,fields,occ,analyzer); System.out.println(query);&#125; catch (ParseException e) &#123; // TODO Auto-generated catch block e.printStackTrace();&#125;results = search.searchQuery(query, "abstract", 100);System.out.println("============\n=========下面是MultiFieldQueryParser的结果==========");if (results != null) &#123; ScoreDoc[] hits = showList(results.scoreDocs, page); if (hits != null) &#123; tags = new String[hits.length]; paths = new String[hits.length]; for (int i = 0; i &lt; hits.length &amp;&amp; i &lt; PAGE_RESULT; i++) &#123; Document doc = search.getDoc(hits[i].doc); System.out.println("doc=" + hits[i].doc + " score=" + hits[i].score + " picPath= " + doc.get("picPath")+ " tag= "+doc.get("abstract")); tags[i] = doc.get("abstract"); paths[i] = picDir + doc.get("picPath"); &#125; &#125; else &#123; System.out.println("page null"); &#125;&#125;else&#123; System.out.println("result null");&#125; 实现结果对比： 搜索关键词为 港台女星 12345678910111213141516171819202122232425262728[港台, 女星]org.apache.lucene.search.TopDocs@23506dfborg.apache.lucene.search.TopDocs@75648bd9=========下面是普通merge的结果==========doc=15007 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/0.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15008 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/10.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15009 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/11.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15010 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/12.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15011 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/13.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15012 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/14.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15013 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/15.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15014 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/16.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15015 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/17.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15016 score=8.551983 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/18.jpg tag= 精美壁纸 人物壁纸 港台美女(abstract:港台 abstract:女星)org.apache.lucene.search.TopDocs@292b2c95=====================下面是MultiFieldQueryParser的结果==========doc=42133 score=20.643898 picPath= pictures/sogou/性感女星/港台女星/阿雅/0.jpg tag= 性感女星 港台女星 阿雅doc=42134 score=20.643898 picPath= pictures/sogou/性感女星/港台女星/阿雅/10.jpg tag= 性感女星 港台女星 阿雅doc=42135 score=20.643898 picPath= pictures/sogou/性感女星/港台女星/阿雅/11.jpg tag= 性感女星 港台女星 阿雅doc=42136 score=20.643898 picPath= pictures/sogou/性感女星/港台女星/阿雅/12.jpg tag= 性感女星 港台女星 阿雅doc=42137 score=20.643898 picPath= pictures/sogou/性感女星/港台女星/阿雅/13.jpg tag= 性感女星 港台女星 阿雅doc=42138 score=20.643898 picPath= pictures/sogou/性感女星/港台女星/阿雅/14.jpg tag= 性感女星 港台女星 阿雅doc=42139 score=20.643898 picPath= pictures/sogou/性感女星/港台女星/阿雅/15.jpg tag= 性感女星 港台女星 阿雅doc=42140 score=20.643898 picPath= pictures/sogou/性感女星/港台女星/阿雅/16.jpg tag= 性感女星 港台女星 阿雅doc=42141 score=20.643898 picPath= pictures/sogou/性感女星/港台女星/阿雅/17.jpg tag= 性感女星 港台女星 阿雅doc=42142 score=20.643898 picPath= pictures/sogou/性感女星/港台女星/阿雅/18.jpg tag= 性感女星 港台女星 阿雅 MultiFieldQueryParser查询方式的搜索结果如下： 多关键词查询的靠前结果同时满足两个关键词 港台 女星 第一页 从第6页开始出现了港台美女等相关搜索结果，能够实现关键词或的查询 1234567891011=========下面是MultiFieldQueryParser的结果==========doc=42163 score=17.694769 picPath= pictures/sogou/性感女星/港台女星/安雅/2.jpg tag= 性感女星 港台女星 安雅doc=42164 score=17.694769 picPath= pictures/sogou/性感女星/港台女星/安雅/3.jpg tag= 性感女星 港台女星 安雅doc=42165 score=17.694769 picPath= pictures/sogou/性感女星/港台女星/安雅/4.jpg tag= 性感女星 港台女星 安雅doc=42166 score=17.694769 picPath= pictures/sogou/性感女星/港台女星/安雅/5.jpg tag= 性感女星 港台女星 安雅doc=42167 score=17.694769 picPath= pictures/sogou/性感女星/港台女星/安雅/6.jpg tag= 性感女星 港台女星 安雅doc=42168 score=17.694769 picPath= pictures/sogou/性感女星/港台女星/安雅/7.jpg tag= 性感女星 港台女星 安雅doc=42169 score=17.694769 picPath= pictures/sogou/性感女星/港台女星/安雅/8.jpg tag= 性感女星 港台女星 安雅doc=42170 score=17.694769 picPath= pictures/sogou/性感女星/港台女星/安雅/9.jpg tag= 性感女星 港台女星 安雅doc=15007 score=15.022858 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/0.jpg tag= 精美壁纸 人物壁纸 港台美女doc=15008 score=15.022858 picPath= pictures/sogou/精美壁纸/人物壁纸/港台美女/10.jpg tag= 精美壁纸 人物壁纸 港台美女 港台 女星 第6页 由此可以验证该多关键词查询实现是合理有效的。 注意 注意：在进行多关键词查询时需要修改ImageIndexer中的analyzer，将其设置为智能分词，不然会出现一些奇怪的查询结果： 搜索港台美女时第一页出现的是港台男星 将ImageIndexer的analyzer设置为智能分词即 analyzer = new IKAnalyzer(true);之后的搜索结果 修改后港台美女搜索结果第一页正常 第三页开始出现相关搜索结果 港台男星]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lec13_Lec14]]></title>
      <url>%2F2017%2F04%2F14%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2FLec13-Lec14%2F</url>
      <content type="text"><![CDATA[(spoc) 理解用户进程的生命周期。 练习用的lab5 spoc exercise project source code 掌握知识点 用户进程的启动、运行、就绪、等待、退出 用户进程的管理与简单调度 用户进程的上下文切换过程 用户进程的特权级切换过程 用户进程的创建过程并完成资源占用 用户进程的退出过程并完成资源回收 注意，请关注：内核如何创建用户进程的？用户进程是如何在用户态开始执行的？用户态的堆栈是保存在哪里的？ 阅读代码，在现有基础上再增加一个用户进程A，并通过增加cprintf函数到ucore代码中， 能够把个人思考题和上述知识点中的内容展示出来：即在ucore运行过程中通过cprintf函数来完整地展现出来进程A相关的动态执行和内部数据/状态变化的细节。(越全面细致越好) 请完成如下练习，完成代码填写，并形成spoc练习报告 内核如何创建用户进程的? 123内核会先新建一个内核线程，然后将用户进程信息（数据，代码）导入新建的内核线程然后将用户进程的context， trap_frame信息设置好（执行地址等信息）然后通过forkret从内核态转向用户态，将用户进程放入进程队列中（就绪态），进行进程调度。 用户进程是如何在用户态开始执行的 1通过进程上下文切换switch_to和特权级转换load_esp0完成信息切换，并且设置好其trapframe, 在进程创建完成之后，通过iret切换到用户态进行执行 用户态的堆栈是保存在哪里的？ 1用户态的堆栈是保存在进程的mm结构里。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[安卓开发记录]]></title>
      <url>%2F2017%2F04%2F12%2F%E5%AE%89%E5%8D%93%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95%2F</url>
      <content type="text"><![CDATA[安卓中用户权限设置 位置：AndroidManifest.xml 在package之后， Application 之前 12345678&lt;!--用户权限--&gt;&lt;uses-permission android:name="android.permission.INTERNET" /&gt;&lt;uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" /&gt;&lt;uses-permission android:name="android.permission.ACCESS_WIFI_STATE" /&gt;&lt;uses-permission android:name="android.permission.ACCESS_NETWORK_STATE" /&gt;&lt;!--VPN 权限--&gt;&lt;uses-permission android:name="android.permission.BIND_VPN_SERVICE" /&gt; Android中Intent机制 作用 启动 Activity： Activity 表示应用中的一个屏幕。通过将 Intent 传递给 startActivity()，您可以启动新的 Activity 实例。Intent 描述了要启动的 Activity，并携带了任何必要的数据。 如果您希望在 Activity 完成后收到结果，请调用 startActivityForResult()。在 Activity 的 onActivityResult() 回调中，您的 Activity 将结果作为单独的 Intent 对象接收。如需了解详细信息，请参阅 Activity 指南。 启动服务： Service 是一个不使用用户界面而在后台执行操作的组件。通过将 Intent 传递给 startService()，您可以启动服务执行一次性操作（例如，下载文件）。Intent 描述了要启动的服务，并携带了任何必要的数据。 如果服务旨在使用客户端-服务器接口，则通过将 Intent 传递给 bindService()，您可以从其他组件绑定到此服务。如需了解详细信息，请参阅服务指南。 传递广播： 广播是任何应用均可接收的消息。系统将针对系统事件（例如：系统启动或设备开始充电时）传递各种广播。通过将 Intent 传递给 sendBroadcast()、sendOrderedBroadcast() 或 sendStickyBroadcast()，您可以将广播传递给其他应用。 Intent 结构 action – 想要实施的动作，例: ACTION_VIEW, ACTION_EDIT, ACTION_MAIN, etc. data – 具体的数据，一般由以Uri表示，例：通讯录中的某条记录，会以Uri来表示 category – 为实施的动作添加的额外信息，即Intent组件的种类信息，一个Intent对象可以有任意个category，例：CATEGORY_LAUNCHER 意味着，它应该在启动器中作为顶级应用而存在 type – 显示指定Intent的数据类型（MIME类型 - 多用途互联网邮件扩展，Multipurpose Internet Mail Extensions），例：一个组件是可以显示图片数据的而不能播放声音文件。很多情况下，data类型可在URI中找到，比如content:开头的URI，表明数据由设备上的content provider提供。但是通过设置这个属性，可以强制采用显式指定的类型而不再进行推导 MIME类型有两种：单个记录格式、多个记录格式 component – 指定Intent的目标组件的类名称。通常 Android会根据Intent 中包含的其它属性的信息，比如action、data/type、category进行查找，最终找到一个与之匹配的目标组件。但是，如果 component这个属性有指定的话，将直接使用它指定的组件，而不再执行上述查找过程。指定了这个属性以后，Intent的其它所有属性都是可选的，例如：Intent it = new Intent(Activity.Main.this, Activity2.class); startActivity(it); extras – 附加信息，例如：it.putExtras(bundle) - 使用Bundle来传递数据； 暂存 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152int send_request_ip(int server_socket, JNIEnv *env, jobject obj, jclass cls) &#123; LOGD(&quot;请求ip地址&quot;); // 发送成功 responseIPv4(&quot;166.111.68.250 255.255.255.0 233.233.233&quot;, env, obj, cls); return 0;&#125;int responseIPv4(string ipv4, JNIEnv *env, jobject obj, jclass cls) &#123; LOGD(ipv4); //2 寻找class里面的方法 // jmethodID (*GetMethodID)(JNIEnv*, jclass, const char*, const char*); jmethodID method1 = (*env)-&gt;GetMethodID(env,cls,&quot;responseIPv4&quot;,&quot;(Ljava/lang/String;)I&quot;); if(method1==0)&#123; LOGD(&quot;find method1 error&quot;); return 0; &#125; LOGD(&quot;find method1 &quot;); //3 .调用这个方法 // void (*CallVoidMethod)(JNIEnv*, jobject, jmethodID, ...); (*env)-&gt;CallVoidMethod(env,obj,method1); return 0;&#125;JNIEXPORT jint JNICALLJava_com_example_ipv4_1over_1ipv6_MyVpnService_startVpn(JNIEnv *env, jobject instance) &#123; // TODO /* * 开启VPN服务 * */ // c调用java函数 jclass cls; cls = env-&gt;GetObjectClass(instance); if(cls != NULL) &#123; send_request_ip(0, env, instance, cls); &#125; return 0;&#125; Service机制 启动服务时依次执行onCreate，onStartCommand，onStart；如果在系统显示调用stopService和stopSelf之前终止服务，service再次重启，onStartCommand会被调用，重启服务时依次执行onStartCommand，onStart。无论何时，都会先调用onStartCommand()，在调用onStart()。 onStartCommand返回值 onStartComand使用时，返回的是一个(int)整形。 这个整形可以有四个返回值： 1start_sticky、start_no_sticky、START_REDELIVER_INTENT、START_STICKY_COMPATIBILITY 它们的含义分别是： START_STICKY：如果service进程被kill掉，保留service的状态为开始状态，但不保留递送的intent对象。随后系统会尝试重新创建service，由于服务状态为开始状态，所以创建服务后一定会调用onStartCommand(Intent,int,int)方法。如果在此期间没有任何启动命令被传递到service，那么参数Intent将为null。 START_NOT_STICKY：“非粘性的”。使用这个返回值时，如果在执行完onStartCommand后，服务被异常kill掉，系统不会自动重启该服务 START_REDELIVER_INTENT：重传Intent。使用这个返回值时，如果在执行完onStartCommand后，服务被异常kill掉，系统会自动重启该服务，并将Intent的值传入。 START_STICKY_COMPATIBILITY：START_STICKY的兼容版本，但不保证服务被kill后一定能重启。 onStartComand参数flags含义 flags表示启动服务的方式： Additional data about this start request. Currently either 0, START_FLAG_REDELIVERY, or START_FLAG_RETRY. START_FLAG_REDELIVERY：如果你实现onStartCommand()来安排异步工作或者在另一个线程中工作, 那么你可能需要使用START_FLAG_REDELIVERY来让系统重新发送一个intent。这样如果你的服务在处理它的时候被Kill掉, Intent不会丢失. START_FLAG_RETRY：表示服务之前被设为START_STICKY，则会被传入这个标记。 显示 隐藏（GONE） XML文件：android:visibility=“gone” Java代码：view.setVisibility(View.GONE); 错误 05-10 19:28:45.915 24188-24188/com.example.ipv4_over_ipv6 A/libc: Fatal signal 5 (SIGTRAP), code 1 in tid 24188 (.ipv4_over_ipv6) c函数未返回]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[操作系统复习笔记]]></title>
      <url>%2F2017%2F04%2F05%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
      <content type="text"><![CDATA[关于x86启动后执行的第一条指令及其地址 piazza 1、实模式下，地址为base+eip。第一条指令的地址是FFFFFFF0H = base(FFFF0000H) + EIP(0000FFF0H)。 2、争端出自于CS。可看看上面我高亮的normally和however部分。简单来讲就是，CS分为两部分，一部分为可见selector，另一部分为隐含base，实模式的一般情况下base = selector&lt;&lt;4，但是，机器刚启动的时候，selector=F000, base=FFFF0000！直到跳转指令以后才变成normally~ 例题：THU OS 2015 mid term 2 (启动)对于x86机器,加电后处于实模式下,并且cs寄存器的段选择子部分为0xf000, 隐藏的基址部分为0xffff0000,eip寄存器为0xfff0,则此时待执行的指令的物理地址为( 0xfffffff0) (16位实模式)执行完第一条 jmp指令后,cs寄存器的段选择子部分变为0xf000,eip变为 0xe05b,则此时待执行指令的物理地址为() 3） (进入32位保护模式)BIOS会将ucore bootloader 加载到网络地址0x7c00,且设置cs为0x0, eip为0x7c00。在boodoader中,使用 gdt加载了如下全局描述符表,然后进入32位保护模 式。此时为了正常工作。应该用 jmp将cs设置为(=3.1=),将ds/es/fs/gs/ss设置为(=3.2=) 此时若ep为0x7c6d,则实际被执行指令的物理地址为(一33二) 进程挂起相关 另一种解决方案是交换。包括把内存中某个进程的一部分或全部移到磁盘中。当内存中没有处于就绪状态的进程时，操作系统就把被阻塞的进程换出到磁盘中的”挂起队列“（suspend queue），即暂时保存从内存中”驱逐“出来的被挂器的进程队列。操作系统在此之后取出挂起队列中的另一个进程，或者接受一个新进程的请求，将其纳入内存运行。 “交换”（swapping）是一个I/O操作，因而可能使问题更恶化。但是由于磁盘I/O一般是系统中最快的I/O（相对于磁带或者打印机I/O），所以交换通常会提高性能。 阻塞-&gt;阻塞/挂起：如果没有就绪进程，则至少一个阻塞进程被换出，为另一个没有阻塞的进程让出空间。如果操作系统确定当前正在运行的进程，或者就绪进程为了维护基本的性能要求而需要更多的内存空间，那么，即使有可用的就绪态进程也可能出现这种转换。 阻塞挂起-&gt;就绪挂起：如果等待的事件发生了，则处于阻塞/挂起状态的进程可转换到就绪/挂起态。注意，这要求操作系统必须能够得到挂起进程的状态信息。 就绪/挂起-&gt;就绪：如果内存中没有就绪态进程，操作系统需要调入一个进程继续执行。此外，当处于就绪/挂起状态的进程比处于就绪态的任何进程的优先级都要高时，也可以进行这种转换。这种情况的产生是由于操作系统设计者规定，调入高优先级的进程比减少交换量更重要。 就绪-&gt;就绪/挂起：通常，操作系统更倾向于挂起阻塞态进程而不是就绪态进程，因为就绪态进程可以立即执行，而阻塞态进程占用了内存空间但不能执行。但如果释放内存以得到足够空间的唯一方法是挂起一个就绪态进程，那么这种转换也是必需的。并且，如果操作系统确信高优先级的阻塞态进程很快就会就绪，那么它可能选择挂起一个低优先级的就绪态进程，而不是一个高优先级的阻塞态进程。 通俗的说，就是挂起不挂起，不光要考虑为进程让出空间，不光要考虑是否就绪，还要考虑进程的优先级。 新建-&gt;就绪挂起及新建-&gt;就绪：当创建一个新进程时，该进程或者加入就绪队列，或者加入就绪/挂起队列。不论哪种情况，操作系统都必须建立一些表管理进程，并为进程分配地址空间。操作系统可能更倾向于在初期执行这些辅助工作，这使得它可以维护大量的未阻塞的进程。通过这一策略，内存中经常会没有足够的足够的空间分配给新进程。因此使用了（新建-&gt;就绪/挂起）转换。另一方面，我们可以证明创建进程时适时（just-in-time）原理，即尽可能推迟创建进程以减少操作系统的开销，并在系统被阻塞态进程阻塞时允许操作系统执行进程创建任务。 阻塞/挂起-&gt;阻塞：这种转化在设计中比较少见，如果一个进程没有准备好执行，并且不在内存中，调入它又有什么意义？但是考虑到下面的情况：一个进程终止，释放了一些内存空间，阻塞/挂起队列中有一个进程优先级比就绪/挂起队列中任何进程的优先级都要高，并且操作系统有理由相信阻塞进程的事件很快就会发射管，这时，把阻塞进程而不是就绪进程调入内存是合理的。 运行-&gt;就绪/挂起：通常当分配给一个运行进程的时间期满时，它将转换到就绪态。但是，如果由于位于阻塞/挂起队列中具有较高优先级的进程变得不再被阻塞，操作系统抢占这个进程，也可以直接把这个运行进程转换到就绪/挂起队列中，并释放一些内存空间。 各种状态/退出：在典型情况下，一个进程在运行时终止，或者是因为它已经完成，或者是因为出现了一些错误条件。但是，在某些操作系统中，一个进程可以被创建它的进程终止，或者当父进程终止时终止。如果允许这样，则进程在任何状态时都可以转换到退出态。 COW机制 COW机制简单来说就是fork的时候，子进程和父进程共用相同的内存，只有在修改的时候，拷贝原有内存当做一份私有的，在私有的基础上修改。 123456789101112131. fork的时候，进行如下处理。 1. VM_SHARE = 0，且页表P=1，将父进程的页表中的PTE_W记为0，这样这份内存只读不写。 如果考虑换入换出，应该注意，该页不能被换出，不然页表会不一致，所以我采取的办法是将该页设置为不可换出。 2. VM_SHARE = 0，且页表P=0，那么我们将页换入，然后按1和3做，或者也可以直接拷贝，并写入硬盘（比较麻烦）。 3. VM_SHARE = 1，不用cow机制。 段机制在这里不是特别好处理，我认为vma的管理就可以一定程度上取代段机制。2. 访问的时候如果发现pagefault，查看error_code和对应vmm的权限，如果发现 页存在，写出错，vmm可以写，那么我们进行处理。 1. VM_SHARE = 1，也就是说这块内存都是共享的，那么我们不应该对这块内存使用cow。 2. VM_SHARE = 0，新建对应的页表。 页存在，写出错，vmm不可以写，那就是错误异常了。 页不存在，写出错，vmm可以写 那么我们应该先把这一页换进来，再进行上面处理。 Page_fault Page_fault page_fault 造成page_fault的情况 造成page fault有两种情况 线性地址转换无效； 线性地址转换有效，但权限不合法。 线性地址转换无效的原因 页表项的P位为0，或保留位reserved为1。 error code的P位 如果页表项的P位为0，则error code的P位为0。 error code的P位 - P位为0时，表示page-fault缺页（准确来说，是entry的P位为0）。 - P位为1时，则不是因为缺页，而是因为page-level protection violation，即我们应该检测后面的标志位。 ucore的do_pgfault中 P为0的处理，即case 0和case 2，作为缺页处理，没问题。 P为1时，这时应该检测后面的标志位。先看case 1，ucore直接failed，也就是说，非缺页的读操作产生的page fault，ucore不做处理（后面的U/S、RSVD或I/D的错误），可以理解，没问题。再看看case 3，ucore先检测虚地址管理vma的写位，如果vma有写的权限，而发生了page fault，那么可能是entry没有写权限，因此可以尝试在entry添加上写权限。问题在于，如果不是因为entry的写权限造成的page fault的呢？此时ucore将陷入死循环！ 简单总结 ucore的page fault处理P=1,W/R=1的情况时，只处理了因为entry缺少写权限的情况，而没有考虑entry有写权限而由其它权限造成的异常，该处理可能导致ucore陷入死循环。赞同高思达同学对此处的质疑。 缺页中断 ①页表项全为0——虚拟地址与物理地址未建立映射关系或已被撤销。 ②物理页面不在内存中——需要进行换页机制。 ③访问权限不够——输出错误信息，并退出。 孤儿进程与僵尸进程 我们知道在unix/linux中，正常情况下，子进程是通过父进程创建的，子进程再创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程到底什么时候结束。 当一个 进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。 子进程通过exit()退出时，父进程既没有结束，也没有通过wait()等待子进程结束，则子进程成为“僵尸进程(zombie) unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到。这种机制就是: 在每个进程退出的时候,内核释放该进程所有的资源,包括打开的文件,占用的内存等。 但是仍然为其保留一定的信息(包括进程号the process ID,退出状态the termination status of the process,运行时间the amount of CPU time taken by the process等)。直到父进程通过wait / waitpid来取时才释放。 但这样就导致了问题，如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。 孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上，init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤 儿进程的父进程设置为init，而init进程会循环地wait()它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。因此孤儿进程并不会有什么危害。 任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。这是每个 子进程在结束时都要经过的阶段。如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。 如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。 设置僵死状态的目的是维护子进程的信息，以便父进程在以后某个时候获取。这些信息包括了子进程的进程ID、终止状态以及资源利用信息（CPU时间、内存使用量等等）。如果一个进程终止（使其所有子进程变成孤儿进程），而该进程有子进程处于僵死状态，那么它的所有僵死子进程的父进程ID将被重置为1（init进程）。继承这些子进程的init进程将清理它们（也就是init进程将wait它们，从而除去它们的僵死状态）。 Belady现象 Clock算法有Belady现象 123412512345 实例 X86寄存器 通用寄存器 段寄存器 CS(代码段) DS(数据段) 指令寄存器 和标志寄存器 EIP：指令寄存器， EIP的低16位即8086的ip， 储存的是下一条要执行的指令的内存地址，在分段地址转换中，表示指令的段内便宜地址 EFLAGS: 标志寄存器， 中断允许标志位（IF）, CLI（禁止中断）、STI两个命令控制， CF,PF，ZF等等寄存器 用户态或内核态下的中断处理有什么区别？在trapframe中有什么体现 用户态进入中断时，由于涉及到从用户态进入内核态，需要从用户栈切换到内核栈，因此需要多保存ss（堆栈段）和esp（栈顶）两个寄存器，先在栈中压入这两个值。再压入error code，cs，eip，flags。 而内核态进入中断时，不需要设计栈的切换，因此只需要压入error code，cs，eip，flags。 在trapframe数据结构中： 12345678910111213141516171819202122struct trapframe &#123; struct pushregs tf_regs; uint16_t tf_gs; uint16_t tf_padding0; uint16_t tf_fs; uint16_t tf_padding1; uint16_t tf_es; uint16_t tf_padding2; uint16_t tf_ds; uint16_t tf_padding3; uint32_t tf_trapno; /* below here defined by x86 hardware */ uint32_t tf_err; uintptr_t tf_eip; uint16_t tf_cs; uint16_t tf_padding4; uint32_t tf_eflags; /* below here only when crossing rings, such as from user to kernel */ uintptr_t tf_esp; uint16_t tf_ss; uint16_t tf_padding5;&#125; __attribute__((packed)); 注释的那一行“below here only hwn crossing rings”，就表示ss和esp只需要在切换特权级（即从用户态到内核态）时需要保存。 x86特权级 linux操作系统CPL、DPL、RPL说明 Linux操作系统中特权级有3种：CPL,DPL和RPL，每个都是有4个等级。 我对他们的关系理解是这样：一般来说，CPL代表当前代码段的权限，如果它想要去访问一个段或门，首先要看看对方的权限如何，也就是检查对方的DPL，如果满足当前的权限比要访问的权限高，则有可能允许去访问，有些情况我们还要检查 选择子的权限，即RPL,因为我们通过选择子:偏移量的方式去访问一个段，这算是一个访问请求动作，因此 称为请求访问权限RPL(Requst Privilege Level)。当请求权限也满足条件，那么访问就被允许了。 CPL(Current Privilege Level) CPL是当前执行的任务的特权等级，它存储在CS和SS的第0位和第1位上。(两位表示0~3四个等级) 通常情况下，CPL等于代码所在段的特权等级，当程序转移到不同的代码段时，处理器将改变CPL。 注意:在遇到一致代码段时，情况特殊，一致代码段的特点是：可以被等级相同或者更低特权级的代码访问，当处理器访问一个与当前代码段CPL特权级不同的一致代码段时，CPL不会改变。 DPL(Descriptor Privilege Level) 表示门或者段的特权级，存储在门（中断描述符IDT）或者段的描述符（GDT）的DPL字段中。正如上面说的那样，当当前代码段试图访问一个段或者门时，其DPL将会和当前特权级CPL以及段或门的选择子比较，根据段或者门的类型不同，DPL的含义不同： 1.数据段的DPL：规定了访问此段的最低权限。比如一个数据段的DPL是1，那么只有运行在CPL为0或1的程序才可能访问它。为什么说可能呢？因为还有一个比较的因素是RPL。访问数据段要满足有效特权级别（上述）高于数据段的DPL. 2.非一致代码段的DPL(不使用调用门的情况)：DPL规定访问此段的特权，只有CPL与之相等才有可能访问。 3.调用门的DPL，规定了程序或任务访问该门的最低权限。与数据段同。 4.一致代码段和通过调用门访问的非一致代码段，DPL规定访问此段的最高权限。 比如一个段的DPL为2，那么CPL为0或者1的程序都无法访问。 5. TSS的DPL，同数据段。 RPL（Rquest Privilege Level） RPL是通过选择子的低两位来表现出来的(这么说来，CS和SS也是存放选择子的，同时CPL存放在CS和SS的低两位上，那么对CS和SS来说，选择子的RPL=当前段的CPL)。处理器通过检查RPL和CPL来确认一个访问是否合法。即提出访问的段除了有足够的特权级CPL，如果RPL不够也是不行的(有些情况会忽略RPL检查)。 为什么要有RPL？ 操作系统往往通过设置RPL的方法来避免低特权级的应用程序访问高特权级的内层数据。 例子情景：调用者调用操作系统的某过程去访问一个段。 当操作系统(被调用过程)从应用程序(调用者)接受一个选择子时，会把选择子的RPL设置称调用者的权限等级，于是操作系统用这个选择子去访问相应的段时(这时CPL为操作系统的等级,因为正在运行操作系统的代码)，处理器会使用调用者的特权级去进行特权级检查，而不是正在实施访问动作的操作系统的特权级(CPL)，这样操作系统就不用以自己的身份去访问(就防止了应用去访问需要高权限的内层数据,除非应用程序本身的权限就足够高)。 那么RPL的作用就比较明显了：因为同一时刻只能有一个CPL，而当低权限的应用去调用拥有至高权限的操作系统的功能来访问一个目标段时，进入操作系统代码段时CPL变成了操作系统的CPL，如果没有RPL，那么权限检查的时候就会用CPL，而这个CPL权限比应用程序高，也就可能去访问需要高权限才能访问的数据，这就不安全了。所以引入RPL，让它去代表访问权限，因此在检查CPL的同时，也会检查RPL.一般来说如果RPL的数字比CPL大(权限比CPL的低)，那么RPL会起决定性作用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lec12练习]]></title>
      <url>%2F2017%2F04%2F03%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2FLec12%E7%BB%83%E4%B9%A0%2F</url>
      <content type="text"><![CDATA[1（不用回答）理解 孤儿进程和僵死进程的含义 http://www.cnblogs.com/xiehongfeng100/p/4619913.html http://www.cnblogs.com/Anker/p/3271773.html https://piazza.com/class/i5j09fnsl7k5x0?cid=753 孤儿进程：一个父进程退出、但其仍在运行的孤儿进程。孤儿进程将被init进程（进程号为1）所收养，并由init进程对它们完成状态收集工作。 僵尸进程：一个已经终止、但是其父进程尚未对其进行善后处理（获取终止子进程的有关信息，释放它仍占用的资源）的进程。 5 请仔细阅读https://chyyuu.gitbooks.io/os_course_exercises/content/all/05-2-spoc-discussion.html. 中的小组思考题 设计一个简化的进程管理子系统，可以管理并调度如下简化进程.给出了参考代码（https://github.com/chyyuu/ucore_lab/blob/master/related_info/lab5/process-cpuio-homework.py），请理解代码，并完成＂YOUR CODE“部分的内容． 根据注释及gitbook中的提示完成实验即可，需要注意的是切换进程的时刻有:进程结束或进程发出yield请求 以及IO的时间设置问题，由输出的提示可知： System will switch when the current process is FINISHED or ISSUES AN YIELD or IO After IOs, the process issuing the IO will run LATER (when it is its turn) 因此，io完成时间应该是 clock_tick + self.io_length + 2,即需要两个切换时间 12# 设置IO完成时间self.io_finish_times[self.curr_proc].append(clock_tick + self.io_length + 2) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336#! /usr/bin/env python# coding:utf8import sysfrom optparse import OptionParserimport random# process switch behaviorSCHED_SWITCH_ON_IO = 'SWITCH_ON_IO'# io finished behaviorIO_RUN_LATER = 'IO_RUN_LATER'# process statesSTATE_RUNNING = 'RUNNING'STATE_READY = 'READY'STATE_DONE = 'DONE'STATE_WAIT = 'WAITING'# members of process structurePROC_CODE = 'code_'PROC_PC = 'pc_'PROC_ID = 'pid_'PROC_STATE = 'proc_state_'# things a process can doDO_COMPUTE = 'cpu'DO_YIELD = 'yld'DO_IO = 'io'class scheduler: def __init__(self, process_switch_behavior, io_done_behavior, io_length): # keep set of instructions for each of the processes self.proc_info = &#123;&#125; self.process_switch_behavior = process_switch_behavior self.io_done_behavior = io_done_behavior self.io_length = io_length return def new_process(self): proc_id = len(self.proc_info) self.proc_info[proc_id] = &#123;&#125; self.proc_info[proc_id][PROC_PC] = 0 self.proc_info[proc_id][PROC_ID] = proc_id self.proc_info[proc_id][PROC_CODE] = [] self.proc_info[proc_id][PROC_STATE] = STATE_READY return proc_id def load(self, program_description): proc_id = self.new_process() tmp = program_description.split(':') if len(tmp) != 3: print 'Bad description (%s): Must be number &lt;x:y:z&gt;' print ' where X is the number of instructions' print ' and Y is the percent change that an instruction is YIELD' print ' and Z is the percent change that an instruction is IO' exit(1) num_instructions, chance_yield, chance_io = int(tmp[0]), float( tmp[1]) / 100.0, float(tmp[2]) / 100.0 assert (chance_yield + chance_io &lt; 1) # print "proc %d, num_instr %d, change_cpu %f" % (proc_id,num_instructions, chance_cpu) for i in range(num_instructions): randnum = random.random(); if randnum &lt; (1.0 - chance_yield - chance_io): self.proc_info[proc_id][PROC_CODE].append(DO_COMPUTE) elif randnum &gt;= (1.0 - chance_yield - chance_io) and randnum &lt; ( 1.0 - chance_io): self.proc_info[proc_id][PROC_CODE].append(DO_YIELD) else: self.proc_info[proc_id][PROC_CODE].append(DO_IO) # print "proc %d, instr idx %d, instr cxt %s" % (proc_id, i, self.proc_info[proc_id][PROC_CODE][i]) return # change to WAIT STATE, the current proc's state should be expected def move_to_wait(self, expected): assert (self.proc_info[self.curr_proc][PROC_STATE] == expected) self.proc_info[self.curr_proc][PROC_STATE] = STATE_WAIT return # change to READY STATE, the current proc's state should be expected # if pid==-1, then pid=self.curr_proc def move_to_ready(self, expected, pid=-1): # YOUR CODE if pid is -1: pid = self.curr_proc assert (self.proc_info[pid][PROC_STATE] == expected) self.proc_info[pid][PROC_STATE] = STATE_READY return # change to RUNNING STATE, the current proc's state should be expected def move_to_running(self, expected): # YOUR CODE assert (self.proc_info[self.curr_proc][PROC_STATE] == expected) self.proc_info[self.curr_proc][PROC_STATE] = STATE_RUNNING return # change to DONE STATE, the current proc's state should be expected def move_to_done(self, expected): # YOUR CODE assert (self.proc_info[self.curr_proc][PROC_STATE] == expected) self.proc_info[self.curr_proc][PROC_STATE] = STATE_DONE return # choose next proc using FIFO/FCFS scheduling, If pid==-1, then pid=self.curr_proc def next_proc(self, pid=-1): # YOUR CODE """ 使用FIFO/FCFS：先来先服务, 只有进程done, yield, io时才会执行切换 先查找位于proc_info队列的curr_proc元素(当前进程)之后的进程(curr_proc+1..end)是否处于READY态， 再查找位于proc_info队列的curr_proc元素(当前进程)之前的进程(begin..curr_proc-1)是否处于READY态 如都没有，继续执行curr_proc直到结束 """ if pid == -1: pid = self.curr_proc # 使用FIFO/FCFS(先到先服务)调度算法选择下一个进程 for i in xrange(self.curr_proc + 1, len(self.proc_info)): if self.proc_info[i][PROC_STATE] == STATE_READY: self.curr_proc = i self.move_to_running(STATE_READY) return # break for i in xrange(0, self.curr_proc): if self.proc_info[i][PROC_STATE] == STATE_READY: self.curr_proc = i self.move_to_running(STATE_READY) return # break # 进程切换 if self.proc_info[self.curr_proc][PROC_STATE] == STATE_READY: self.move_to_running(STATE_READY) return def get_num_processes(self): return len(self.proc_info) def get_num_instructions(self, pid): return len(self.proc_info[pid][PROC_CODE]) def get_instruction(self, pid, index): return self.proc_info[pid][PROC_CODE][index] def get_num_active(self): num_active = 0 for pid in range(len(self.proc_info)): if self.proc_info[pid][PROC_STATE] != STATE_DONE: num_active += 1 return num_active def get_num_runnable(self): num_active = 0 for pid in range(len(self.proc_info)): if self.proc_info[pid][PROC_STATE] == STATE_READY or \ self.proc_info[pid][PROC_STATE] == STATE_RUNNING: num_active += 1 return num_active def get_ios_in_flight(self, current_time): num_in_flight = 0 for pid in range(len(self.proc_info)): for t in self.io_finish_times[pid]: if t &gt; current_time: num_in_flight += 1 return num_in_flight def space(self, num_columns): for i in range(num_columns): print '%10s' % ' ', def check_if_done(self): if len(self.proc_info[self.curr_proc][PROC_CODE]) == 0: if self.proc_info[self.curr_proc][PROC_STATE] == STATE_RUNNING: self.move_to_done(STATE_RUNNING) self.next_proc() return def run(self): clock_tick = 0 if len(self.proc_info) == 0: return # track outstanding IOs, per process self.io_finish_times = &#123;&#125; for pid in range(len(self.proc_info)): self.io_finish_times[pid] = [] # make first one active self.curr_proc = 0 self.move_to_running(STATE_READY) # OUTPUT: heade`[rs for each column print '%s' % 'Time', for pid in range(len(self.proc_info)): print '%10s' % ('PID:%2d' % (pid)), print '%10s' % 'CPU', print '%10s' % 'IOs', print '' # init statistics io_busy = 0 cpu_busy = 0 while self.get_num_active() &gt; 0: clock_tick += 1 # check for io finish io_done = False for pid in range(len(self.proc_info)): if clock_tick in self.io_finish_times[pid]: # if IO finished, the should do something for related process # YOUR CODE # IO完成，将pid进程转换为Ready状态 self.move_to_ready(STATE_WAIT, pid) if self.proc_info[self.curr_proc][ PROC_STATE] != STATE_RUNNING: self.next_proc(); io_done = True # pass #YOU should delete this # if current proc is RUNNING and has an instruction, execute it instruction_to_execute = '' if self.proc_info[self.curr_proc][PROC_STATE] == STATE_RUNNING and \ len(self.proc_info[self.curr_proc][PROC_CODE]) &gt; 0: # pop a instruction from proc_info[self.curr_proc][PROC_CODE]to instruction_to_execute # YOUR CODE instruction_to_execute = self.proc_info[self.curr_proc][ PROC_CODE].pop(0) # pass #YOU should delete this # OUTPUT: print what everyone is up to if io_done: print '%3d*' % clock_tick, else: print '%3d ' % clock_tick, for pid in range(len(self.proc_info)): if pid == self.curr_proc and instruction_to_execute != '': print '%10s' % ('RUN:' + instruction_to_execute), else: print '%10s' % (self.proc_info[pid][PROC_STATE]), if instruction_to_execute == '': print '%10s' % ' ', else: print '%10s' % 1, num_outstanding = self.get_ios_in_flight(clock_tick) if num_outstanding &gt; 0: print '%10s' % str(num_outstanding), io_busy += 1 else: print '%10s' % ' ', print '' # if this is an YIELD instruction, switch to ready state # and add an io completion in the future if instruction_to_execute == DO_YIELD: # YOUR CODE # 发出YIELD请求,放弃使用CPU, 进程切换 self.move_to_ready(STATE_RUNNING) self.next_proc() pass # YOU should delete this # if this is an IO instruction, switch to waiting state # and add an io completion in the future elif instruction_to_execute == DO_IO: # YOUR CODE # 发出I/O操作请求,放弃使用CPU self.move_to_wait(STATE_RUNNING) # 设置IO完成时间 self.io_finish_times[self.curr_proc].append( clock_tick + self.io_length + 2) # 切换进程 self.next_proc() pass # YOU should delete this else: cpu_busy += 1 # ENDCASE: check if currently running thing is out of instructions self.check_if_done() return (cpu_busy, io_busy, clock_tick)## PARSE ARGUMENTS#parser = OptionParser()parser.add_option('-s', '--seed', default=0, help='the random seed', action='store', type='int', dest='seed')parser.add_option('-l', '--processlist', default='', help='a comma-separated list of processes to run, in the form X1:Y1:Z1,X2:Y2:Z2,... where X is the number of instructions that process should run, and Y/Z the chances (from 0 to 100) issue an YIELD/IO', action='store', type='string', dest='process_list')parser.add_option('-L', '--iolength', default=3, help='how long an IO takes', action='store', type='int', dest='io_length')parser.add_option('-p', '--printstats', help='print statistics at end; only useful with -c flag (otherwise stats are not printed)', action='store_true', default=False, dest='print_stats')(options, args) = parser.parse_args()random.seed(options.seed)process_switch_behavior = SCHED_SWITCH_ON_IOio_done_behavior = IO_RUN_LATERio_length = options.io_lengths = scheduler(process_switch_behavior, io_done_behavior, io_length)# example process description (10:100,10:100)for p in options.process_list.split(','): s.load(p)print 'Produce a trace of what would happen when you run these processes:'for pid in range(s.get_num_processes()): print 'Process %d' % pid for inst in range(s.get_num_instructions(pid)): print ' %s' % s.get_instruction(pid, inst) print ''print 'Important behaviors:'print ' System will switch when',if process_switch_behavior == SCHED_SWITCH_ON_IO: print 'the current process is FINISHED or ISSUES AN YIELD or IO'else: print 'error in sched switch on iobehavior' exit(-1)print ' After IOs, the process issuing the IO will',if io_done_behavior == IO_RUN_LATER: print 'run LATER (when it is its turn)'else: print 'error in IO done behavior' exit(-1)print ''(cpu_busy, io_busy, clock_tick) = s.run()print ''print 'Stats: Total Time %d' % clock_tickprint 'Stats: CPU Busy %d (%.2f%%)' % (cpu_busy, 100.0 * float(cpu_busy) / clock_tick)print 'Stats: IO Busy %d (%.2f%%)' % (io_busy, 100.0 * float(io_busy) / clock_tick)print '']]></content>
    </entry>

    
    <entry>
      <title><![CDATA[服务器配置相关问题]]></title>
      <url>%2F2017%2F03%2F31%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%2F</url>
      <content type="text"><![CDATA[服务器配置相关记录 Apache的反向代理 首先是库之类的环境配置， 如果是编译的，./configure附加–enable-proxy参数，把代理模块编译进来。 如果是安装好的，就在配置文件http.conf里启用相应的模块 LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_http_module modules/mod_proxy_http.so 有的服务器该配置文件为, /etc/apache2/apache2.conf 12LoadModule proxy_module /usr/lib/apache2/modules/mod_proxy.soLoadModule proxy_http_module /usr/lib/apache2/modules/mod_proxy_http.so 123456789101112131415&lt;VirtualHost *:80&gt; ServerAlias wordpress.zhangshenghao.win ServerName wordpress.zhangshenghao.win ProxyPassReverse / http://pi.zhangshenghao.win/wordpress/ ProxyPass / http://pi.zhangshenghao.win/wordpress/ &lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt; ServerAlias blog.zhangshenghao.win ServerName blog.zhangshenghao.win ProxyPassReverse / http://pi.zhangshenghao.win/qingfeng14.github.io/ ProxyPass / http://pi.zhangshenghao.win/qingfeng14.github.io/ &lt;/VirtualHost&gt; 123456789101112131415&lt;VirtualHost *:80&gt; ServerAlias code.zhangshenghao.win ServerName code.zhangshenghao.win # ProxyPassReverse / http://pi.zhangshenghao.win/wordpress/ DocumentRoot /Users/alexzhangch/Downloads/FTP_SERVER/ &lt;/VirtualHost&gt;&lt;Directory &quot;/Users/alexzhangch/Downloads/FTP_SERVER/&quot;&gt; Options FollowSymLinks Multiviews MultiviewsMatch Any AllowOverride None Require all granted&lt;/Directory&gt; 服务器重启 1sudo /etc/init.d/apache2 restart 开启HTTPS 代理 开启HTTPS步骤 更全 步骤1：生成密钥 1openssl genrsa 1024 &gt; server.key 说明：这是用128位rsa算法生成密钥，得到server.key文件 步骤2: 生成证书请求文件 1openssl req -new -key server.key &gt; server.csr 说明：这是用步骤1的密钥生成证书请求文件server.csr, 这一步提很多问题，一一输入 1234567891011Country Name (2 letter code) [AU]:CN ← 国家代号，中国输入CN State or Province Name (full name) [Some-State]:BeiJing ← 省的全名，拼音 Locality Name (eg, city) []:BeiJing ← 市的全名，拼音 Organization Name (eg, company) [Internet Widgits Pty Ltd]:MyCompany Corp. ← 公司英文名 Organizational Unit Name (eg, section) []: ← 可以不输入 Common Name (eg, YOUR name) []: ← 此时不输入 Email Address []:admin@mycompany.com ← 电子邮箱，可随意填Please enter the following ‘extra’ attributes to be sent with your certificate request A challenge password []: ← 可以不输入 An optional company name []: ← 可以不输入 步骤3: 生成证书 1openssl req -x509 -days 3650 -key server.key -in server.csr &gt; server.crt 说明：这是用步骤1,2的的密钥和证书请求生成证书server.crt，-days参数指明证书有效期，单位为天 1sudo ln -s /etc/apache2/sites-available/default-ssl.conf /etc/apache2/sites-enabled/001-ssl.conf let’s encrypt 12Generating key (2048 bits): /etc/letsencrypt/keys/0001_key-certbot.pemCreating CSR: /etc/letsencrypt/csr/0001_csr-certbot.pem 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;VirtualHost _default_:443&gt; ServerAdmin zhangshenghao1995@163.com DocumentRoot /var/www/html/qingfeng14.github.io/ ErrorLog $&#123;APACHE_LOG_DIR&#125;/error.log CustomLog $&#123;APACHE_LOG_DIR&#125;/access.log combined # SSL Engine Switch: # Enable/Disable SSL for this virtual host. SSLEngine on # A self-signed (snakeoil) certificate can be created by installing # the ssl-cert package. See # /usr/share/doc/apache2/README.Debian.gz for more info. # If both key and certificate are stored in the same file, only the # SSLCertificateFile directive is needed. SSLCertificateFile /etc/letsencrypt/live/zhangshenghao.win/fullchain.pem SSLCertificateKeyFile /etc/letsencrypt/live/zhangshenghao.win/privkey.pem &lt;FilesMatch &quot;\.(cgi|shtml|phtml|php)$&quot;&gt; SSLOptions +StdEnvVars &lt;/FilesMatch&gt; &lt;Directory /usr/lib/cgi-bin&gt; SSLOptions +StdEnvVars &lt;/Directory&gt; BrowserMatch &quot;MSIE [2-6]&quot; \ nokeepalive ssl-unclean-shutdown \ downgrade-1.0 force-response-1.0 # MSIE 7 and newer should be able to use keepalive BrowserMatch &quot;MSIE [17-9]&quot; ssl-unclean-shutdown ServerName zhangshenghao.win &lt;/VirtualHost&gt; &lt;VirtualHost _default_:443&gt; ServerAdmin zhangshenghao1995@163.com DocumentRoot /var/www/html/qingfeng14.github.io/ ErrorLog $&#123;APACHE_LOG_DIR&#125;/error.log CustomLog $&#123;APACHE_LOG_DIR&#125;/access.log combined # SSL Engine Switch: # Enable/Disable SSL for this virtual host. SSLEngine on # A self-signed (snakeoil) certificate can be created by installing # the ssl-cert package. See # /usr/share/doc/apache2/README.Debian.gz for more info. # If both key and certificate are stored in the same file, only the # SSLCertificateFile directive is needed. SSLCertificateFile /etc/letsencrypt/live/blog.zhangshenghao.win/fullchain.pem SSLCertificateKeyFile /etc/letsencrypt/live/blog.zhangshenghao.win/privkey.pem &lt;FilesMatch &quot;\.(cgi|shtml|phtml|php)$&quot;&gt; SSLOptions +StdEnvVars &lt;/FilesMatch&gt; &lt;Directory /usr/lib/cgi-bin&gt; SSLOptions +StdEnvVars &lt;/Directory&gt; BrowserMatch &quot;MSIE [2-6]&quot; \ nokeepalive ssl-unclean-shutdown \ downgrade-1.0 force-response-1.0 # MSIE 7 and newer should be able to use keepalive BrowserMatch &quot;MSIE [17-9]&quot; ssl-unclean-shutdown ServerName blog.zhangshenghao.win &lt;/VirtualHost&gt; http 重定向至 http 12RewriteEngine OnRewriteRule ^ https://%&#123;SERVER_NAME&#125;%&#123;REQUEST_URI&#125; [END,NE,R=permanent] squid 代理服务器]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[lec10_lec11练习题]]></title>
      <url>%2F2017%2F03%2F29%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2Flec10-lec11%2F</url>
      <content type="text"><![CDATA[1 以lab3为例，说明虚拟页与磁盘后备页面的对应关系是什么？ 物理内存+磁盘空间 构成了虚拟存储通过虚拟页式存储机制提供给用户更大的逻辑空间，虚拟内存页有可能在物理内存中，也可能在磁盘后备页面中，这种调整是通过页面置换算法进行对应的换入换出的。 4 由于何种原因，可出现进程的何种状态转到退出状态？ 正常退出：进程的应用程序逻辑流程执行结束，进程会由运行态转为退出状态 错误退出：程序运行过程中发现错误（异常输入等等）主动退出（运行状态到退出状态） 致命错误：程序运行出现差错无法继续执行而退出（运行到退出） 被其他进程所杀，其他进程向该进程发送信号使之退出（此前可能是就绪状态，运行状态，等待状态） 5 请设计一个简化的进程管理子系统，可以管理并调度如下简化进程.给出了参考代码（https://github.com/chyyuu/ucore_lab/blob/master/related_info/lab4/process-concept-homework.py），请理解代码，并完成＂YOUR CODE“部分的内容。 该调度算法模拟了先到先服务调度（FCFS）算法，根据注释填入代码即可 需要注意的是在进行FCFS算法时，需要注意在还有其他进程处于Ready状态时不要让当前进程继续运行,如下所示： 12345678910111213def next_proc(self, pid=-1): #YOUR CODE if pid==-1: pid = self.curr_proc # 使用FIFO/FCFS(先到先服务)调度算法选择下一个进程 for i in xrange(0, len(self.proc_info)): if self.proc_info[i][PROC_STATE] == STATE_READY and i != pid: # 避免选择本进程再次调度 self.curr_proc = i break if self.proc_info[self.curr_proc][PROC_STATE] == STATE_READY: self.move_to_running(STATE_READY) return]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[计算机系统结构]指令系统]]></title>
      <url>%2F2017%2F03%2F26%2F%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84-%E5%B1%82%E6%AC%A1%E5%AD%98%E5%82%A8%2F</url>
      <content type="text"><![CDATA[程序访问的局部性原理：时间局部性，空间局部性 存储系统的多级层次结构 CPU-&gt;M1-&gt;M2–。。。。。。.&gt;Mn 在存储层次中，各存储器中一般满足包含关系,即任何一层存储器中的内容都是其下一层存储（离CPU更远一级）中内容的子集 CPU与M1一般以字为单位传递，M1以外一般以块/页为单位传递数据 存储系统性能参数 存储容量S 一般来说，整个存储系统的存储容量即为最后一级存储器的容量，eg:cache + 主存的存储系统容量为主存容量 存储系统的平均每位价格C 命中率H CPU 访问该存储系统时，在M1中找到所需信息的概率 平均访存时间\(T_A\) 命中时间 不命中开销：访一级时间 + 数据传送时间 三级存储系统：Cache + 主存 + 磁盘 cache-主存层次：为了弥补主存速度的不足，一般是硬件完成的，对应用程序员和系统程序员是透明的 主存-辅存层次：为了弥补主存容量的不足，常被用于实现虚拟存储器，向编程人员提供用不完的程序空间，主要由软件完成 存储层次的四个问题 映像规则 查找算法 替换算法 写策略 Cache cache 基本结构及原理 cache是按块管理的，cache和主存均被分成大小相同的块，信息以块为单位调入cache中 主存地址： 块地址（块号） | 块内偏移 主存地址寄存器–》主存-Cache地址转换部件 –》 命中，Cache块地址，根据偏移在Cache存储体中查到对应的数据指令送给CPU -》 未命中，访主存储器，调入Cache（是否需要替换），送给CPU，或者直接送给CPU提高效率 Cache 映像规则 全相联映射 主存中的人意块可以放到Cache中的任意一个位置 ### 直接映射 主存中每一块只能放到Cache中的唯一一个位置，对应关系依次循环分配 主存的第i块（块地址为i）映射到Cache的第j块 \[j = i mod M\] M为Cache的快数， 若\(M = 2^m\)，则j实际上是i的低m位（注意是块地址的低m位），可用这m位去进行选择（索引） 组相连映像 Cache被分为若干组，每个组由若干块组成，主存中每一个块可以放到Cache中唯一一个组的任意一个位置。组的选择通常采用位选择方法 对于主存中的第i个块，若它映射到Cache中的组号为j，则 \[j = i mdo G\] G为Cache的组数，当\(G=2^g\)时，k为块号i的低g位，这里的低g位称为索引 如果每组有n 个块，则称该映像规则为n路组相联 n值越大，Cache的空间利用率就越高，块冲突的概率就越低 查找方法 Cache中设置有一个目录表，每一个Cache块在该表中均有唯一的一项，用于指出当前该块存放的信息是哪个主存块的（一般有多个主存块映射到该Cache块，它实际上记录了该主存块的块地址的高位部分，称为标识），每个主存块能唯一地由其标识来确定 12主存地址： 标识 | 索引 | 块内偏移 ____块地址__ 经典的CPU性能公式 现在我们可以用指令数、CPI和时钟周期时间来写出基本的性能公式： CPU时间=指令数×CPI×时钟周期时间 CPI（clock cycles per instruction）：每条指令的时钟周期数，表示执行某个程序或者程序片段时每条指令所需的时钟周期平均数。 指令数（instruction count）：执行某程序所需的总指令数量。 或 CPU时间=指令数×CPI/时钟频率 永远记住，唯一能够被完全可靠测量的计算机性能指标是时间。例如，对指令集减少指令数目的改进可能降低时钟周期时间或提高CPI，从而抵消了改进的效果。类似地，CPI与执行的指令类型相关，执行指令数最少的代码其执行速度未必是最快的。 写分配法 张晨曦 按写分配法：写失效时，先把所写单元所在的块调入 Cache，然后再进行写入。这与读失效类似。这种方法也称为写时取方法。 不按写分配法：写失效时，直接写入下一级存储器而不将相应的块调入 Cache。这种方法也称为绕写法。 写策略 写Cache时何时更新主存中的内容 写直达法： 执行写操作时，不仅把数据写入Cache中对应的块，还把数据写入下一级存储器 写回法： 拷回法，只把数据写回cache，Cache块被替换时写回下一级存储器]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[操作系统-页面置换算法]]></title>
      <url>%2F2017%2F03%2F25%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[置换算法的功能和目标 功能 当出现缺页异常，需调入新页面而内存已满时，置换算法选择被置换的物理页面 设计目标 尽可能减少页面的调入调出次数 把未来不再访问或短期内不访问的页面调出 页面锁定(frame locking) 描述必须常驻内存的逻辑页面 操作系统的关键部分 要求响应速度的代码和数据 页表中的锁定标志位(lock bit) 置换算法的评价方法 记录进程访问内存的页面轨迹 评价：模拟页面置换算法，记录缺页的次数，更少的缺页意味着更好的性能 页面置换算法分类 局部页面置换算法：着眼于当前进程 最优算法，先进先出算法，最近最久未使用算法，时钟算法，最不常用算法 全局页面置换算法：着眼于所有可换出的物理页面 工作集算法，缺页率算法 局部页面置换算法 最优页面置换算法 OPT 置换未来最长时间不访问的页面 实际系统中无法实现 FIFO算法 思路： 选择在内存中滞留时间最长的页面进行置换 实现： 维护一个记录所有位于内存中的逻辑页面链表 链表元素按驻留内存时间排序，链首最长，链尾最短 出现缺页时，选择链首进行置换 特征： 实现简单 性能较差 Belady现象 时钟置换算法 思路：对页面的访问情况进行大致统计 实现： 在页表项增加访问位， 各页面组织成环形链表 指针指向最先调入的页面 算法： 访问页面时，在页表项记录页面访问情况 缺页时，从指针处开始顺序查找未被访问的页面进行置换 特征：是LRU和FIFO的折中 【Note】:访问位的标记是硬件自动完成的 具体流程 页面装入内存时，访问位初始化为0 访问页面（读/写)时，访问位置1 缺页时，从指针当前位置顺序检查环形链表 访问位为0，则置换该页 访问位为1，则访问位置0，并指针移动到下一个页面， 直到找到可置换的页面 全局页面置换算法 工作集页置换算法 工作集 \(W(t, \Delta)\) t是当前的执行时刻 \(\Delta\) 是工作集窗口，即一个定长的页面访问时间窗口 \(W(t,\Delta)\)表示在当前时刻t前的\(\Delta\)时间窗口中的所有访问页面所组成的集合 \(|W(t,\Delta)|\)指工作集的大小，即页面数目 工作集页置换算法思路：换出不在工作集中的页面 窗口大小\(\tau\):当前时刻前\(\tau\)个内存访问的页引用是工作集，\(\tau\)被称为窗口大小 实现方法： 访存链表：维护窗口内的访存页面链表 访存时，换出不在工作集的页面，更新访存链表 缺页时，换出页面，更新访存链表]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[OS-lec9-exercise]]></title>
      <url>%2F2017%2F03%2F24%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2FOS-lec9-exercise%2F</url>
      <content type="text"><![CDATA[Lec9 练习题 1. 物理页帧数量为3，且初始时没有对应的虚拟页。虚拟页访问序列为0,1,2,0,1,3,0,3,1,0,3，请问采用最优置换算法的缺页次数为（4） 最优置换算法：置换未来最长时间不访问的页面。 时间 1 2 3 4 5 6 7 8 9 10 11 物理页帧 0 1 2 0 1 3 0 3 1 0 3 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 3 3 3 3 3 3 缺页? 缺页 缺页 缺页 缺页 2-&gt;3 缺页次数为4次 2. 物理页帧数量为3，且初始时没有对应的虚拟页。虚拟页访问序列为0,1,2,0,1,3,0,3,1,0,3，请问采用FIFO置换算法的缺页次数为（6） 时间 1 2 3 4 5 6 7 8 9 10 11 物理页帧 0 1 2 0 1 3 0 3 1 0 3 0 0 0 0 0 0 3 3 3 3 3 3 1 1 1 1 1 1 0 0 0 0 0 2 2 2 2 2 2 2 1 1 1 缺页? 缺页 缺页 缺页 缺页 缺页 缺页 0-&gt;3 1-&gt;0 2-&gt;1 缺页6次 3.物理页帧数量为4，且初始时没有对应的虚拟页。虚拟页访问序列为0,3,2,0,1,3,4,3,1,0,3,2,1,3,4，请问采用CLOCK置换算法（用1个bit表示存在时间）的缺页次数为（9） 题3Clock算法1 题3Clock算法2 缺页次数9 4. 物理页帧数量为4，且初始时没有对应的虚拟页。虚拟页访问序列为0,3,2,0,1,3,4,3,1,0,3,2,1,3,4，请问采用CLOCK置换算法（用2个关联，bit表示存在时间,可以表示4,）的缺页次数为（） 题4-1 题4-2 缺页次数为8 5.（spoc）根据你的学号 mod 4的结果值，确定选择四种页面置换算法（0：LRU置换算法，1:改进的clock页置换算法，2：工作集页置换算法，3：缺页率置换算法）中的一种来设计一个应用程序（可基于python,ruby, C, C++，LISP等）模拟实现，并给出测试用例和测试结果。请参考如python代码或独自实现。 工作集页置换算法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# coding: utf-8# ! /usr/bin/env python# 工作集页面置换算法# 访存页面链表work_list = []# 工作集work_set = set(work_list)# 窗口大小t = 4def access(page): """ 访问页面函数,针对每一个页,进行工作集的更新,访存链表的更新,页面置换 :param page: :return: """ global work_set global work_list # 是否出现页缺失 miss = False if page in work_set: # 当前页面在工作集中,表示命中 print "命中页面" else: miss = True print "页缺失" work_list.append(page) # 删除第一个页面 first = work_list[0] if len(work_list) &gt; t: # 已经超出工作集,去除列表首页 del work_list[0] work_set = set(work_list) if first not in work_set: print 'page %s 换出' % first if miss: print "page %s 换入" % page print "当前访存链表:", work_list print "当前工作集:", work_setdef access_pages(pages, input_work_list): global work_set global work_list work_list = input_work_list work_set = set(input_work_list) print "页面访问顺序为:", pages print "初始工作集:", work_set print "初始访问列表:", work_list pages = pages.split(',') count = 0 for i in pages: count += 1 print 'Page ', count, i, access(i) print '' # 访问完成之后清空 work_list = [] work_set = set(work_list)if __name__ == '__main__': print "这是一个工作集置换算法的简单实现" log = ''' t = 4 test_pages = "c,c,d,b,c,e,c,e,a,d" test_work_str = "e,d,a" ''' print "课件中测试集:", log t = input("窗口大小t=") assert (int(t) &gt; 0) # 访问页面顺序 test_pages = raw_input('测试页面顺序(以,隔开,如e,d,a,c,c) test_pages=') test_work_str = raw_input('此前访问的t个页面顺序为(如e,d,a)test_work_str=') test_work_list = test_work_str.split(',') print test_work_list assert (len(test_work_list) &lt;= t) # test_pages = "e,d,a,c,c,d,b,c,e,c,e,a,d" access_pages(test_pages, test_work_list) 测试用例使用课本中的访问顺序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051页面访问顺序为: c,c,d,b,c,e,c,e,a,d初始工作集: set([&apos;a&apos;, &apos;e&apos;, &apos;d&apos;])初始访问列表: [&apos;e&apos;, &apos;d&apos;, &apos;a&apos;]Page 1 c 页缺失page c 换入当前访存链表: [&apos;e&apos;, &apos;d&apos;, &apos;a&apos;, &apos;c&apos;]当前工作集: set([&apos;a&apos;, &apos;c&apos;, &apos;e&apos;, &apos;d&apos;])Page 2 c 命中页面page e 换出当前访存链表: [&apos;d&apos;, &apos;a&apos;, &apos;c&apos;, &apos;c&apos;]当前工作集: set([&apos;a&apos;, &apos;c&apos;, &apos;d&apos;])Page 3 d 命中页面当前访存链表: [&apos;a&apos;, &apos;c&apos;, &apos;c&apos;, &apos;d&apos;]当前工作集: set([&apos;a&apos;, &apos;c&apos;, &apos;d&apos;])Page 4 b 页缺失page a 换出page b 换入当前访存链表: [&apos;c&apos;, &apos;c&apos;, &apos;d&apos;, &apos;b&apos;]当前工作集: set([&apos;c&apos;, &apos;b&apos;, &apos;d&apos;])Page 5 c 命中页面当前访存链表: [&apos;c&apos;, &apos;d&apos;, &apos;b&apos;, &apos;c&apos;]当前工作集: set([&apos;c&apos;, &apos;b&apos;, &apos;d&apos;])Page 6 e 页缺失page e 换入当前访存链表: [&apos;d&apos;, &apos;b&apos;, &apos;c&apos;, &apos;e&apos;]当前工作集: set([&apos;c&apos;, &apos;b&apos;, &apos;e&apos;, &apos;d&apos;])Page 7 c 命中页面page d 换出当前访存链表: [&apos;b&apos;, &apos;c&apos;, &apos;e&apos;, &apos;c&apos;]当前工作集: set([&apos;c&apos;, &apos;b&apos;, &apos;e&apos;])Page 8 e 命中页面page b 换出当前访存链表: [&apos;c&apos;, &apos;e&apos;, &apos;c&apos;, &apos;e&apos;]当前工作集: set([&apos;c&apos;, &apos;e&apos;])Page 9 a 页缺失page a 换入当前访存链表: [&apos;e&apos;, &apos;c&apos;, &apos;e&apos;, &apos;a&apos;]当前工作集: set([&apos;a&apos;, &apos;c&apos;, &apos;e&apos;])Page 10 d 页缺失page d 换入当前访存链表: [&apos;c&apos;, &apos;e&apos;, &apos;a&apos;, &apos;d&apos;]当前工作集: set([&apos;a&apos;, &apos;c&apos;, &apos;e&apos;, &apos;d&apos;]) 6. 请判断OPT、LRU、FIFO、Clock和LFU等各页面置换算法是否存在Belady现象？如果存在，给出实例；如果不存在，给出证明。 FIFO：存在Belady现象，例子 FIFO算法 物理页面增加，缺失数次数反而升高，出现了Belady现象 LRU:不存在Belady现象 证明：对于确定的页面访问序列PagesList,设其分配的物理页面数为n， 当访问PagesList[i]页面时发生了缺页(易知i&gt;n)，即页面PagesList[i]不在页面i-n到i-1这n个页面中，进而发生了缺页异常，而加大n至n1, PagesList[i]有可能在i-n1 至 i-1这n1个页面中，也可能不在，前者此时不会发生缺页异常，后者仍然会发生，但无论如何，分配的物理页面数增加时，其缺页数可能持平，也可能减少，但不可能增加。 OPT:不存在Belady现象 最优置换算法置换出未来最长时间不访问的页面，这就意味着分配物理页数目为n时，置换一次页面之后，至少n次访问不会出现缺页，而n增大时，可以将缺页继续向后推迟，进而n增大时缺页数不可能会反而增加 LFU,Clock:不存在Belady现象 实际上，堆栈式页面置换算法都不会产生Belady现象，LRU,OPT，LFU,Clock均属于堆栈式页面置换算法，在堆栈式页面置换算法中，页面优先级的分配是独立于页面帧数的，对于堆栈式页面置换算法，分配的物理页面帧数增加时可以使得其缺页数减少，而FIFO这类算法，其替换页面的优先级决定于其分配的物理页面帧数，因此在这种情况下可能会出现Belady现象，而堆栈式算法则不会出现这样的状况。 参考资料: Efficient (stack) algorithms for analysis of write-back and sector memories [http://www.eecs.berkeley.edu/Pubs/TechRpts/1987/CSD-87-358.pdf section 1.3] Principles of Computer Operating Systemm Stack Page Replacement Policies [http://cseweb.ucsd.edu/classes/sp02/cse120_B/stack.html]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ucore_lab]]></title>
      <url>%2F2017%2F03%2F23%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2Fucore-lab%2F</url>
      <content type="text"><![CDATA[ucore_lab 实验中一些重要结构体参数的含义 Page结构体 每个Page描述了一个物理页 12345678910111213141516/* * * struct Page - Page descriptor structures. Each Page describes one * physical page. In kern/mm/pmm.h, you can find lots of useful functions * that convert Page to other data types, such as phyical address. * */struct Page &#123; int ref; // page frame&apos;s reference counter // 页帧的reference uint32_t flags; // array of flags that describe the status of the page frame // 描述页帧的标记位， unsigned int unsigned int property; // the num of free block, used in first fit pm manager // 空闲块的数量， 用于first fit算法 list_entry_t page_link; // free list link // page_link&#125;; set_bit, clear_bit宏 123456set_bit(int nr,void *addr)；// 将addr中第nr位的值置为1 返回addr原第nr为的值，即0或者1clear_bit(int nr,void *addr)；// 将addr中第nr位的值置为0 返回addr原第nr为的值的反码test_bit(int nr, volatile void *addr) // 改为是否为1， 是1返回1，是0返回0 123456#define SetPageReserved(page) set_bit(PG_reserved, &amp;((page)-&gt;flags))#define ClearPageReserved(page) clear_bit(PG_reserved, &amp;((page)-&gt;flags))#define PageReserved(page) test_bit(PG_reserved, &amp;((page)-&gt;flags))#define SetPageProperty(page) set_bit(PG_property, &amp;((page)-&gt;flags))#define ClearPageProperty(page) clear_bit(PG_property, &amp;((page)-&gt;flags))#define PageProperty(page) test_bit(PG_property, &amp;((page)-&gt;flags)) 12#define PG_reserved 0 // if this bit=1: the Page is reserved for kernel, cannot be used in alloc/free_pages; otherwise, this bit=0 #define PG_property 1 // if this bit=1: the Page is the head page of a free memory block(contains some continuous_addrress pages), and can be used in alloc_pages; if this bit=0: if the Page is the the head page of a free memory block, then this Page and the mem. Or this Page isn't the head page. 12// convert list entry to page#define le2page(le, member) to_struct((le), struct Page, member)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数值分析]]></title>
      <url>%2F2017%2F03%2F21%2F%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[设𝑨,𝑩,𝑪均为𝑛×𝑛矩阵，且𝑩、𝑪非奇异，𝒃是𝑛维向量，要计算\(𝒙 = B^{-1} (2A+I)(C^{-1}+A)b\), 请给出一个合理、高效率的算法流程. \[y1 = C^{-1}b\] \[y2 = y1 + Ab\] \[y_3 = 2(Ay_2) + y_2\] \[ x = B^{-1}y_3\] 如果A的每个对角元的绝对值都比所在行的非对角元的绝对值的和要大,即 \[|a_{ii}|&gt;sum{j!=i}|a_{ij}|\] 对所有的i成立,那么称A是（行）严格对角占优阵. 如果A’是行严格对角占优阵,那么称A是列严格对角占优阵. 习惯上如果不指明哪种类型的话就认为是行对角占优. 矩阵特征值的几何意义 矩阵乘法对应了一个变换，是把任意一个向量变成另一个方向或长度都大多不同的新向量。在这个变换的过程中，原向量主要发生旋转、伸缩的变化。如果矩阵对某一个向量或某些向量只发生伸缩变换，不对这些向量产生旋转的效果，那么这些向量就称为这个矩阵的特征向量，伸缩的比例就是特征值。 实际上，上述的一段话既讲了矩阵变换特征值及特征向量的几何意义（图形变换）也讲了其物理含义。物理的含义就是运动的图景：特征向量在一个矩阵的作用下作伸缩运动，伸缩的幅度由特征值确定。特征值大于1，所有属于此特征值的特征向量身形暴长；特征值大于0小于1，特征向量身形猛缩；特征值小于0，特征向量缩过了界，反方向到0点那边去了。 特征值及特征向量定义 定义 设A是n阶方阵，如果数λ和n维非零列向量x使关系式 Ax=λx (1) 成立，那么这样的数λ称为矩阵A特征值，非零向量x称为A的对应于特征值λ的特征向量．（1）式也可写成， ( A-λE)X=0 (2) 这是n个未知数n个方程的齐次线性方程组，它有非零解的充分必要条件是系数行列式 |A-λE|=0 , (3) 特征值 来自维基百科的解释 在数学上，特别是线性代数中，对于一个给定的线性变换\(A\)，它的特征向量（eigenvector，也译固有向量或本征向量）\(v\) 经过这个线性变换之后，得到的新向量仍然与原来的\(v\)保持在同一条直线上，但其长度或方向也许会改变。即 \[ Av=\lambda v\] \(\lambda\) 为标量，即特征向量的长度在该线性变换下缩放的比例，称 \(\lambda\) 为其特征值（本征值）。如果特征值为正，则表示\(v\)在经过线性变换的作用后方向也不变；如果特征值为负，说明方向会反转；如果特征值为0，则是表示缩回零点。但无论怎样，仍在同一条直线上。图1给出了一个以著名油画《蒙娜丽莎》为题材的例子。在一定条件下（如其矩阵形式为实对称矩阵的线性变换），一个变换可以由其特征值和特征向量完全表述，也就是说：所有的特征向量组成了这向量空间的一组基底。一个特征空间(eigenspace)是具有相同特征值的特征向量与一个同维数的零向量的集合，可以证明该集合是一个线性子空间，比如 \[ E_{\lambda}=\{u \in V\mid Au=\lambda u\}\] 即为线性变换 A中以λ为特征值的特征空间。 这些概念在纯数学和应用数学的众多领域中都有重要的应用。在线性代数和泛函分析之外，甚至在一些非线性的情况下，这些概念都是十分重要的。 \(\mathbf{A}\)的特征向量\(\mathbf {x}\) ，按照定义，是在变换 \(\mathbf{A}\)的作用下会得到 \(\mathbf {x}\) 自身的若干倍的非零向量。假设在 \(\mathbf{A}\)的作用下 \(\mathbf {x}\) 变成了自身的 \(\lambda\) 倍，也就是 \(\mathbf{A} \mathbf{x} = \lambda \mathbf{x}\) 在等式两边的左侧乘以单位矩阵I，得到 \[\mathbf{IA} \mathbf{x} =\mathbf{I} \cdot \lambda \mathbf{x} \] \(\mathbf{A}\mathbf{x} = (\lambda I)\mathbf{x}\) 因此 \((\mathbf{A}-\lambda \mathbf{I}) \mathbf{x}=0\) 根据线性方程组理论，为了使这个方程有非零解，矩阵 \(\mathbf{A}-\lambda \mathbf{I}\)的行列式必须是零： \[\det(\mathbf{A}-\lambda \mathbf{I}) = 0\] 按照行列式的展开定义，上面式子的左端是一个关于 \(\lambda\) 的多项式，称为特征多项式。这个多项式的系数只和 \(\mathbf{A}\)有关。在这个例子中，可以计算这个特征多项式： \[\det\!\left(\begin{bmatrix}1 &amp; 0\\ -\frac{1}{2} &amp; 1\end{bmatrix} - \lambda\begin{bmatrix}1 &amp; 0\\ 0 &amp; 1\end{bmatrix} \right)=(1-\lambda)^2\] 在这种情况下特征多项式的方程变成 \[(1-\lambda)^2 = 0\]它的唯一的解是： \(\lambda=1\)。这就是矩阵 \(\mathbf{A}\)的特征值。 找到特征值 \(\lambda=1\)后，就可以找出 \[(\mathbf{A}-\lambda \mathbf{I}) \mathbf{x}=0\] 的非零解，也就是特征向量了。在例子中： \[\begin{bmatrix}1-\lambda &amp; 0\\ -\frac{1}{2} &amp; 1-\lambda \end{bmatrix}\begin{bmatrix}x_1\\ x_2\end{bmatrix}=0\] 将\(\lambda=1\)代入，就有 \[\begin{bmatrix}0 &amp; 0\\ -\frac{1}{2} &amp; 0 \end{bmatrix}\begin{bmatrix}x_1\\ x_2\end{bmatrix}=0\] 解这个新矩阵方程，得到如下形式的解： \[\mathbf{x} = \begin{bmatrix}0\\ c\end{bmatrix}\] 这里的c是任意非零常量。因此，矩阵\(\mathbf{A}\)的特征向量就是所有竖直方向的向量（比如图中红色箭头代表的向量）。 正定矩阵的判定 判定定理1：对称阵A为正定的充分必要条件是：A的特征值全为正。 判定定理2：对称阵A为正定的充分必要条件是：A的各阶顺序主子式都为正。 判定定理3：任意阵A为正定的充分必要条件是：A合同于单位阵。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[lec8 SPOC思考题]]></title>
      <url>%2F2017%2F03%2F21%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2Flec8-SPOC%E6%80%9D%E8%80%83%E9%A2%98%2F</url>
      <content type="text"><![CDATA[内存访问局部性的应用程序例子 (1)(w4l2)下面是一个体现内存访问局部性好的简单应用程序例子，请参考，在linux中写一个简单应用程序，体现内存局部性差，并给出其执行时间。 123456789101112#include &lt;stdio.h&gt;#define NUM 1024#define COUNT 10int A[NUM][NUM];void main (void) &#123; int i,j,k; for (k = 0; k&lt;COUNT; k++) for (i = 0; i &lt; NUM; i++) for (j = 0; j &lt; NUM; j++) A[i][j] = i+j; printf("%d count computing over!\n",i*j*k);&#125; 可以用下的命令来编译和运行此程序： 12gcc -O0 -o goodlocality goodlocality.ctime ./goodlocality 可以看到其执行时间。 执行该段代码，输出的执行时间为： 123real 0m0.045suser 0m0.043ssys 0m0.002s 将i、j顺序调换，更改数组访问时间之后 123456789101112131415161718#include &lt;stdio.h&gt;#define NUM 1024#define COUNT 10int A[NUM][NUM];int main (void) &#123; int i,j,k; for (k = 0; k&lt;COUNT; k++) for (j = 0; j &lt; NUM; j++) for (i = 0; i &lt; NUM; i++) A[i][j] = i+j; printf("%d count computing over!\n",i*j*k);&#125;10485760 count computing over!real 0m0.266suser 0m0.251ssys 0m0.014s 更换ij顺序之后，局部性较差，执行时间也就相应较长，因为数组在存储器中是按照行顺序的存储的，而CPU提取cache中数据时会将其相邻位置数据载入，缺页的加载也是以页为单位的载入，因此，行扫描时数据缺失的情况会更少，执行时间会更短。 缺页异常嵌套 （1）缺页异常可用于虚拟内存管理中。如果在中断服务例程中进行缺页异常的处理时，再次出现缺页异常，这时计算机系统（软件或硬件）会如何处理？请给出你的合理设计和解释。 参考条目： Lenky @ Double Fault &amp; Triple Fault [http://www.lenky.info/archives/2012/04/1479] Wiki Double_fault [https://en.wikipedia.org/wiki/Double_fault] Wiki Triple_fault [https://en.wikipedia.org/wiki/Triple_fault] 解答: 在中断服务例程中进行缺页异常处理时，系统处于内核态，此时如果再次出现缺页异常，也就意味着内核出现了问题，（这种现象称为Double Fault）,由参考条目1中的提示可知，在x86中，发生Double Fault的情况有以下几种： First Exception Second Exception Benign Contributory Page Fault Benign x x x Contributory x Double Fault x Page Fault x Double Fault Double Fault 在遇到Double Fault时，操作系统无法对这种异常进行恢复，但会收集相关的信息，关闭对应的程序和服务，而如果此时处理Double Fault异常的函数也出现了异常，则会进一步发生Triple Fault，这时CPU只能进行机器的重启。 缺页中断次数计算 （2）如果80386机器的一条机器指令(指字长4个字节)，其功能是把一个32位字的数据装入寄存器，指令本身包含了要装入的字所在的32位地址。这个过程最多会引起几次缺页中断？ 提示：内存中的指令和数据的地址需要考虑地址对齐和不对齐两种情况。需要考虑页目录表项invalid、页表项invalid、TLB缺失等是否会产生中断？ 解答：指令字长4字节，在极端情况下有可能恰好在两个相邻页的中间，进而取指令时会引发两次缺页中断，而数据也是4字节，与之相似，最多可引发两次缺页中断，从而这个过程最多可引起4次缺页中断。 补充：在x86中，TLB缺失是由硬件进行处理的，不会触发中断，而页表是常驻内存的，不会触发中断，例如，对于二级页表来说，页目录项为invalid时，其对应的页表实际上并不存在，当实际需要时动态进行分配，但是并不会产生异常。页表项为invalid时，其页表中存储了其在磁盘中的索引,或者该映射既没有在内存中，也没有在硬盘上，但是这些都不会产生缺页中断。 虚拟页式存储的地址转换 （3）(spoc) 有一台假想的计算机，页大小（page size）为32 Bytes，支持8KB的虚拟地址空间（virtual address space）,有4KB的物理内存空间（physical memory），采用二级页表，一个页目录项（page directory entry ，PDE）大小为1 Byte,一个页表项（page-table entries PTEs）大小为1 Byte，1个页目录表大小为32 Bytes，1个页表大小为32 Bytes。页目录基址寄存器（page directory base register，PDBR）保存了页目录表的物理地址（按页对齐）。 PTE格式（8 bit） : 1VALID | PFN6 ... PFN0 PDE格式（8 bit） : 1VALID | PT6 ... PT0 其 123VALID==1表示，表示映射存在；VALID==0表示，表示内存映射不存在（有两种情况：a.对应的物理页帧swap out在硬盘上；b.既没有在内存中，页没有在硬盘上，这时页帧号为0x7F）。PFN6..0:页帧号或外存中的后备页号PT6..0:页表的物理基址&gt;&gt;5 已经建立好了1个页目录表和8个页表，且页目录表的index为0~7的页目录项分别对应了这8个页表。 在物理内存模拟数据文件中，给出了4KB物理内存空间和4KBdisk空间的值，PDBR的值。 请手工计算后回答下列虚地址是否有合法对应的物理内存，请给出对应的pde index, pde contents, pte index, pte contents，the value of addr in phy page OR disk sector。 123451) Virtual Address 6653:2) Virtual Address 1c13:3) Virtual Address 6890:4) Virtual Address 0af6:5) Virtual Address 1e6f: 解答：根据 04-1-spoc-memdiskdata.md物理内存模拟数据文件， PDBR 值为 0xd80, 对应页号为0x6c, 8KB的虚拟地址空间需要13bit编址， 4KB物理地址需要12bit编址，一级页表中页目录项需要5bit定位，二级页表中页表项需要5bit定位，页内偏移用5bit编址，页帧号用7bit编址 题目中给出的是16bit虚拟地址，其中14-10位页目录项的index， 9-5位为页表项的index， 4-0位为页内偏移 Virtual Address 6653: 1230 110_01 10_010 1_0011 --&gt; pde index: 0x19(11001) pde contents: (valid 0x0, pt 0x7f) --&gt; Fault (page directory entry not valid) 2)Virtual Address 1c13: 123450001 1100 0001 00110 001_11 00_000 1_0011--&gt; pde index:0x07 pde contents:(0xbd, 1 011 1101, valid 1, pfn 0x3d) --&gt; pte index:0x00, 页号0x3d pte contents:(valid 1, pfn 0x76) --&gt; Page 76 ,To Physical Address 0xed3(0 1110 1101 0011) --&gt; Value: 02 3)Virtual Address 6890: 12340110 1000 1001 00000 110_10 00_100 1_0000--&gt; pde index:0x1a pde contents:(valid 0, pfn 0x7f)--&gt; Fault (page directory entry not valid) 4)Virtual Address 0af6: 123450000 1010 1111 01100 000_10 10_111 1_0110--&gt; pde index:0x02 pde contents:(0xa1(1 010 0001), valid 1, pfn 0x21) --&gt; pte index:0x17 页号0x21 pte contents:(valid 0, pfn 0x7f) --&gt; Fault (page directory entry not valid) 5)Virtual Address 1e6f: 1234 0 001_11 10_011 0_1111 --&gt; pde index:0x7 pde contents:(0xbd, valid 1, pfn 0x3d) --&gt; pte index:0x13, 页号0x3d pte contents:(0x16, valid 0, pfn 0x16)--&gt; To Disk Sector Address 0x2cf (0010 1100 1111) --&gt; Value: 1c]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[机器学习-朴素贝叶斯]]></title>
      <url>%2F2017%2F03%2F19%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%2F</url>
      <content type="text"><![CDATA[朴素贝叶斯原理 youryion数据挖掘指导 朴素贝叶斯法属于一种分类方法，基于特征条件独立假设学习输入输出的联合概率分布，以此为模型，对于给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。 简单有效，是一种常用的机器学习方法. 设输入空间 \(X \subseteq R^n\)为n维向量的集合 输出空间为类标记集合 \(Y=c_1, c_2,\cdots,c_k\) X是定义在输入空间上的随机变量 Y是定义在输出空间上的随机变量 P(X,Y)是X和Y的联合概率分布 \(T = (x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\)是由P(X,Y)独立同分布产生的训练集 贝叶斯法则 条件概率 条件概率表示为P（A|B），读作“在B条件下A的概率”。 若只有两个事件A，B，那么 \[P(A|B) = \frac{P(AB)}{P(B)}\] 贝叶斯法则 引入独立性假设 得到朴素贝叶斯分类器 拉普拉斯平滑]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[机器学习实验-朴素贝叶斯分类器]]></title>
      <url>%2F2017%2F03%2F18%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E9%AA%8C-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%2F</url>
      <content type="text"><![CDATA[提示：个人联系方式及代码简要说明、运行方式在README.md文件中 实验目的 在真实数据集上实现朴素贝叶斯分类器，并验证其分类效果 了解如何在测试数据集上实现一个机器学习算法 了解如何评价分类效果 了解如果分析实验结果 算法实现原理 假设各条件相互间独立，即\[P(y|x_1,\cdots,x_n)P(y) \propto \prod_{i=1}^{n}P(x_i|y)\] 在训练时训练 \(P(y)\) 以及\(P(x_i|y)\) 测试时输出 \[\hat y = argmax_yP(y)\prod_{i=1}^{n}P(x_i|y)\] 数据集处理 数据集描述 实验给定了Adult数据集，其中adult.train为训练集（32561条数据），adult.test为测试集(16281条数据)，每行数据代表一个人，共有15个维度的特征，最后一个特征为该人的收入是否超过了50K。 数据集中部分特征是连续数据，部分数据可能未知(用?表示) 分类器的性能评价指标： 本次实验中，我采用了准确率作为朴素贝叶斯分类器性能的评价指标，计算方法为： \[Accuracy = \frac{number\ of\ correctly\ classified\ records}{number\ test\ records}\] 数据集的变量及其含义 变量名 意义 数据特征 处理方式 age 年龄 连续数据 分段离散 work_class 职业类型 离散数据 fnlwgt 最终重量(?) 连续数据 无意义、忽略 education 学历等级 离散数据 education_num 学历的数字等级 连续数据 重复、忽略 marital-status 婚姻状况 离散数据 occupation 职业 离散数据 relationship 家庭关系 离散数据 race 人种 离散数据 sex 性别 离散数据 capital_gain 资本利得 连续数据 离散化 capital_loss 资本损失 连续数据 离散化 hours_per_week 每周工作时长 连续数据 离散化 native-country 出生国 离散 income 收入 离散 特殊数据的处理方式 未知数据？的处理 数据集中有未知的数据(?), 我的处理方式是将这类数据直接忽略掉 数据合并 使用R语言对数据进行统计，发现，Never-worked和Without-pay可以合并为Without-pay字段。 数据的离散化 数据规律探索 考虑到R语言对数据处理的优越性，因此采用R语言对数据规律进行探索，利用R语言读入测试集和训练集 123456# 读取测试集，已清除？test = read.csv("after.test", sep=",", header=F, col.names=c("age", "work_class", "fnlwgt", "education", "education_num", "marital-status", "occupation", "relationship", "race", "sex", "capital_gain", "capital_loss", "hourr_per_week","native-country", "income"), fill = FALSE, strip.white = T) 然后对连续数据做统计之后得到如下结果 Age的规律 12345678&gt; table(train$age) 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 328 447 594 629 621 674 824 752 799 745 789 808 774 813 851 789 837 836 828 852 828 791 786 765 769 741 743 704 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 706 711 683 523 555 575 571 455 448 394 386 343 337 344 332 276 259 213 186 173 136 110 111 90 80 64 54 40 73 74 75 76 77 78 79 80 81 82 83 84 85 86 88 90 49 38 34 29 20 14 15 16 13 7 5 8 3 1 3 35 可知年龄范围为17~90，我们设置其分割粒度为5 资本收益 资本收益 可以从统计结果看出，投资收益相互间差别很大，直接以固定颗粒度分割并不适合，考虑到投资和收入之间存在一定的关系，而且可以很明显的看出收益为0的占了所有数据的大部分，我们将其分为三个类别，没有资本收益，资本收益较少，资本收益较大，。 除去数据中为0的值之后，求得其平均值，中位数，方差如下： 123456789&gt; # 资本收益平均值&gt; mean(train$capital_gain[train$capital_gain!=0])[1] 12977.6&gt; # 资本收益中位数&gt; median(train$capital_gain[train$capital_gain!=0])[1] 7298&gt; # 资本收益方差&gt; sd(train$capital_gain[train$capital_gain!=0])[1] 22311.91 可以看出其方差较大，以平均值作为界点不合适，我们取其中位数作为资本收益高低的界点(训练集与测试集这个数据差别不大) 同理，资本损失的数据也有这样的规律，我们也用这样的方法对其进行处理。 123456789&gt; # 资本损失平均值&gt; mean(train$capital_loss[train$capital_loss!=0])[1] 1867.898&gt; # 资本损失中位数&gt; median(train$capital_loss[train$capital_loss!=0])[1] 1887&gt; # 资本损失收益方差&gt; sd(train$capital_loss[train$capital_loss!=0])[1] 361.8574 资本损失的差异值不大，我们直接取中位数作为分界点 每周工作时间 每周工作时间 工作时间为1~99， 分割粒度设置为5 各连续变量的范围及对应的分割粒度如下： 变量名 范围 分割粒度 age 17~90 5 capital_gain 0 ~ 99999 0，0~7298，7298+ capital_loss 0 ~ 4356 0，0~1887， 1887+ hours_per_week 1~99 5 实验结果的分析 训练集规模的影响 问题：训练集的规模对分类效果有什么影响？ 选取5%， 50%， 100%的训练集数据训练分类模型 测试数据的选择，经过多方面的对比测试，发现选取的特征值为 1年龄 工作类别 学历等级 婚姻状况 职业 投资利得 投资损失 收入 时，训练的模型分类效果最好。以此为基础，分别选取 5%， 50%， 100%的训练集数据训练分类模型时的训练结果对比如下： 比例 训练集数目 准确率 5% 1494 83.71% 50% 15075 83.99% 100% 30162 84.12% 由这个表格可以看出，随着数据集的增加，分类器的分类效果越来越好。而实际上，即使只取了5%（1494条训练数据），训练出的分类器分类效果仍然挺好的，可以由此体会到贝叶斯分类的高效性和实用性。 重复随机抽取样本实验（5次），记录最小，最大，平均准确率 随机比例 训练集数目 准确率 70.13% 21131 83.99% 47.92% 14458 84.01% 94.40% 28472 84.04% 58.65% 17687 84.14% 11.83% 3566 83.95% 最小值 最大值 平均值 83.95% 84.14% 84.03% 综合两个测试结果可以得出如下结论：数据集的规模会对分类效果产生一定影响，但这种影响并不是绝对的，当抽取的训练集具有随机性时，小训练集也有可能会有特别好的分类效果，不过整体来看，训练集规模越大，分类效果越好。 0概率的处理 当测试集中某个数据的某条特征值取了某个值\(x_i\)，但训练集中该特征值并没有取过该值\(x_i\)，则在训练时\(P(x_i|y) = 0\)，由此在做测试时计算其概率\[\hat y = argmax_yP(y)\prod_{i=1}^{n}P(x_i|y)\]时会得到概率为0。 解决方法：通常我们会进行拉普拉斯平滑处理，即在计算条件概率时对每个\(x_i\) 做\(+\lambda\)处理, 对应的总数也需要做\(+M\lambda\)，经过测试可以发现，在未做拉普拉斯平滑时，训练集取50%时，分类准确率为83.95%， 加上拉普拉斯平滑处理之后，分类准确率为83.99%， 准确率有一定提升。 连续特征以及未知特征的处理 连续数据如何进行处理 说明：【数据的分析及离散化方案】见前面【3.4.3数据的离散化】小节。由于后期经过测试发现特征选取年龄 工作类别 学历等级 婚姻状况 职业 投资利得 投资损失 收入这8个特征时分类效果最好，故前面测试样例的特征选取均选择了这8个，为了测试连续数据分割方案对分类效果的影响，将每周工作时间这一连续特征加入分类的特征中。 测试时，训练集取100%， 拉普拉斯平滑处理的\(\lambda = 1\) 各连续特征值分割粒度与其分类效果对比 特征 分割粒度 准确率 age 不分割 83.816% age 3 83.831% age 5 83.751% age 10 83.784% 特征 分割粒度 准确率 hour 不分割 83.845% hour 3 83.845% hour 5 83.752% hour 10 83.804% 特征 分割粒度 准确率 投资收益与损失 不分割 【85.20%】 投资收益与损失 1000 83.62% 投资收益与损失 无，低，高 83.75% （注意：测试某一特征时，其余特征分割情况默认为： 年龄分割粒度 5， 每周工作时间分割粒度为5， 投资收益和损失分割为无， 收益/损失低, 收益/损失高） 结果分析：这里发现了一些很尴尬的结果，对这三个连续特征值进行不同粒度离散之后发现，【不进行离散】，直接以每一个数据单独作为一个类别进行分类时准确率反而比对其进行不同间距离散之后分类【准确率高】，特别是【投资收益与损失】的两个特征值，不进行离散时其准确率甚至高达 【85.2%】，而进行了等间距离散或者以无，低、高， 结合前面对各个特征的分布情况的统计可以进行如下猜测： 结合前面age, work hour, capital_gain, capital_loss几个特征值的取值特征统计结果， 可以发现，age和work hour在各个取值中虽然较为分散，但是也有小范围集中，简单的等间距离散，对其分类的优化效果不大，甚至于有可能因为粒度过大而使分类效果显著下降， 当分割粒度恰好使得集中数据分在了一个category时，其准确率会略高一点，而如果恰好使之分散开，可能会对分类准确率有反作用，如work hour特征分割粒度为5和10的对比。 对于投资收益和损失这两个特征值，分析其数据特征可以发现，有超过70%的数据是0，而其他数据就较为零散并且差异值极大，简单地等间距分割，或者以中位数，平均数作为临界点进行分割都是不太合理的，因此这种情况下不进行离散化分类效果反而会更好，（不知道高斯分布处理会不会优化其分类效果，由于能力和时间限制，没来得及进行测试） 未知数据如何处理 对于未知数据的处理，我做了两种情况的对比，一种是直接忽略掉这些数据，另一种是将‘？’也视为一种数据和特征 处理方案 准确率 忽略未知数据 84.12% 视为新类型 【84.45%】 可以看出，将未知数据视为一种特殊的新类型时其分类准确率有较大提高，可知这些数据某种程度上也能够反映出其收入的高低 选取的特征值对比 选取的特征值 准确率 年龄 工作类别 重量 学历等级 教育年限 婚姻状况 职业 家庭关系 人种 性别 投资利得 投资损失 每周工作时间 出生国 收入 79.77% 年龄 工作类别 学历等级 婚姻状况 职业 家庭关系 人种 性别 投资利得 投资损失 每周工作时间 出生国 收入 81.85% 年龄 工作类别 学历等级 婚姻状况 职业 家庭关系 性别 投资利得 投资损失 每周工作时间 出生国 收入 81.83% 年龄 工作类别 学历等级 婚姻状况 职业 人种 投资利得 投资损失 每周工作时间 收入 83.74% 年龄 工作类别 学历等级 婚姻状况 职业 投资利得 投资损失 每周工作时间 收入 83.75% 年龄 工作类别 学历等级 婚姻状况 职业 投资利得 投资损失 收入 84.12% 年龄 工作类别 教育年限 婚姻状况 职业 收入 81.79% 由这个表的对比分析可以明显地感受到特征值的选取对分类效果的影响,【年龄,工作类别,学历等级,婚姻状况,职业,投资利得,投资损失】这几个特征值能够很大程度上反应出其收入的高低，特别是投资收入和损失，这个特征与收入有较大的相关性，这也是为什么在【5.3.1 连续数据如何进行处理】一节中提到对这两个特征不进行分割时其分类效果甚至可以高达85.20%的一个原因。 这也提醒我们在选取训练数据时注意对特征值的选取，有代表性的特征对其分类准确率有促进作用，而一些无关的特征则会对分类效果有负作用。 交叉验证 选取不同比例的测试集数据用作训练，观察其对分类效果的影响 测试集比例 训练集+测试集 准确率 0% 15075 + 0 83.99% 5% 15075 + 751 84.02% 50% 15075 + 7525 84.23% 100% 15075 + 15060 84.26% [注] 训练集选取的是50%训练集数据 由这个数据对比可以看出，训练模型时加入部分测试集数据，对分类效果有提升作用。 实验总结及结论 本次实验实现了贝叶斯分类算法，并探讨了数据规模、特征值的选择对分类效果的影响，以及连续值，未知值的不同离散方案和处理方案对分类效果的影响，并探讨了拉普拉斯平滑对分类效果的影响。 通过多方面的对比，主要得出了以下一些结论: 特征值的选取对分类效果影响较大，可以根据特征值与类别的相关性大小判断其对分类是有帮助的还是有干扰的。 特征值个数也对分类效果有一定影响，选择合适的，足够的特征作为分类依据是较好的，特征值的选择和个数的选择可通过参数的调整进行尝试后得出最优方案 数据规模对分类效果有一定影响，但是只要特征值选取较好，训练数据较少情况下训练出的模型其分类效果也较好。 连续值的处理方式对分类效果影响较大，对于一些本身比较离散并且该特征值对类型影响较大情况下，分割粒度越小，分类效果会更好，尤其是本实验中投资收入和投资损失两个特征值，不进行分割时其准确率甚至高达85.2%，可明显体会到数据离散粒度对分类效果的影响。 未知数据的处理，未知数据视为一种特殊类型也是一种比较有效的处理方式，背后原因可能是这些没统计到数据的人群可能具有某方面的共性，其收入也会受到这方面的影响。 本次实验中自己收获很大，特别是学会了从不同的方面去评价一个算法的性能的方式的分析方法。此外，对编程也有一些新的启发，在编程时需要注意面向对象编程，考虑到各种可能的变化，本次实验中的贝叶斯分类器的实现方法我参考了【参考资料1 使用python编写朴素贝叶斯分类器】一文的实现方式，这种实现可以达到一种自适应的状态，不论特征值有多少个，是什么类型的数据，只要给出参数，均可对其进行训练和分类，这就方便了我们进行不同的特征值对分类效果的影响分析时的测试，只需要对测试文件和训练文件做对应修改即可。此外，在实现过程中设置了很多参数，可以方便进行训练数据比例，是否随机选取，特征值分割粒度，是否进行拉普拉斯平滑处理等进行设置，极大地方便了测试和分析。 参考资料 使用Python编写朴素贝叶斯分类器 https://dataminingguide.books.yourtion.com/chapter-6/chapter-6-6.html Dataset: Adult (R) http://scg.sdsu.edu/dataset-adult_r/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[搜索引擎性能评价实验]]></title>
      <url>%2F2017%2F03%2F18%2F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%2F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%80%A7%E8%83%BD%E8%AF%84%E4%BB%B7%E5%AE%9E%E9%AA%8C%2F</url>
      <content type="text"><![CDATA[实验步骤 自由分组， 至多2人一组 构建查询样例集合：利用网络资源(http://top.baidu.com/; http://top.sogou.com/等) 和个人使用经验构建查询样例集合，查询样例集合需覆盖不同查询热门程度（ 冷门/热门） 和各种类型的用户查询需求（ 导航类/信息类/事务类），样例集合的规模为10个查询，各类比例为2:5:3， 并根据个人经验，撰写每个查询样例的信息需求内容。 构建Pooling：学生根据其构建的查询样例集合，抓取常用的三个中文搜索引擎(百度、360好搜、 搜狗)对这部分查询词的查询结果，每个搜索引擎抓取查询结果的前十位结果，并利用这些结果 构建Pooling。 构建相关性标注集合：根据步骤2中撰写好的信息需求，对Pooling里的结果进行标注，标注为 “ 答案” 和“ 非答案” 两类即可。 根据标注结果，依据MAP，P@10，MRR等评价指标对各个搜索引擎的查询性能进行评价，并对 搜索引擎满足不同信息需求的情况加以比较，每人各自撰写实验报告。 查询样例集合创建 导航类 丝芙兰官网（热门） 河海大学主页（冷门） 信息类 萨德(热门), 美对朝忍耐到尽头(热门)，红薯 地瓜（冷门），青铜器制作流程（冷门）, 烟草学专业(冷门) 事务类 NBA直播(热门)， 金刚狼3下载（热门），张家界联想笔记本维修（冷门） 查询样例信息需求 丝芙兰官网（热门）：找到丝芙兰官网，查看产品信息，功效，购买方式等等 河海大学主页（冷门）：找到河海大学的校园主页 萨德：关于萨德的最新新闻，以及事件经历 美对朝忍耐到尽头：相关的新闻 红薯 地瓜：红薯与地瓜是否是同一种事物，各地有什么区别 青铜器制作流程：直接给出青铜器的制作方法 烟草学专业：查询专业简介，需要给出专业学习内容，就业方向，相关学校 NBA直播：最新NBA赛事直播，比分情况，赛况解说等 金刚狼3下载：给出电影的下载链接或者在线观看链接 张家界联想笔记本维修：给出维修点，联系方式等 构建pooling 针对三个搜索引擎分别抓取对应搜索数据，并进行标记，抓取结果及Pooling标记结果见【统计数据.xls】 性能指标计算 首先需要明确性能指标的计算方法 平均准确率（AP）： \[AP=\frac{1}{N}\sum_{i=1}^NPrecision(i)\] MAP MAP方法是Mean Average Precison，即平均准确率法的简称。其定义是求每个相关文档检索出后的准确率的平均值（即Average Precision）的算术平均值（Mean），即 \[MAP = mean(AP)\] RR 首位相关结果倒数RR,即出现第一个相关性标注的排序的倒数 \[RR = \frac{1}{Rank(1)}\] MRR MRR是平均排序倒数（Mean Reciprocal Rank）的简称，MRR方法主要用于寻址类检索（Navigational Search）或问答类检索（Question Answering）,MRR方法首先计算每一个查询的第一个相关文档位置的倒数，然后将所有倒数值求平均。 P@N P@N本身是Precision@N的简称，指的是对特定的查询，考虑位置因素，检测前N条结果的准确率 基于此，计算各词条的RR,P@10，AP，以及对搜索引擎的MRR,MAP，P@10结果如下： 分词条结果 进一步统计各个搜索引擎对不同类型的关键词的搜索结果性能： 各搜索引擎不同类别的统计结果 实验结论 按照统计结果做出各项指标的柱状图如下： MAP MP@10 MRR 总体的数据 由统计结果分析，从总体来看，在各项指标中，百度是三个搜索引擎中表现最好的,360的性能次之，而搜狗的结果则稍差一些。 导航类搜索词 对于导航类搜索关键词，RR一般用作评价导航类的查询需求，用于表示用户在知道目标前需要浏览的结果数目，可以看到，三大搜索引擎的导航类关键词的MRR指标均为1，可以发现，当用户想要搜索的信息为已知资源，主页，资源等信息时，搜索引擎可能会更倾向于返回给用户一些官方的主页信息，以使用户能够尽快找到目标，对于导航类信息的其他指标，相差也不大，但是P@10的指标值相差比较大，百度的P@10值是较好的，而360和搜狗的结果则稍差，查看原始搜索结果标记，三大搜索引擎都加入了对应的百科，问答平台，而搜狗和360的结果还夹杂了不少“同名的广告”，以“河海大学主页”词条为例，360和搜狗的结果中有不少标题虽是“河海大学招生网”等信息，但实际是一些培训机构的页面，两家的搜索引擎并没有做这方面的剔除，使得结果首页多了不少奇怪的“广告”，影响了搜索体验。另一个比较有趣的现象是，河海大学离退休工作处官网的名称是“河海大学主页”，这个页面在三大搜索引擎的结果中排第2、3位，可见搜索引擎背后会根据用户的点击数据调整结果的显示顺序。 信息类搜索词 信息类数据是用户搜索需求中占比最大的，用户的关注点在于结果的全面和权威性，对于这类搜索词，搜索引擎多数会给出其问答平台的结果，相关新闻结果，或者百科结果。对于信息类关键词，P@10是评价其搜索性能的较好指标，百度的数据在70%左右，而360和搜狗在60%左右，可见在中文搜索中，百度的确做得比较好，对于大多数信息类搜索词，百度的结果足够全面。对于新闻类的信息，三大搜索引擎结果差别并不是特别大，但是对于一些知识类信息，或者生活类信息的搜索，360和搜狗的表现则差强人意，以“红薯 地瓜”关键词为例，用户的搜索需求是查询红薯地瓜的区别，百度的结果大体上与之相符，而搜狗和360除了少数两三条结果与之相关，多数结果只与红薯有关，可以推测是由于搜索引擎的分词和联合搜索系统的处理方式的差异。 事务类搜索词 事物类搜索词中，百度的结果优势不是那么明显，甚至略差，360的结果则稍微更好一些， 这里差异较大的词条是金刚狼3下载这个搜索词条，其实这个词条是一个坑，一般来说这类资源可能在互联网上很少甚至不存在，因此很多数据可能其实是广告或者一些死链接，这时可能更需要搜索引擎去剔除一些不必要的结果以帮助用户完成其任务需求，360的结果大多数是迅雷的链接，而百度的结果则包含了各种不同的站点，这些站点大多数是广告等非用户目标站点，可能是出于广告费等方面的考虑吧，使得其结果表现并不好。 冷热门 对于热门数据，三大搜索引擎的表现都比较好，冷门数据百度表现依然较好，而360和搜狗的性能则有所下降，一方面可能是由于百度的市场占有率更大，用户更多，能够获取到的用户数据也更多更全面，即使是冷门搜索词由于有较大的用户基数也能得到较好地反馈结果，另一方面，百度的数据抓取可能更全面，对于不同类别的搜索词，百度的P@10指标均能达到近70%，可见其数据是比较齐全的，这也给其冷门搜索词的搜索提供的数据。 总结 从各方面的分析可以看出，百度的性能的确是最好的，分析推测其原因如下：百度的实力更强，硬件资源，软件资源均遥遥领先于其他两家搜索引擎，这就使得百度可以拿到更多的数据，拿到更全面的数据，这会对搜索引擎性能有较大的影响；此外，百度的用户群体更大，丰富的用户数据可以帮助百度动态优化其搜索结果的排序，进而提升用户体验；百度的分词和检索算法可能更优，正如前面提到的“地瓜 红薯”词条，百度的结果是两个词的联合结果，而360和搜狗的结果可能只与其中一个有关。对于搜狗来说，其搜索结果中有时总是会有微信或者知乎的结果，当用户的意图并不在此时，可能会极大地影响其体验。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CCF2016]]></title>
      <url>%2F2017%2F03%2F16%2F%E7%AE%97%E6%B3%95%2FCCF2016%2F</url>
      <content type="text"><![CDATA[2016年CCF真题练习 Mac 下C++的编译 gcc -o target source.cpp -lstdc++ 2016-12 第一题 中间数 试题名称： 中间数 时间限制： 1.0s 内存限制： 256.0MB 12345678910111213141516171819202122232425262728293031问题描述 在一个整数序列a1, a2, …, an中，如果存在某个数，大于它的整数数量等于小于它的整数数量，则称其为中间数。在一个序列中，可能存在多个下标不相同的中间数，这些中间数的值是相同的。 给定一个整数序列，请找出这个整数序列的中间数的值。输入格式 输入的第一行包含了一个整数n，表示整数序列中数的个数。 第二行包含n个正整数，依次表示a1, a2, …, an。输出格式 如果约定序列的中间数存在，则输出中间数的值，否则输出-1表示不存在中间数。样例输入62 6 5 6 3 5样例输出5样例说明 比5小的数有2个，比5大的数也有2个。样例输入43 4 6 7样例输出-1样例说明 在序列中的4个数都不满足中间数的定义。样例输入53 4 6 6 7样例输出-1样例说明 在序列中的5个数都不满足中间数的定义。评测用例规模与约定 对于所有评测用例，1 ≤ n ≤ 1000，1 ≤ ai ≤ 1000。 思路：调用库函数进行排序，然后从中间向两侧进行查找 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt; #include &lt;cstring&gt; #include &lt;algorithm&gt;using namespace std;int a[1002];int main(int argc, char const *argv[])&#123; /* code */ int n = 0; cin &gt;&gt; n; for(int i = 0; i &lt; n; ++i) &#123; cin&gt;&gt;a[i]; &#125; sort(a, a+ n); int min = n/2; int max = n/2; // 一开始这里的设置是错的 for(int i = n/2; i&lt; n; ++i) &#123; if(a[n/2] &lt; a[i]) &#123; max = i; break; &#125; &#125; for(int i = n/2; i&gt;=0; --i) &#123; if(a[n/2] &gt; a[i]) &#123; min = i; break; &#125; &#125; if(n-1-max+1 == min + 1 || (max ==n/2 &amp;&amp; min ==n/2) ) &#123; cout &lt;&lt; a[n/2]&lt;&lt;"\n"; &#125; else &#123; cout&lt;&lt; -1&lt;&lt;"\n"; &#125; return 0;&#125; 2016-12第二题 工资计算 试题编号： 201612-2 试题名称： 工资计算 时间限制： 1.0s 内存限制： 256.0MB 12345678910111213141516171819202122问题描述 小明的公司每个月给小明发工资，而小明拿到的工资为交完个人所得税之后的工资。假设他一个月的税前工资（扣除五险一金后、未扣税前的工资）为S元，则他应交的个人所得税按如下公式计算： 1） 个人所得税起征点为3500元，若S不超过3500，则不交税，3500元以上的部分才计算个人所得税，令A=S-3500元； 2） A中不超过1500元的部分，税率3%； 3） A中超过1500元未超过4500元的部分，税率10%； 4） A中超过4500元未超过9000元的部分，税率20%； 5） A中超过9000元未超过35000元的部分，税率25%； 6） A中超过35000元未超过55000元的部分，税率30%； 7） A中超过55000元未超过80000元的部分，税率35%； 8） A中超过80000元的部分，税率45%； 例如，如果小明的税前工资为10000元，则A=10000-3500=6500元，其中不超过1500元部分应缴税1500×3%=45元，超过1500元不超过4500元部分应缴税(4500-1500)×10%=300元，超过4500元部分应缴税(6500-4500)×20%=400元。总共缴税745元，税后所得为9255元。 已知小明这个月税后所得为T元，请问他的税前工资S是多少元。输入格式 输入的第一行包含一个整数T，表示小明的税后所得。所有评测数据保证小明的税前工资为一个整百的数。输出格式 输出一个整数S，表示小明的税前工资。样例输入9255样例输出10000评测用例规模与约定 对于所有评测用例，1 ≤ T ≤ 100000。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IPv6协议转发实验]]></title>
      <url>%2F2017%2F03%2F16%2F%E7%BD%91%E7%BB%9C%2FIPv6%E5%8D%8F%E8%AE%AE%E8%BD%AC%E5%8F%91%E5%AE%9E%E9%AA%8C%2F</url>
      <content type="text"><![CDATA[p{ text-indent: 2em; } 实验目的 通过前面的实验，我们已经深入了解了 IPv6 协议的分组接收和发送处理流程。本实验需要将实验模块的角色定位从通信两端的主机转移到作为中间节点的路由器上，在 IPv6 分组收发处理的基础上，实现分组的路由转发功能。 网络层协议最为关注的是如何将 IPv6 分组从源主机通过网络送达目的主机，这个任务就是由路由器中的 IPv6协议模块所承担。路由器根据自身所获得的路由信息，将收到的 IPv6分组转发给正确的下一跳路由器。如此逐跳地对分组进行转发，直至该分组抵达目的主机。 IPv6 分组转发是路由器最为重要的功能。 本实验设计实现路由器中的 IPv6 协议，可以在原有 IPv6 分组收发实验的基础上，增加 IPv6 分组的转发功能。对网络的观察视角由主机转移到路由器中，了解路由器是如何为分组选择路由，并逐跳地将分组发送到目的端的。 大家在本实验中也会初步接触路由表这一重要的数据结构，认识路由器是如何根据路由表对分组进行转发的。 实验具体任务 对于每一个到达本机的 IPv6 分组，根据其目的 IPv6 地址查找本机的路由表，对该分组进行如下的几类操作： 丢弃查不到路由的分组； 向上层协议上交目的地址为本机地址的分组； 根据路由查找结果，向相应接口转发其余的分组。 实验内容 实验内容主要包括： 设计路由表数据结构：设计路由表所采用的数据结构。要求能够根据 IPv6 地址来确定分组处理行为（丢弃、 上交或转发），转发情况下需获得下一跳的 IPv6 地址。路由表的数据结构和查找算法会极大的影响路由器的转发性能，有兴趣的同学可以深入思考和探索。 IPv6 分组的接收和发送：对前面实验中所完成的代码进行修改，在路由器协议栈的 IPv6 模块中能够正确完成分组的接收和发送处理。具体要求不做改变，参见IPv6 分组收发实验。 IPv6 分组的转发：对于需要转发的分组进行处理，获得下一跳的 IP 地址，然后调用发送接口函数进一步处理。 实验过程： 程序整体设计流程 程序运行流程 实验流程如图1所示，在下层接收接口函数stud_ipv6_fwd_deal( )中(图1接口函数1)，实现 分组接收处理。其主要功能是根据分组中目的 IPv6 地址查找路由表，根据路由表查找结果进行后续处理。 分组需要上交，则调用接口函数ipv6_fwd_LocalRcv( )(图 5.1 中接口函数2); 需要丢弃，则调用函数 ipv6_fwd_DiscardPkt( )(图 5.1 中函数5); 需要转发，则进行转发操作。转发操作的实现要点包括: Hop Limit 值减 1，然后调用发送接口函数 ipv6_fwd_SendtoLower( )(图 5.1 中接口函数 4)将分组发送出去。 接口函数ipv6_fwd_SendtoLower( )比前面实验增加了一个参数nexthop，要求 在调用时传入下一跳的 IPv6 地址，此地址是通过查找路由表得到的。 另外，本实验增加了一个路由表配置的接口(图1中函数6)，要求能够根据系统所给信息来设定本机路由表。实验中只需要简单地设置静态路由信息，以作为分组接收和发送处理的判断依据。 路由表数据结构设计及路由查找过程 在本实验的实现过程中，我的路由表数据结构是采用链表进行实现的，路由查找时顺序遍历链表比对掩码和目的地址，并记录当前最长匹配结果。路由的掩码匹配做法是先将IPv6地址转换为128bit的位数组，然后比对掩码长度位，具体如下： 转换为bitset&lt;128&gt; 位数组 123456789bitset&lt;128&gt; trans_bit_addr(ipv6_addr addr) &#123; bitset&lt;128&gt; bit_ipv6; for (int i = 0; i &lt; 4; ++i) &#123; bit_ipv6 = bit_ipv6 | (bitset&lt;128&gt; (addr.dwAddr[3-i]) ) &lt;&lt; (32 * i); // 按位或将ipv6_addr的四个long型数据转换为对应的位数组，左移96，64，32，0位 &#125; return bit_ipv6;&#125; 路由查找 1234567891011121314151617181920212223242526272829303132333435list&lt;stud_ipv6_route_msg&gt;::iterator router;bool match = false;// 是否找到匹配项int MAX_LENGTH = 0;// 标记当前最长匹配// 利用bitset将目的ip地址转换为128位数组bitset&lt;128&gt; dest_ipv6 = trans_bit_addr(*dest_addr);ipv6_addr next;for(router = router_tables.begin(); router != router_tables.end(); ++router) &#123; // 遍历路由表 if (router -&gt; masklen &lt; MAX_LENGTH) &#123; // 短于当前已匹配路由表 continue; &#125; // 将路由表中目的ip地址换算为bit表示的数组 bitset&lt;128&gt; router_dest = trans_bit_addr(router -&gt; dest); bool local_match = true; for(int i = 0; i &lt; router -&gt; masklen; ++i) &#123; if (router_dest[i] != dest_ipv6[i]) &#123; local_match = false; break; &#125; &#125; if (local_match) &#123; match = true; // 匹配则更新masklen, 更新路由地址 next = router -&gt; nexthop; MAX_LENGTH = router -&gt; masklen; &#125;&#125; 优化措施 这样的设计其实效率是比较低的，可以进一步完成的优化是：在插入新的路由信息至路由链表时，按照掩码从大到小的顺序插入，这样在遍历查找路由信息时，查找到第一个匹配的记录即可停止遍历。 更进一步的优化是采用二叉树的形式进行构建。 下层分组接收函数 stud_ipv6_fwd_deal( ) 本函数是 IPv6 协议接收流程的下层接口函数，实验系统从网络中接收到分组后 会调用本函数。调用该函数之前已完成 IPv6 分组的合法性检查，因此本函数应该考虑实现 如下功能: 判定是否为发给本机的分组，如果是，则调用 ipv6_fwd_LocalRcv(). 1234567891011121314151617181920// a. 查找是否是发向本机// 先获取目的地址，第192bit起为目的ip，故偏移24Byteipv6_addr *dest_addr = (ipv6_addr*) (pBuffer + 24);ipv6_addr *local_addr = new ipv6_addr();// 本地IPv6地址getIpv6Address(local_addr);bool is_lcoal = true;for(int i = 0; i &lt;16; ++i) &#123; if(dest_addr-&gt;bAddr[i] != local_addr-&gt;bAddr[i]) &#123; // 分组不是本地 is_lcoal = false; break; &#125;&#125;if(is_lcoal) &#123; // 是本机接收分组，直接上交 ipv6_fwd_LocalRcv(pBuffer, length); return 0;&#125; 按照最长匹配原则查找路由表，获取下一跳 IPv6 地址。查找失败，则调用 ipv6_fwd_DiscardPkt(). 123456789101112131415161718192021222324252627282930313233343536// b. 按照最长匹配查找路由表获取下一跳，查找失败则调用ipv6_fwd_DiscardPkt( )；∂list&lt;stud_ipv6_route_msg&gt;::iterator router;bool match = false;// 是否找到匹配项int MAX_LENGTH = 0;// 标记当前最长匹配// 利用bitset将目的ip地址转换为128位数组bitset&lt;128&gt; dest_ipv6 = trans_bit_addr(*dest_addr);ipv6_addr next;for(router = router_tables.begin(); router != router_tables.end(); ++router) &#123; // 遍历路由表 if (router -&gt; masklen &lt; MAX_LENGTH) &#123; // 短于当前已匹配路由表 continue; &#125; // 将路由表中目的ip地址换算为bit表示的数组 bitset&lt;128&gt; router_dest = trans_bit_addr(router -&gt; dest); bool local_match = true; for(int i = 0; i &lt; router -&gt; masklen; ++i) &#123; if (router_dest[i] != dest_ipv6[i]) &#123; local_match = false; break; &#125; &#125; if (local_match) &#123; match = true; // 匹配则更新masklen, 更新路由地址 next = router -&gt; nexthop; MAX_LENGTH = router -&gt; masklen; &#125;&#125; 查找成功，则调用 ipv6_fwd_SendtoLower()，完成分组发送。 转发过程中注意对 Hop Limit 的处理。 123456789101112131415161718// c. 需要转发，hop limit - 1 ,调用 ipv6_fwd_SendtoLower( )完成报文发送if(match) &#123; // 获取hop limit，注意转换为本地字节序 char HopLimit = *(char *)(pBuffer + 7); HopLimit -= 1; memcpy(pBuffer + 7, &amp;(HopLimit), sizeof(char)); if(HopLimit == 1) &#123; // 直接发向目的地址 ipv6_fwd_SendtoLower(pBuffer, length, dest_addr); return 0; &#125; if(HopLimit &gt; 1) &#123; ipv6_fwd_SendtoLower(pBuffer, length, &amp;next); return 0; &#125;&#125; 实验结果分析 分析传输的报文，处理正确 实验结果 遇到的问题及解决 掩码的比对问题，由于IPV6地址是128位长，其实际存储结构为 123456typedef union&#123; char bAddr[16]; unsigned short wAddr[8]; long dwAddr[4];&#125;ipv6_addr; 其掩码比对无法像IPV4地址那样直接简单地进行移位操作，因此，我想到的一个解决方法是将其转换为长度为128的位数组，进一步依次进行比较。 处理IPV6数据包时的网络字节序和本机字节序问题，网络字节序是大端模式，而本机字节序一般是小端模式，因此需要注意其字节序的转换，在本实验的实现过程中，IPv6地址的比较是采用按位比对的模式，由于计算机底层硬件bit序并不受解析模式的影响，因此不需要考虑字节序转换问题，而解析hop limit时，由于是直接截取的char类型(8 bit),也不会受字节序的影响，也没有必要进行字节序的转换。 思考题：实验指导书的思考题（2） IPv6和IPv4地址长度存在显著差别，考虑路由查找过程中各自采用什么样的数据结构和算法有助于提高查找效率 答： IPV4的地址为32位长，不考虑空间占用的话，实际上最快的一种数据结构应该是二叉树，即根据目的地址的比特串构建二叉树即可，这样搜索时最多需要32步，可以说是可以极大的减小查询时间，当然这样的空间占用会比较高，通常会做出压缩的优化以及其他优化，可以说IPv4的路由查询可以做到非常高效的查询。 而IPv6地址长度为128位，是不可能像IPv4那样建一个二叉比特树的，查阅相关资料，有如下解决方案： 已有IPv6路由表的统计结果和地址分配策略表明，长度大于48比特的前缀比例很低，仅为5%左右，因此可对IPv6地址的高48位采用多分支trie进行查找，剩余的16比特直接采用hash查找。根据IPv6地址前缀的分布特点，构造查找步宽为24-8-8-8-16的五层多分支TrieC树，限制最坏情况下路由查找的访存次数。 通过这样的方式可以极大地加快IPV6的路由查询。 总结 本次实验实现了IPV6分组的转发，通过本次实验，我更加清晰地认识了网络原理课程中的IPv6数据 包转发的过程，对最长匹配原则也有了一个清晰的理解，对网络字节序和本机字节序有了更深入的理解。感谢助教的热心帮助。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux/Mac 常用命令]]></title>
      <url>%2F2017%2F03%2F15%2Flinux-Mac-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[使用pandoc将markdown输出为pdf 安装配置及常用命令 pandoc的安装与配置 12345678910111213141516171819pandoc hello-world.md -o out.pdf --latex-engine=xelatexpandoc -D latex &gt; mytemplate.tex# 如果提示pandoc无法找到插件xelatex（支持输出中文），则下载Tex，BasicTexpandoc hello-world.md -o out.pdf --latex-engine=/Library/TeX/texbin/xelatex# tips：可以将该路径加入$PATH# 指定中英文字体pandoc -N -s --toc --smart --latex-engine=xelatex -V CJKmainfont='Kai' -V mainfont='Monaco' -V geometry:margin=1in hello-world.md -o output.pdfpandoc -N -s --toc --smart -V CJKmainfont='Songti SC' -V mainfont='Monaco' --variable sansfont="Monaco" --variable monofont="Monaco" --variable fontsize=26pt --latex-engine=xelatex -V geometry:margin=1in IPv6协议转发实验.md -o example14.pdfpandoc -s --smart --template default.tex -V CJKmainfont='Songti SC' -V mainfont='Monaco' --variable sansfont="Monaco" --variable monofont="Monaco" --latex-engine=xelatex -V geometry:margin=1in --listings -H code.tex OS-lec9-exercise.md -o lec9.pdf- --toc: 生成带目录的pdf文档pandoc -s -N --toc --smart --template /Users/alexzhangch/Documents/git_project/blog/qingfeng14.github.io/source/_posts/default.tex -V CJKmainfont='Songti SC' -V mainfont='Monaco' --variable sansfont="Monaco" --variable monofont="Monaco" --latex-engine=xelatex -V geometry:margin=1in --listings -H /Users/alexzhangch/Documents/git_project/blog/qingfeng14.github.io/source/_posts/code.tex 密码学-Exercise1.md -o out.pdf Mac 下的中文字体集 12345678910宋体仿宋 STFangsong宋体黑体 STHei宋体简体 Songti SC PingFang SC LingWai SC LiSong Pro LiHei Pro Libian SC Lantinghei TC Kaiti SC 1\documentclass[$if(fontsize)$$fontsize$,$endif$$if(lang)$$babel-lang$,$endif$$if(papersize)$$papersize$paper,$endif$$for(classoption)$$classoption$$sep$,$endfor$]&#123;$documentclass$&#125; pandoc 导出pdf 图片位置固定 Unix/Linux 系统下修改环境变量 123sudo vi .bash_profile# 添加需要增加的环境变量PATH=$PATH:/Library/TeX/texbin/ 然后重新启动terminal即可 sublime 快捷键插入自定义字符串 Preference-&gt; Key Bingding-&gt; 修改user settings 在其中加入自定义快捷键 123456&#123; "keys": ["alt+r"], "command": "insert_snippet", "args": &#123; "contents": "&lt;font color=red&gt;$&#123;1:&#125;$SELECTION&lt;/font&gt;$&#123;0&#125;" &#125; &#125;, 其中光标所在位置为${1:}$SELECTION所在地 树莓派开机自启动脚本 12345678910111213141516171819202122232425#!/bin/sh### BEGIN INIT INFO# Provides: auto_start# Required-Start: $remote_fs# Required-Stop: $remote_fs# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Start or stop the HTTP Proxy.### END INIT INFOcase $1 in start) # svnserve -d -r /home/pi/svn_repository python /home/pi/Documents/tips/auto_login.py python /home/pi/Documents/tips/start_note.py python /home/pi/Documents/tips/baidu_weather.py php5 /home/pi/Documents/tips/bind_dns/bind.php pi php5 /home/pi/Documents/tips/bind_dns/bind.php survey ;; stop) killall svnserve ;;*)echo "Usage: $0 (start|stop)";;esac 注：本意是想写一个可以开机自启动的脚本，脚本的目的是登录校园网，然后将本机的IP地址更新到自己的域名中，向linux机器添加开机自启动脚本的方法为： 123456789# 在/etc/init.d/文件夹下添加新的启动脚本，格式参考上面，注意需要加入BEGIN INIT INFO那一段注释，否则在加入启动项时会出现LSB不存在的errorsudo chmod +x 775 name# 给脚本足够运行权限sudo update-rc.d name defaults 95# 将自启动脚本name添加到自启动表项中，启动顺序为95，注意，需要使用网络的脚本顺序要大于90sudo update-rc.d -f name remove# 移除自启动项name 这样既可开机自启动该脚本了 但是在实际运行中发现并不能实现自动的登录以及域名解析的更新，分析了之后发现该脚本启动时间太早，机器还没有分到ip地址，无法完成网络请求，于是将该脚本加入到了/etc/rc.local自启动脚本中，linux系统的脚本启动顺序为： 123456/etc/init.d/ # init.d目录包含许多系统各种服务的启动和停止脚本。/etc/rc.local# 脚本是在系统初始化级别脚本运行之后再执行的，# 因此可以安全地在里面添加你想在系统启动之后执行的脚本。 在rc.local文件中，exit 0之前加入我们的启动脚本 为了保证可以联网，我们在脚本中设置了一个死循环，重复登录直到登录成功 12345678910111213141516while True: try: f = urllib2.urlopen(url, post_data) # `这里完成了向登录页面发送登录POST请求的操作，只有这一步成功完成之后才能进行下一步的绑定域名脚本的执行，如果尚未分配到ip则会进入异常处理等待5秒继续尝试登录` content = f.read() # print content result=urllib.urlopen('http://baidu.com').read() print result print os.popen('sh /home/pi/Documents/bind.sh').read() # 在python中执行shell脚本的方法，这个函数可以输出脚本的输出信息 print "Network is Ready!" break except Exception , e: print e print "Network is not ready,Sleep 5s..." time.sleep(5) python 调用命令行 os.popen这种调用方法可以输出脚本的输出信息,推荐使用 12import osos.popen('sh /home/pi/Documents/bind.sh').read() os.system 会输出一些奇怪的东西 12import osos.system("echo \"Hello World\"") 查看应用安装位置 12345# 查看运行文件所在处which hexo# 查看应用安装位置whereis hexo git 相关 git status 中文乱码问题: git config --global core.quotepath false git gitignore 不起作用: 1234git rm -r --cached .git add .git commit -m 'update .gitignore'git push -u origin master Mac 下鼠标设置 defaults read -g com.apple.mouse.scaling defaults write -g com.apple.mouse.scaling 7 mac GCC 问题 12ld: symbol(s) not found for architecture i386clang: error: linker command failed with exit code 1 (use -v to see invocation) 使用标准c库 1gcc -o run hw3a.cpp -lstdc++ Ubuntu 内存查看及释放 实时查看内存信息 123watch -n 1 free -mwatch -n 1 cat /proc/meminfo 释放内存 1234sudo sysctl -w vm.drop_caches=3sudo sync &amp;&amp; echo 3 | sudo tee /proc/sys/vm/drop_caches 123456789101112131415# 1. Freeing Up the Page Cacheecho 1 &gt; /proc/sys/vm/drop_caches# 2. Freeing Up the Dentries and Inodesecho 2 &gt; /proc/sys/vm/drop_caches# 3. Freeing Up the Page Cache, Dentries and Inodesecho 3 &gt; /proc/sys/vm/drop_caches# 4. Flushing the File System Bufferssync 树莓派查看ARM GPU内存分配 1vcgencmd get_mem arm &amp;&amp; vcgencmd get_mem gpu mysql 123456mkdir /var/run/mysqld/chown mysql: /var/run/mysqld/# Unknown/unsupported storage engine: InnoDB# 这条命令是关键sudo -u mysql mysqld --skip-innodb --default-storage-engine=myisam]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[计算机系统结构]指令系统]]></title>
      <url>%2F2017%2F03%2F15%2F%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84-%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F%2F</url>
      <content type="text"><![CDATA[指令系统，寻址方式，内存映射，大端小端，哈夫曼编码，单地址指令，两地址指令 \[\sum_{i=1}^n a_i=0\] 计算机系统的性能评价 时钟频率 指令执行速度 一种经典的表示运算速度的方法 MIPS(Million Instructions Per Second), GIPS, TIPS \[MIPS = \frac{指令条数}{执行时间\times 10^6} = \frac{Fz}{CPI} = IPC \times Fz\] 其中: Fz为处理机的工作主频 CPI(Cycles Per Instruction)为每条指令所需的平均时钟周期数 IPC(Instruction Per Cycle)为每个时钟周期平均执行的指令条数 平均速度 核心程序法 峰值速度]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[密码学]古典密码]]></title>
      <url>%2F2017%2F03%2F14%2F%E5%AF%86%E7%A0%81%E5%AD%A6%2F%E5%AF%86%E7%A0%81%E5%AD%A6-%E5%8F%A4%E5%85%B8%E5%AF%86%E7%A0%81%2F</url>
      <content type="text"><![CDATA[Description：移位密码，凯撒密码，置换密码 移位密码： 加密:ci= (pi+K) mod 26 解密:pi= (ci-K) mod 26 123密钥：整数， 1≤K ≤25 (26个英文字母)加密：明文P中的每个字母被它之后的第K个字母替代解密：密文C中的每个字母被它之前的第K个字母替代 凯撒密码 1当 K=3时，该密码体制成为凯撒密码(Caesar Cipher) 在古罗马的战争(公元前54年)中使用 置换密码 Lecture 2 置换密码（ Permutation Cipher）：保持明文的所有字母不变，只是利用置换打乱了明 文字母的位置和次序；对明文字符的位置进行重新排列的一种密码。 也称易位密码、换位密码、移位密码 m = n, 把明文每m个分割，然后按照\(\pi(x)\)的对应关系，调整明文顺序，形成密文，解密时反向进行即可 代换密码 Lecture 2 密钥K是所有的26个数字0,1,2…,25的一个置换， 即 – 加密： \(c_i=S(p_i)\) – 解密： \(p_i=S^{-1}(c_i)\) 安全性分析：暴力搜索所有的密钥不可行 \[26! = 4*10^{26} = 2^{88.4}\] (公元前一千年内) 元9世界， 阿拉伯科学家al-Kindi发明代换密码频率分析， 分析单个英文字母出现频率，两个连续字母出现的概率 代换密码频率分析步骤 统计密文单词频率，与英文字母表中字母频率进行比较 维吉尼亚密码 加密 掩盖了加密后的字母统计概率（多表替换） 使用多个移位密码(shift cipher) 维吉尼亚密码 123明文: A T T A C K A T D A W N密钥: L E M O N L E M O N L E密文: L X F O PV E F R N H R 解密； 分析方法 – 密钥空间大小为26m，若m很大，使用计算机穷尽密钥搜索也需要很长时间 – 寻找密钥长度，将问题变成简单的移位密码 如何寻找m ？ – 两种方法 • Kasiski测试法， 1863 • 重合指数法分析， 1920 Kasiski test（ 卡西斯基测试） – 基于以下事实 • 两段相同的明文段将被加密成相同的密文段，则他们的位置间距为m的倍数 – 算法 • 搜索长度至少为3的相同的密文段 • 记下离起始密码段的距离d1,d2,d3… • 则m整除gcd(d1,d2,d3…) 重合指数法（ Index of coincidence） – 定义：设x=x1x2x3…,xn是一条长度为n的串， x的重合指数Ic(x)定义为x中两个随机元素相同的 概率 重合指数法]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[[搜索引擎]性能评价]]></title>
      <url>%2F2017%2F03%2F14%2F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%2F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-%E6%80%A7%E8%83%BD%E8%AF%84%E4%BB%B7%2F</url>
      <content type="text"><![CDATA[搜索引擎性能评价的目的 对用户而言： 信息获取渠道 对搜索引擎广告商而言 对搜索技术研究人员而言 对搜索引擎服务提供者 从较差查询样例中学习 链接锚本重定向问题 清华美院 团、派 搜索引擎性能评价流程 1.1 搜索引擎性能评价的对象 网络服务提供商的属性 市场占用率、 网络信息检索工具属性 网络数据环境、用户群体 搜索引擎运行效果 响应时间 耗费的硬件资源 是否满足用户的信息需求 用户获取信息耗费的时间成本？ 根据用户的需求调整响应时间和查询质量？ 1.2 搜索引擎性能评价的Cranfield体系 黑箱评价方式：给定标准输入情况下，看系统输出与标准输出的差异 输入:语料库，查询样例、相关性标注 优势：复用性（一次标注，多次使用） 语料库采集 信息检索系统：提供固定的语料库集合，集合规模适当，数据质量可靠 商业搜索引擎：不提供固定的语料库集合，评价数据抓取子系统性能 查询样例集合构建 用户查询规模庞大 核心问题：如何采样：真实性，精确性，全面性 查询采样的真实性：反映用户实际需求 来源：用户查询日志行为（日志隐私保护）、公开数据资源 查询采样的精确性：减少数据标注困难 查询采样的全面性：综合评价各方面性能 少量查询样例代表大多数需求 采样依据：内容类别、热门程度、需求类型 查询信息需求决定了用户使用搜索引擎的满意度，数据环境复杂用户意图难以琢磨 搜索引擎用户信息需求分布： 导航类：查询某个已知存在的资源，页面 主页，考试资源等等 信息类：查询与某个主题相关的关键信息资源 获取相关信息，没有确定查询目标， 香港股市，，， 事务类：查找与完成某个特定任务相关的资源 垂直搜索引擎服务对象 如：xxx下载， 保证采样全面性：查询热门程度（冷热保证） 查询信息需求（2：5：3） 结果相关性标注 内容相关≠关键资源 相关性结果的共性要求： 结果提供的学习时新、真实可靠 结果的标题和摘要应当方便阅读并有效引导用户阅读 以信息需求类别为指导 Pooling 方法 文本语料=》查询样例集 》 手工相关性标注 准确率/召回率 准确率：找到的是否准确 召回率：找到的是否全面 信息检索强调序列的关系 搜索引擎性能指标设计 AP：平均准确率 搜索引擎用户行为的特殊性 前10个结果（85%） 搜索引擎用户信息需求的差异性 • 导航类信息需求的用户仅关注特定检索目标 • 信息类信息需求的用户关注全面而权威的信息 • 事务类信息需求的用户关注自己的任务是否可以顺利完成。 指标 适用 描述 RR 导航类 用户在找到搜索目标前需要浏览多少结果 P@N 信息类 结果列表中多大比例信息能够满足用户需求？ MAP 反映系统在全部相关文档上性能的单值指标。系统检索出来的相关文档越靠前(rank 越高)，MAP就应该越高 前n位成功率 事务类 用户是否能够利用给出的结果完成自己所关注的事务 首位相关结果倒数(Reciprocal Rank) \[RR = \frac{1}{Rank(1)}\] 适用于导航类型的查询信息需求（ 用户在找到搜索目标前需要浏览多少结果？ ） 前N位准确率(Precision@N) 适用于信息类型的查询信息需求（ 结果列表中多大比例信息能够满足用户需求？ ） 前N位成功率(Success@N) 适用于事务类型的查询信息需求（ 用户是否能够利用给出的结果完成自己所关注的事务？ ） 其他 NDCG@N: • Normalized Discounted Cumulative Gain • 对结果进行多级相关性标注时适用 • ERR: Expected Reciprocal Rank • Supported by Yahoo! and Google • 可以获取用户行为数据时适用 • B-pref: Binary preference • 相关性标注不完整时适用 P@N的计算方法 P@N本身是Precision@N的简称，指的是对特定的查询，考虑位置因素，检测前N条结果的准确率。例如对单次搜索的结果中前5篇，如果有4篇为相关文档，则P@5 = 4/5 = 0.8 。 测试通常会使用一个查询集合（按照前文所述方法构造），包含若干条不同的查询词，在实际使用P@N进行评估时，通常使用所有查询的P@N数据，计算算术平均值，用来评判该系统的整体搜索结果质量。 N的选取 对用户来说，通常只关注搜索结果最前若干条结果，因此通常搜索引擎的效果评估只关注前5、或者前3结果，所以我们常用的N取值为P@3或P@5等。 对一些特定类型的查询应用，如寻址类的查询（Navigational Search），由于目标结果极为明确，因此在评估时，会选择N=1（即使用P@1）。举个例子来说，搜索“新浪网”、或“新浪首页”，如果首条结果不是 新浪网（url：www.sina.com.cn），则直接判该次查询精度不满足需求，即P@1=0 MRR 平均倒数排序 MRR是平均排序倒数（Mean Reciprocal Rank）的简称，MRR方法主要用于寻址类检索（Navigational Search）或问答类检索（Question Answering），这些检索方法只需要一个相关文档，对召回率不敏感，而是更关注搜索引擎检索到的相关文档是否排在结果列表的前面。 MRR方法首先计算每一个查询的第一个相关文档位置的倒数，然后将所有倒数值求平均。 MRR 上述的P@N方法，易于计算和理解。但细心的读者一定会发现问题，就是在前N结果中，排序第1位和第N位的结果，对准确率的影响是一样的。但实际情况是，搜索引擎的评价是和排序位置极为相关的。即排第一的结果错误，和第10位的结果错误，其严重程度有天壤之别。因此在评价系统中，需要引入位置这个因素。 MRR是平均排序倒数（Mean Reciprocal Rank）的简称，MRR方法主要用于寻址类检索（Navigational Search）或问答类检索（Question Answering），这些检索方法只需要一个相关文档，对召回率不敏感，而是更关注搜索引擎检索到的相关文档是否排在结果列表的前面。MRR方法首先计算每一个查询的第一个相关文档位置的倒数，然后将所有倒数值求平均。例如一个包含三个查询词的测试集，前5结果分别为： 查询一结果：1.AN 2.AR 3.AN 4.AN 5.AR 查询二结果：1.AN 2.AR 3.AR 4.AR 5.AN 查询三结果：1.AR 2.AN 3.AN 4.AN 5.AR 其中AN表示不相关结果，AR表示相关结果。那么第一个查询的排序倒数（Reciprocal Rank）RR1 = 1/2=0.5 ；第二个结果RR2 = 1/2 = 0.5 ； 注意倒数的值不变，即使查询二获得的相关结果更多。同理，RR3= 1/1 = 1。 对于这个测试集合，最终MRR=（RR1+RR2+RR3）/ 3 = 0.67 然而对大部分检索应用来说，只有一条结果无法满足需求，对这种情况，需要更合适的方法来计算效果，其中最常用的是下述MAP方法。 MAP MAP方法是Mean Average Precison，即平均准确率法的简称。其定义是求每个相关文档检索出后的准确率的平均值（即Average Precision）的算术平均值（Mean）。这里对准确率求了两次平均，因此称为Mean Average Precision。（注：没叫Average Average Precision一是因为难听，二是因为无法区分两次平均的意义） MAP 是反映系统在全部相关文档上性能的单值指标。系统检索出来的相关文档越靠前(rank 越高)，MAP就应该越高。如果系统没有返回相关文档，则准确率默认为0。 MAP:全称mean average precision(平均准确率)。mAP是为解决P，R，F-measure的单点值局限性的，同时考虑了检索效果的排名情况。 计算如下： 假设有两个主题，主题1有4个相关网页，主题2有5个相关网页。某系统对于主题1检索出4个相关网页，其rank分别为1, 2, 4, 7；对于主题2检索出3个相关网页，其rank分别为1,3,5。对于主题1，平均准确率为(1/1+2/2+3/4+4/7)/4=0.83。对于主题 2，平均准确率为(1/1+2/3+3/5+0+0)/5=0.45。则MAP=(0.83+0.45)/2=0.64。”]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello Hexo]]></title>
      <url>%2F2017%2F03%2F14%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new "My New Post" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy 草稿 草稿相当于很多博客都有的“私密文章”功能。 1$ hexo new draft "new draft" 会在source/_drafts目录下生成一个new-draft.md文件。但是这个文件不被显示在页面上，链接也访问不到。也就是说如果你想把某一篇文章移除显示，又不舍得删除，可以把它移动到_drafts目录之中。 如果你希望强行预览草稿，更改配置文件： 1render_drafts: true 或者，如下方式启动server： 1$ hexo server --drafts 下面这条命令可以把草稿变成文章，或者页面： 1$ hexo publish [layout] &lt;filename&gt; More info: Deployment MathJax MathJax 常用命令 mathjax 常用 推荐 手写识别 修复公式不正常 在blog文件夹中执行： 1$ hexo math install 在_config.yml文件中添加： 12plugins:- hexo-math 使用 1Simple inline $a = b + c$. 效果： Simple inline \(a = b + c\). MathJax Block: 1234$$\frac&#123;\partial u&#125;&#123;\partial t&#125;= h^2 \left( \frac&#123;\partial^2 u&#125;&#123;\partial x^2&#125; +\frac&#123;\partial^2 u&#125;&#123;\partial y^2&#125; +\frac&#123;\partial^2 u&#125;&#123;\partial z^2&#125;\right)$$ 效果： \[\frac{\partial u}{\partial t} = h^2 \left( \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} + \frac{\partial^2 u}{\partial z^2}\right)\] 为Hexo Next博客添加关键词功能 修改文件：themes\next\layout_partials\head.swig 1234567&#123;% if page.keywords %&#125; &lt;meta name="keywords" content="&#123;&#123; page.keywords &#125;&#125;" /&gt;&#123;% elif page.tags and page.tags.length %&#125; &lt;meta name="keywords" content="&#123;% for tag in page.tags %&#125;&#123;&#123; tag.name &#125;&#125;,&#123;% endfor %&#125;" /&gt;&#123;% elif theme.keywords %&#125; &lt;meta name="keywords" content="&#123;&#123; theme.keywords &#125;&#125;" /&gt;&#123;% endif %&#125; 修改内容：35行左右，将原来的设置ketwords的代码覆盖即可 1234567&#123;% if page.keywords and page.keywords.length %&#125; &lt;meta name="keywords" content="&#123;% for key in page.keywords %&#125;&#123;&#123; key &#125;&#125;,&#123;% endfor %&#125;" /&gt;&#123;% elif page.tags and page.tags.length %&#125; &lt;meta name="keywords" content="&#123;% for tag in page.tags %&#125;&#123;&#123; tag.name &#125;&#125;,&#123;% endfor %&#125;" /&gt;&#123;% elif theme.keywords %&#125; &lt;meta name="keywords" content="&#123;&#123; theme.keywords &#125;&#125;" /&gt;&#123;% endif %&#125; hexo 中设置访问密码 在themes-&gt;next-&gt;layout-&gt;_partials-&gt;head.swig中的meta标签之后添加js代码 123456789101112131415161718192021222324252627282930313233&lt;script src=&quot;https://cdn.bootcss.com/js-sha1/0.4.1/sha1.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;http://cdn.bootcss.com/blueimp-md5/1.1.0/js/md5.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; loopy() function loopy() &#123; if(&apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; while(true) &#123; var pass = prompt(&quot;输入正确密码才能查看!&quot;); if(pass) &#123; // 点击的确定 var ss = sha1(pass) // alert(ss); if(ss == &apos;&#123;&#123; page.password &#125;&#125;&apos;) &#123; alert(&quot;欢迎进入我的博客！Contact me at zhangshenghao1995@163.com&quot;); break; &#125; else &#123; alert(&quot;密码错误！&quot;); &#125; &#125; else if(pass == &quot;&quot;) &#123; // 用户没有输入 &#125; else &#123; // 点击取消 history.back() &#125; &#125; &#125;&#125; &lt;/script&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[现代密码学作业1]]></title>
      <url>%2F2017%2F03%2F14%2F%E5%AF%86%E7%A0%81%E5%AD%A6%2F%E5%AF%86%E7%A0%81%E5%AD%A6-Exercise1%2F</url>
      <content type="text"><![CDATA[1.5 使用穷尽密钥搜索方法破译如下利用移位密码加密的密文 BEEAK FYDJX UQYHY JIQRY HTYJI QFBQD UYJII KFUHC QD 解：移位密码的加解密方法为： 12加密：明文P中的每个字母被它之后的第K个字母替代解密：密文C中的每个字母被它之前的第K个字母替代 为了方便使用python编程完成遍历： 12345678import syspassword = 'BEEAK FYDJX UQYHY JIQRY HTYJI QFBQD UYJII KFUHC QD'password = password.replace(' ', '')for i in range(0, 26): print i, "\t", for word in password: sys.stdout.write(chr(((ord(word) - i) - (65-26)) % 26 + 97)) sys.stdout.write('\n') 输出结果为： 12345678910111213141516171819202122232425260 beeakfydjxuqyhyjiqryhtyjiqfbqduyjiikfuhcqd1 addzjexciwtpxgxihpqxgsxihpeapctxihhjetgbpc2 zccyidwbhvsowfwhgopwfrwhgodzobswhggidsfaob3 ybbxhcvagurnvevgfnoveqvgfncynarvgffhcrezna4 xaawgbuzftqmudufemnudpufembxmzqufeegbqdymz5 wzzvfatyespltctedlmtcotedlawlypteddfapcxly6 vyyuezsxdroksbsdcklsbnsdckzvkxosdccezobwkx7 uxxtdyrwcqnjrarcbjkramrcbjyujwnrcbbdynavjw8 twwscxqvbpmiqzqbaijqzlqbaixtivmqbaacxmzuiv9 svvrbwpuaolhpypazhipykpazhwshulpazzbwlythu10 ruuqavotznkgoxozyghoxjozygvrgtkozyyavkxsgt11 qttpzunsymjfnwnyxfgnwinyxfuqfsjnyxxzujwrfs12 pssoytmrxliemvmxwefmvhmxwetperimxwwytivqer13 orrnxslqwkhdlulwvdeluglwvdsodqhlwvvxshupdq14 nqqmwrkpvjgcktkvucdktfkvucrncpgkvuuwrgtocp15 mpplvqjouifbjsjutbcjsejutbqmbofjuttvqfsnbo16 lookupintheairitsabirditsaplaneitssuperman17 knnjtohmsgdzhqhsrzahqchsrzokzmdhsrrtodqlzm18 jmmisnglrfcygpgrqyzgpbgrqynjylcgrqqsncpkyl19 illhrmfkqebxfofqpxyfoafqpxmixkbfqpprmbojxk20 hkkgqlejpdawenepowxenzepowlhwjaepooqlaniwj21 gjjfpkdioczvdmdonvwdmydonvkgvizdonnpkzmhvi22 fiieojchnbyuclcnmuvclxcnmujfuhycnmmojylguh23 ehhdnibgmaxtbkbmltubkwbmltietgxbmllnixkftg24 dggcmhaflzwsajalkstajvalkshdsfwalkkmhwjesf25 cffblgzekyvrzizkjrsziuzkjrgcrevzkjjlgvidre 查看输出的26条结果，发现lookup in the air its a bird its a plane its superman是其中有意义的语句，相应秘钥为K=16 1.6 (a) 设\(\pi\) 为集合{1,2,\(\cdots\),8}上的置换： \(x\) 1 2 3 4 5 6 7 8 \(\pi(x)\) 4 1 6 2 7 3 8 5 求出逆置换 \(\pi^{-1}\) 解密下列使用置换密码加密的密文，密钥是\((a)\)中的\(\pi^{-1}\) \[ETEGENLMDNTNEOORDAHATECOESAHLRMI\] 解： (a). 逆置换\(\pi^{-1}\) \(x\) 1 2 3 4 5 6 7 8 \(\pi^{-1}(x)\) 2 4 6 1 8 3 5 7 (b). 解密，秘钥是\((a)\)中的\(\pi^{-1}\), 则解密时使用置换\(\pi\)进行解密，按8个字母分组，\[ETEGENLM , DNTNEOOR , DAHATECO , ESAHLRMI , \] 解密得：\[GENTLEME\ NDONOTRE\ ADEACHOT\ HERSMAIL\] 明文为：\[gentlemen\ don&#39;t\ read\ each\ others\ mail.\] 1.21 以下给出的四段密文,第一个由代换密码加密而成第二个由维吉尼亚密码加密而成,第三个由仿射密码加密而成,最后一个不知其具体的密码体制,试从密文确定其明文。要求给出清晰的分析过程,包括统计分析和进行的计算。 代换密码: 1EMGLOSUDCGDNCUSWYSFHNSFCYKDPUMLWG YICOXYSIPJCKQPKUGKMGOLICGINCGACKSNISACYKZSCKXECJCKSHYSXCGOIDPKZCNKSHICGIWYGKKG KGOLDSILKGOIUSIGLEDSPWZUGFZCCNDGY YSFUSZCNXEOJNCGYEOWEUPXEZGACGNFGLKNSACIGOIYCKXCJUCIUZCFZCCNDGYYSFEUEKUZCSOCFZC CNCIACZEJNCSHFZEJZEGMXCYHCJUMGKUCY 提示:F解密到w 解： Step1 字母频数统计: (‘C’, 37), (‘G’, 24), (‘S’, 20), (‘K’, 18), (‘I’, 15), (‘Y’, 15), (‘U’, 14), (‘N’, 13), (‘Z’, 13), (‘E’, 12), (‘O’, 10), (‘F’, 9), (‘D’, 8), (‘J’, 7), (‘L’, 7), (‘X’, 7), (‘P’, 6), (‘A’, 5), (‘H’, 5), (‘M’, 5), (‘W’, 5), (‘Q’, 1) 于是猜测：\(S(e) = C\) Step2 统计双字出现频率 [(‘CG’, 7), (‘CK’, 5), (‘CN’, 5), (‘CY’, 4), (‘CJ’, 3), (‘CI’, 3), (‘CC’, 3), (‘CF’, 2), (‘CS’, 2), (‘CO’, 1), (‘CZ’, 1), (‘CU’, 1)] [(‘ZC’, 7), (‘AC’, 5), (‘NC’, 5), (‘CC’, 3), (‘XC’, 3), (‘IC’, 3), (‘UC’, 2), (‘JC’, 2), (‘YC’, 1), (‘OC’, 1), (‘DC’, 1), (‘EC’, 1), (‘FC’, 1), (‘SC’, 1), (‘HC’, 1)] 出现次数最多的双字为CG,和ZC G可能是r,s,n,d,a中的一个，GC没有出现，故G不是r,G出现24次，频率为0.09， 假设S(a)=G Z的出现频率为 0.05， ZC(Ze)出现频率约0.02, 推测S(h)=Z SC（Se）出现1次(0.0039)，没有CS(eS),S出现20次（0.078），猜测S(o)=S AC出现5次，频率0.019， A出现频率为0.0195， 已知F解密到w，此时该字符串如下： 1EMaLOoUDeaDNeUoWYowHNoweYKDPUMLWaYIeOXYoIPJeKQPKUa KMaOLIeaINeaAeKoNIoAeYKhoeKXEeJeKoHYoXeaOIDPKheNKoHIeaIWYaKKaKaOLDoILKaOIUoI aLEDoPWhUawheeNDaYYowUoheNXEOJNeaYEOWEUPXEhaAeaNwaLKNoAeIaOI YeKXeJUeIUhewheeNDaYYowEUEKUheoOewheeNeIAehEJNeoHwhEJhEaMXeYHeJUMaKUeY wheeN出现次数较多，猜测S(l) = N 1EMaLOoUDeaDleUoWYowHloweYKDPUMLWaYIeOXYoIPJeKQPKUaKMaOLI eaIleaAeKolIoAeYKhoeKXEeJeKoHYoXeaOIDPKhelKoHIeaIWYaKKaKaOLDoILKaOIUoIaLEDoPWh UawheelDaYYowUohelXEOJleaYEOWEUPXEhaAealwaLKloAeIaOIYeK XeJUeIUhewheelDaYYowEUEKUheoOewheeleIAehEJleoHwhEJhEaMXeYHeJUMaKUeY 统计h前后的字母， [(‘wh’, 4), (‘Kh’, 2), (‘Uh’, 2), (‘Eh’, 1), (‘oh’, 1), (‘Jh’, 1), (‘Wh’, 1), (‘eh’, 1)][(‘he’, 7), (‘hE’, 3), (‘ha’, 1), (‘hU’, 1), (‘ho’, 1)] Khe出现一次，Uhe出现两次，推测S(t)=U 1EMaLOotDeaDletoWYowHloweYKDPtMLWaYIeOXYoIPJeKQPKtaKMaOLI eaIleaAeKolIoAeYKhoeKXEeJeKoHYoXeaOIDPKhelKoHIeaIWYaKKaKaOLDoILKaOItoIaLEDoPWh tawheelDaYYowtohelXEOJleaYEOWEtPXEhaAealwaLKloAeIaOIYeK XeJteIthewheelDaYYowEtEKtheoOewheeleIAehEJleoHwhEJhEaMXeYHeJtMaKteY 由wheellDaYYow ，猜测S(b) = D, S(r) = Y 由Hlower，猜测S(f) = H 由Wrow，猜测S(g)= W 由Khoe，猜测S(s) = K 由Master，猜测S(m) = M 此时文本为： 1EmaLOot be able to grow flowers bPt mLgarIeOXroIPJesQPstasmaOL IeaI leaAes olI oAer shoes XEeJesofroXeaOIbPshels of IeaI grass as aOLboILsaOItoIaLEboPght a wheelbarrow to helXEOJlearEOgEtPXEhaAealwaLs loAe IaOIresXeJteI the wheelbarrow EtEs the oOe wheel eIAehEJleofwhEJhEamXerfeJt master 由oOe，猜测，S(n) = O 由lwaAes, 猜测S(v) = A ….. 最终结果为： 1I may not be able to grow flowers, but my garden produces just as many dead leaves, old overshoes pieces of rope and bushels of dead grass as anybody’s. And today I bought a wheelbarrow to help in clearing it up. I have always loved and respected the wheelbarrow. It is the one wheeled vehicle of which I am perfect master. 维吉尼亚密码: 1KCCPKBGUFDPHQTYAVINRRTMVGRKDNBVFDETDGILTXRGUDDKOTF MBPVGEGLTGCKQRACQCWDNAWCRXIZAKFTLEWRPTYCQKYVXCHKFTPONCQQRHJVAJUWETMCMSPKQDYHJV DAHCTRLSVSKCGCZQQDZXGSFRLSWCWSJTBHAFSIASPRJAH KJRJUMVGKMITZHFPDISPZLVLGWTFPLKKEBDPGCEBSHCTJRWXBAFSPEZQNRWXCVYCGAONWDDKACKAWBBIKFTI OVKCGGHJVLNHIFFSQESVYCLACNVRWBBIREPBBVFEXOSCDYGZWPFDTKFQIYCWHJVLNHIQIBTKHJVNPIST 重合指数法确定m 1234567891011121314m= 1 Ic = 0.0408718383496 avg: 0.0408718383496m= 2 Ic = 0.0384615384615 0.047120045623 avg: 0.0427907920423m= 3 Ic = 0.0559418457649 0.0481016731017 0.0482625482625 avg: 0.050768689043m= 4 Ic = 0.0372549019608 0.0427423981641 0.0375788869765 0.0490533562823 avg: 0.0416573858459m= 5 Ic = 0.0425812115891 0.0430201931519 0.0325644504749 0.0352781546811 0.0429669832655 avg: 0.0392821986325m= 6 Ic = 0.062656641604 0.0837662337662 0.0493506493506 0.0649350649351 0.0428571428571 0.0733766233766 avg: 0.0628237259816m= 7 Ic = 0.030612244898 0.0443262411348 0.0434397163121 0.040780141844 0.0443262411348 0.0443262411348 0.040780141844 avg: 0.041227281186 m=6时，重合指数接近0.065, 进而确定m=6 密钥中各字符之间的相对位移的确定。根据确定好了的密钥长度m，分别计算各个字符不同相对位移下的重合指数，并将结果与0.065比较，从而确定各字符之间的相对位移。 密钥为: CRYPTO 明文为： 1i learned how to calculate the amount of paper needed for a room when i was at school you multiply the square foot age of the walls by the cubic contents of the floor and ceiling combined and double it you then allow half the total for openings such as windows and doors then you allow the other half for matching the pattern then you double the whole thing again to give a margin of error and then you order the paper 仿射密码: 1KQEREJEBCPPCJCRKIEACUZB KRVPKRBCIBQCARBJCVFCUPKRIOFKPACUZQE PBKRXPEIIEABDKPBCPFCDCCAFIEABDKPBCPFEQPKAZBKRHAIB KAPCCIBURCC DKDCCJCIDFUIXPAFFERBICZDFKABICBBENEFCUPJCVKABPCYDCCDPKBCOCPERKIVKSCP ICBRKIJPKABI 仿射密码的加密函数是\(S(x) = (ax+b) mod(m)\)，其中 • a和m互质。 • m是字母的数目。 此处m=26, 根据字母频率，C出现次数最多，假设S(e) = C， 即4a + b = 2,其中a与26互素， 尝试所有与26互素的数字，判定结果正确的指标采用重合指数的方式，将结果与0.065进行比较，确定正确结果。 明文为：O Canada terre de nos aieux ton front est ceint defleurons glorieux car ton bras sait porter lepee il sait porter la croix ton histoire est une epopee des plus brillants exploits et ta valeur de foi trempee protegera nos foyers et nos droits (d)未知密码: 1BNVSNSIHQCEELSSKKYERIFJKXUMBGYKAMOLJTYAVFBKVT DVBPWWRJY YLAOKYMPIQSCGDLFSRLL PROYGESEBUUALRWXM MASAZLGLEDFJBZAVVPXWICGJXASCBYEHOSNMULKCEAHTQ OKMFLEBKFXLRRFDT7XCTWBJSICBGAWDVYDHAVFJXZLBKC GJINEAHTTOEWTUHKRQVVRGZBXYIREMMASCSPBHLHJMBLR FFJELHWEYILWISTFW WYEJCMHYUYRUFSFMGESI GRL WALSIWM NUHSIMYYITCCQP2SICEHBCCMZFEGVJYOCDEMMPGHVAAUM ELCMOEHVLTIPSUYILVGFLMVWDVYDBTHFRAYISYSGKVSUU HYHGGCKTMBLRX 不妨尝试一下维吉尼亚密码密码，将其以输入用b的程序进行解密，结果为： 秘钥长度为 6 秘钥为: THEORY 明文为: 秘钥长度为 6 秘钥为: THEORY 明文为: I grew up among slow talkers men in particular who dropped words a few at a time like beans in a hill and when I got to Minneapolis where people took a lake wobegon comma to mean the end of a story I couldn’t speak a whole sentence in company and was considered not too briaht so I enrolled in a speech couqse taught by orvilles and the founder of reflexive relaxology a self hypnotic technique that enabled a person to speak up to three hundred words per minute 1.26 下面给出一种特殊的置换密码。设m,n为正整数，将明文写成一个m*n的矩阵，依次取各列构成密文。例如，设m=3,n=4，可以将明文cryptography写成 123cryptography 对应的密码是: ctaropyghpry (1) 在已知m和n的情况下，Bob如何解密密文 (2) 现在根据上面的方法，试破解下列密文：MYAMRARUYIQTENCTORAHROYWDSOYEOUARRGDERNOGW 解： （1）已知m和n时，Bob可以以间隔m, 依次取密文中的字符，组合成明文。 （2）遍历m,n的组合，结果如下： 1234567891011121314m: 1 n: 42myamraruyiqtenctorahroywdsoyeouarrgdernogwm: 2 n: 21marryqecoarydoeurgengxlzthsmsqgnvrxnzqcqnvm: 3 n: 14mmrietaodyureoxqtpmngxrdzfqfyywrappummpblum: 6 n: 7mreaduextmgrzqywapmpljfqlvolnmkuaccvomrjyrm: 7 n: 6mucoedxxsxndygmuspjnoaxknpwonkvzcjmblhlsaqm: 14 n: 3mcexsnymsjoxnwnvcmllanhwqqwznigtdihdscualjm: 21 n: 2moxxyujanovjlsnxqgzlgqigsfatopepybawiwonxc 查阅资料，发现key是142536，调整其顺序,得到 mary mary quite contrary how does your garden grow 1.29 下面给出一个由维吉尼亚密码改进的流密码。给定长度为m的密钥字(K,…,K) 通过规则 \[z_i = K_i(1\le i \le m), z_{i+m} = (z_i + 1)mod26 (i \ge 1)\]来构造密钥流序列,换句话说,每次我们使用的密钥字都使用字母后续者的模26来替代。例如,如果“SUMMER”是密钥字,我们首先用“SUMMER”来加密第一个六字母组,对下一个六字母组,使用“TVNNFS”,等等。 (a)描述一下怎样利用重合指数法来确定首次用来加密的密钥字的长度,然后找到它。 (b)通过分析下列密文来测试你的方法: 1IYMYSILONRFNCQXQJEDSHBUIBCJUZBOLFQYSCHATPEQGQ JEJNGNXZWHHGWFSUKULJQACZKKJOAAHGKEMTAFGMKVRDO PXNEHEKZNKFSKIFRQVHHOVXINPHMRTJPYWQGJWPUUVKFP OAWPMRKKQZWLQDYAZDRMLPBJKJOBWIWPSEPVVQMBCRYVC RUZAAOUMBCHDAGDIEMSZFZHALIGKEMJJJPCIWKRMLMPIN AYOFIREAOLDTH ITDVRMSE 解： (a) 分m组取时，每次需要减index 并mod 26，用生成的序列去计算其重合指数 (b) 结果如下; 1234567891011121314m= 1 Ic = 0.0402853824457 avg: 0.0402853824457m= 2 Ic = 0.0401172864188 0.0355857656937 avg: 0.0378515260562m= 3 Ic = 0.0361336946703 0.0430593194821 0.0478771454381 avg: 0.0423567198635m= 4 Ic = 0.0380750925436 0.0407191961925 0.0382513661202 0.0349726775956 avg: 0.038004583113m= 5 Ic = 0.0710204081633 0.0739795918367 0.0756802721088 0.0960884353741 0.0816326530612 avg: 0.0796802721088秘钥长度为 5秘钥为: PRIME明文为:the most famous cryptologist in history owesh is fameless to what he did than to what he said and to the sensational way in which he said it and this was most perfectly in character for herbertosborneyardley was perhaps the most engagin garticulateandtechnicoloredpersonalityinthebusiness 1.30 1.30 解：使用python解密，结果如下: 12345678910111213141516171819202122232425260 aqndwbhapnkjhwaxjyhwhanpjdjynaqjohzypzypdjobannykjoyphjdijtp1 kjqixtokwqsfoxkzfroxokqwfifrqkjfvoerwerwifvtkqqrsfvrwoficfpw2 sfjczpvsxjugvzseglvzvsjxgcgljsfgyvhlxhlxcgypsjjlugylxvgcagwx3 ugfaewyuzfmbyeuhbdyeyufzbabdfugbryodzodzabrwuffdmbrdzybakbxz4 mbgkhxrmegntrhmotirhrmgetktigmbtlrvieviektlxmggintliertkstze5 ntbsozlnhbqplonvpclolnbhpspcbntpdlychychspdznbbcqpdchlpsupeh6 qptuvedqotjwdvqywadvdqtowuwatqpwidraoraouwieqttajwiaodwumwho7 jwpmyhijvpfxiyjrxkiyijpvxmxkpjwxcilkvlkvmxchjppkfxckvixmnxov8 fxwnrocfywgzcrflzscrcfwyznzswfxzacdsydsynzaofwwsgzasycznqzvy9 gzxqlvagrxbealgdeualagxreqeuxgzekaiuriurqekvgxxubekuraeqjeyr10 bezjdykblzthkdbihmkdkbzlhjhmzbehskcmlcmljhsybzzmthsmlkhjfhrl11 thefirstdepositconsistedofonethousandandfourteenpoundsofgold12 pohgclupihwvucpavqucuphivgvqhpovmukqikqigvmlphhqwvmqiuvgbvdi13 wvobadmwcoxymawkyjmamwocybyjowvynmsjcsjcbyndwoojxynjcmybtyic14 xyvtkinxavzrnkxsrfnknxvartrfvxyrqnufaufatrqixvvfzrqfanrtprca15 zrypscqzkyelqszulgqsqzyklplgyzrljqmgkmgkpljczyygeljgkqlpwlak16 elrwuajesrhdjuemdbjujersdwdbreldfjnbsnbswdfaerrbhdfbsjdwxdks17 hdlxmkfhuloifmhnitfmfhluixitlhdigfqtuqtuxigkhlltoigtufixzisu18 oidznsgomdvcgnoqcpgngodmczcpdoicbgjpmjpmzcbsoddpvcbpmgczecum19 vciequbvniyabqvjawbqbvinaeawivcatbfwnfwneatuviiwyatwnbaehamn20 yachjmtyqcrktjyfkxtjtycqkhkxcyakptgxqgxqhkpmyccxrkpxqtkhoknq21 rkaofnprjalspfrgszpfprajsoszarkswpbzjbzjoswnraazlswzjpsovsqj22 lskvgqwlfkduwglbuewgwlkfuvueklsuxwteftefvuxqlkkeduxefwuvyujf23 dusybjxdgsimxbdtmhxbxdsgmymhsdumzxphgphgymzjdsshimzhgxmyrmfg24 imurtfzibucnztipnoztziubnrnouimnezwobwobrnefiuuocneobznrlngb25 cnmlpgectmaqepcwqvepecmtqlqvmcnqhexvtxvtlqhgcmmvaqhvteqldqbt K = 11时为结果，明文为： the first deposit consisted of one thousand and fourteen pounds of gold]]></content>
    </entry>

    
  
  
</search>
